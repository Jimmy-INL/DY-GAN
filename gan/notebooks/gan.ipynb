{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import tensorflow\n",
      "import keras\n",
      "import matplotlib\n",
      "import sklearn\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# running with non gpu singularity container, so commented out the next line to use CPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "print \"import tensorflow\"\n",
    "           \n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, LeakyReLU, Lambda\n",
    "from keras.layers import Input, merge, Concatenate, concatenate\n",
    "from keras.losses import binary_crossentropy\n",
    "print \"import keras\"\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "print \"import matplotlib\"\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from scipy.stats import binned_statistic_2d\n",
    "\n",
    "print \"import sklearn\"\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Minv(cols,ptetaphi=False,nopy2=False):\n",
    "    \"\"\"\n",
    "    Computes M for two objects given the cartesian momentum projections\n",
    "    if `ptetaphi` is True, then assumes the 8 input columns are cylindrical eptetaphi\n",
    "    if `nopy2` is True, input is 7 columns with no py2\n",
    "    \"\"\"\n",
    "    if ptetaphi:\n",
    "        cols = ptetaphi_to_cartesian(cols)\n",
    "    if nopy2:\n",
    "        M2 = (cols[:,0]+cols[:,4])**2\n",
    "        M2 -= (cols[:,1]+cols[:,5])**2\n",
    "        M2 -= (cols[:,2]          )**2\n",
    "        M2 -= (cols[:,3]+cols[:,6])**2\n",
    "    else:\n",
    "        M2 = (cols[:,0]+cols[:,4])**2\n",
    "        M2 -= (cols[:,1]+cols[:,5])**2\n",
    "        M2 -= (cols[:,2]+cols[:,6])**2\n",
    "        M2 -= (cols[:,3]+cols[:,7])**2\n",
    "    return np.sqrt(M2)\n",
    "\n",
    "def cartesian_to_ptetaphi(eight_cartesian_cols):\n",
    "    \"\"\"\n",
    "    Takes 8 columns as cartesian e px py pz e px py pz\n",
    "    and converts to e pt eta phi e pt eta phi\n",
    "    \"\"\"\n",
    "    e1 =  eight_cartesian_cols[:,0]\n",
    "    e2 =  eight_cartesian_cols[:,4]\n",
    "    px1 = eight_cartesian_cols[:,1]\n",
    "    px2 = eight_cartesian_cols[:,5]\n",
    "    py1 = eight_cartesian_cols[:,2]\n",
    "    py2 = eight_cartesian_cols[:,6]\n",
    "    pz1 = eight_cartesian_cols[:,3]\n",
    "    pz2 = eight_cartesian_cols[:,7]\n",
    "    p1 = np.sqrt(px1**2+py1**2+pz1**2)\n",
    "    p2 = np.sqrt(px2**2+py2**2+pz2**2)\n",
    "    pt1 = np.sqrt(px1**2+py1**2)\n",
    "    pt2 = np.sqrt(px2**2+py2**2)\n",
    "    phi1 = np.arctan2(py1,px1)\n",
    "    phi2 = np.arctan2(py2,px2)\n",
    "    eta1 = np.arctanh(pz1/p1)\n",
    "    eta2 = np.arctanh(pz2/p2)\n",
    "    return np.c_[e1,pt1,eta1,phi1,e2,pt2,eta2,phi2]\n",
    "\n",
    "def ptetaphi_to_cartesian(eight_eptetaphi_cols):\n",
    "    \"\"\"\n",
    "    Takes 8 columns as e pt eta phi e pt eta phi\n",
    "    and converts to e px py pz e px py pz\n",
    "    \"\"\"\n",
    "    e1 =  eight_eptetaphi_cols[:,0]\n",
    "    e2 =  eight_eptetaphi_cols[:,4]\n",
    "    pt1 =  eight_eptetaphi_cols[:,1]\n",
    "    pt2 =  eight_eptetaphi_cols[:,5]\n",
    "    eta1 =  eight_eptetaphi_cols[:,2]\n",
    "    eta2 =  eight_eptetaphi_cols[:,6]\n",
    "    phi1 =  eight_eptetaphi_cols[:,3]\n",
    "    phi2 =  eight_eptetaphi_cols[:,7]\n",
    "    px1 = np.abs(pt1)*np.cos(phi1)\n",
    "    px2 = np.abs(pt2)*np.cos(phi2)\n",
    "    py1 = np.abs(pt1)*np.sin(phi1)\n",
    "    py2 = np.abs(pt2)*np.sin(phi2)\n",
    "    pz1 = np.abs(pt1)/np.tan(2.0*np.arctan(np.exp(-1.*eta1)))\n",
    "    pz2 = np.abs(pt2)/np.tan(2.0*np.arctan(np.exp(-1.*eta2)))\n",
    "    return np.c_[e1,px1,py1,pz1,e2,px2,py2,pz2]\n",
    "\n",
    "def get_dphi(px1,py1,px2,py2):\n",
    "    phi1 = np.arctan2(py1,px1)\n",
    "    phi2 = np.arctan2(py2,px2)\n",
    "    dphi = phi1-phi2\n",
    "    dphi[dphi>np.pi] -= 2*np.pi\n",
    "    dphi[dphi<-np.pi] += 2*np.pi \n",
    "    return dphi\n",
    "\n",
    "    \n",
    "def cartesian_zerophi2(coords,ptetaphi=False):\n",
    "    \"\"\"\n",
    "    returns 8-1=7 columns rotating leptons such that phi2 is 0 (and removing it)\n",
    "    if `ptetaphi` is True, then return eptetaphi instead of epxpypz\n",
    "    \"\"\"\n",
    "    lepcoords_cyl = cartesian_to_ptetaphi(lepcoords)\n",
    "    phi1 = lepcoords_cyl[:,3]\n",
    "    phi2 = lepcoords_cyl[:,7]\n",
    "    dphi = phi1-phi2\n",
    "    dphi[dphi>np.pi] -= 2*np.pi\n",
    "    dphi[dphi<-np.pi] += 2*np.pi\n",
    "    lepcoords_cyl[:,3] = dphi\n",
    "    lepcoords_cyl[:,7] = 0.\n",
    "    if ptetaphi:\n",
    "        return np.delete(lepcoords_cyl, [7], axis=1)\n",
    "    else:\n",
    "        return np.delete(ptetaphi_to_cartesian(lepcoords_cyl), [6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invmass_from_8cartesian(x):\n",
    "    invmass = K.sqrt(\n",
    "                (x[:,0:1]+x[:,4:5])**2-\n",
    "                (x[:,1:2]+x[:,5:6])**2-\n",
    "                (x[:,2:3]+x[:,6:7])**2-\n",
    "                (x[:,3:4]+x[:,7:8])**2\n",
    "                )\n",
    "    return invmass\n",
    "\n",
    "def invmass_from_8cartesian_nopy2(x):\n",
    "    invmass = K.sqrt(\n",
    "                (x[:,0:1]+x[:,4:5])**2-\n",
    "                (x[:,1:2]+x[:,5:6])**2-\n",
    "                (x[:,2:3]         )**2-\n",
    "                (x[:,3:4]+x[:,6:7])**2\n",
    "                )\n",
    "    return invmass\n",
    "\n",
    "def add_invmass_from_8cartesian(x):\n",
    "    return K.concatenate([x,invmass_from_8cartesian(x)])\n",
    "\n",
    "\n",
    "def fix_outputs(x):\n",
    "    \"\"\"\n",
    "    Take nominal delphes format of 19 columns and fix some columns\n",
    "    \"\"\"\n",
    "    return K.concatenate([\n",
    "        # x[:,0:21],\n",
    "        x[:,0:7], # epxpypz for lep1,lep2 -1 for no py2\n",
    "        x[:,7:8], # nvtx\n",
    "        K.sign(x[:,8:10]), # q1 q2\n",
    "        x[:,10:12], # iso1 iso2\n",
    "        x[:,12:14], # met, metphi\n",
    "        x[:,14:19], # jet pts\n",
    "#         x[:,0:8], # epxpypz for lep1,lep2\n",
    "#         K.sign(x[:,8:9]), # lep1 charge\n",
    "#         x[:,9:10], # lep1 iso\n",
    "#         K.sign(x[:,10:11]), # lep2 charge\n",
    "#         x[:,11:12], # lep2 iso\n",
    "#         K.round(x[:,12:13]), # nvtxs\n",
    "#         x[:,13:15], # met, metphi\n",
    "#         K.round(x[:,15:16]), # ngenjets\n",
    "#         x[:,16:21], # jet pts\n",
    "        ])\n",
    "\n",
    "def custom_loss(c):\n",
    "    def loss_func(y_true, y_pred_mll):\n",
    "        y_true = y_true[:,0]\n",
    "        y_pred = y_pred_mll[:,0]\n",
    "        mll_pred = y_pred_mll[:,1]\n",
    "        \n",
    "#         mll_loss = K.mean(K.abs(mll_pred - 91.2))\n",
    "\n",
    "        mll_loss = K.mean((mll_pred - 91.2)**2)\n",
    "\n",
    "#         pseudomll = K.random_normal_variable(shape=(1,1), mean=91.2, scale=2)\n",
    "#         mll_loss = K.mean((mll_pred - pseudomll)**2)\n",
    "        \n",
    "        return binary_crossentropy(y_true, y_pred) + c*mll_loss\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(preds,reals,fname=\"\"):\n",
    "    nrows, ncols = 4,4\n",
    "    fig, axs = plt.subplots(nrows,ncols,figsize=(16,13))\n",
    "    fig.subplots_adjust(wspace=0.1,hspace=0.3)\n",
    "\n",
    "\n",
    "    info = [\n",
    "        [\"mll\",(60,120,50)],\n",
    "        [\"lep1_e\",(0,250,50)],\n",
    "        [\"lep1_px\",(-100,100,50)],\n",
    "        [\"lep1_py\",(-100,100,50)],\n",
    "        [\"lep1_pz\",(-200,200,50)],\n",
    "        [\"lep2_e\",(0,250,50)],\n",
    "        [\"lep2_px\",(-100,100,50)],\n",
    "        [\"lep2_pz\",(-200,200,50)],\n",
    "        [\"dphi\",(-4,4,50)],\n",
    "        [\"nvtxs\",(0,50,350)],\n",
    "        [\"met\",(0,150,50)],\n",
    "        [\"metphi\",(-6,6,50)],\n",
    "        [\"lep1_charge\",(-7,7,30)],\n",
    "        [\"lep2_charge\",(-7,7,30)],\n",
    "        [\"lep1_iso\",(0,10,30)],\n",
    "        [\"lep2_iso\",(0,10,30)],\n",
    "\n",
    "    ]\n",
    "    for ic,(cname,crange) in enumerate(info):\n",
    "        if cname == \"mll\":\n",
    "            real = reals[\"mll\"]\n",
    "            pred = Minv(preds,ptetaphi=False,nopy2=True)\n",
    "        elif cname == \"lep1_e\": real, pred = reals[cname], preds[:,0]\n",
    "        elif cname == \"lep1_px\": real, pred = reals[cname], preds[:,1]\n",
    "        elif cname == \"lep1_py\": real, pred = reals[cname], preds[:,2]\n",
    "        elif cname == \"lep1_pz\": real, pred = reals[cname], preds[:,3]\n",
    "        elif cname == \"lep2_e\": real, pred = reals[cname], preds[:,4]\n",
    "        elif cname == \"lep2_px\": real, pred = reals[cname], preds[:,5]\n",
    "        elif cname == \"lep2_pz\": real, pred = reals[cname], preds[:,6]\n",
    "        elif cname == \"dphi\":\n",
    "            real = get_dphi(reals[\"lep1_px\"], reals[\"lep1_py\"], reals[\"lep2_px\"], reals[\"lep2_py\"])\n",
    "            pred = get_dphi(preds[:,1], preds[:,2], preds[:,5], np.zeros(len(preds)))\n",
    "        elif cname == \"nvtxs\": real, pred = reals[cname], np.round(preds[:,7])\n",
    "        elif cname == \"lep1_charge\": real, pred = reals[cname], preds[:,8]\n",
    "        elif cname == \"lep2_charge\": real, pred = reals[cname], preds[:,9]\n",
    "        elif cname == \"lep1_iso\": real, pred = reals[cname], preds[:,10]\n",
    "        elif cname == \"lep2_iso\": real, pred = reals[cname], preds[:,11]\n",
    "        elif cname == \"met\": real, pred = reals[cname], preds[:,12]\n",
    "        elif cname == \"metphi\": real, pred = reals[cname], preds[:,13]\n",
    "        idx = ic // ncols, ic % ncols\n",
    "        bins_real = axs[idx].hist(real, range=crange[:2],bins=crange[-1], histtype=\"step\", lw=2,density=True)\n",
    "        bins_pred = axs[idx].hist(pred, range=crange[:2],bins=crange[-1], histtype=\"step\", lw=2,density=True)\n",
    "        axs[idx].set_xlabel(\"{}\".format(cname))\n",
    "        axs[idx].get_yaxis().set_visible(False)\n",
    "    #     axs[idx].set_yscale(\"log\", nonposy='clip')\n",
    "    _ = axs[0,0].legend([\"True\",\"Pred\"], loc='upper right')\n",
    "    if fname:\n",
    "        fig.savefig(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.args = dict(kwargs)\n",
    "\n",
    "        self.tag = kwargs[\"tag\"]\n",
    "        self.input_file = str(kwargs[\"input_file\"])\n",
    "        self.noise_shape = (int(kwargs[\"noise_size\"]),)\n",
    "        self.output_shape = (int(kwargs[\"output_size\"]),)\n",
    "        self.noise_type = int(kwargs[\"noise_type\"])\n",
    "        self.ntest_samples = int(kwargs[\"ntest_samples\"])\n",
    "        self.nepochs_dump_pred_metrics = int(kwargs[\"nepochs_dump_pred_metrics\"])\n",
    "        self.nepochs_dump_models = int(kwargs[\"nepochs_dump_models\"])\n",
    "        self.nepochs_dump_plots = int(kwargs[\"nepochs_dump_plots\"])\n",
    "        self.nepochs_max = int(kwargs[\"nepochs_max\"])\n",
    "        self.batch_size = int(kwargs[\"batch_size\"])\n",
    "        self.do_concatenate_disc = kwargs[\"do_concatenate_disc\"]\n",
    "        self.do_concatenate_gen = kwargs[\"do_concatenate_gen\"]\n",
    "        self.do_batch_normalization_disc = kwargs[\"do_batch_normalization_disc\"]\n",
    "        self.do_batch_normalization_gen = kwargs[\"do_batch_normalization_gen\"]\n",
    "        self.do_soft_labels = kwargs[\"do_soft_labels\"]\n",
    "        self.do_noisy_labels = kwargs[\"do_noisy_labels\"]\n",
    "        self.do_tanh_gen = kwargs[\"do_tanh_gen\"]\n",
    "        self.nepochs_decay_noisy_labels = int(kwargs[\"nepochs_decay_noisy_labels\"])\n",
    "        self.use_ptetaphi_additionally = kwargs[\"use_ptetaphi_additionally\"]\n",
    "        self.optimizer_gen = kwargs[\"optimizer_gen\"]\n",
    "        self.optimizer_disc = kwargs[\"optimizer_disc\"]\n",
    "        self.depth_disc = kwargs[\"depth_disc\"]\n",
    "        self.width_disc = kwargs[\"width_disc\"]\n",
    "        self.depth_gen = kwargs[\"depth_gen\"]\n",
    "        self.width_gen = kwargs[\"width_gen\"]\n",
    "        self.beefy_generator = kwargs[\"beefy_generator\"]\n",
    "        self.add_invmass_disc = kwargs[\"add_invmass_disc\"]\n",
    "        self.fix_delphes_outputs = kwargs[\"fix_delphes_outputs\"]\n",
    "        self.use_delphes = kwargs[\"use_delphes\"]\n",
    "        self.use_mll_loss = kwargs[\"use_mll_loss\"]\n",
    "        self.loss_mll_weight = kwargs[\"loss_mll_weight\"]\n",
    "        if self.use_ptetaphi_additionally: self.output_shape = (self.output_shape[0]+8,)\n",
    "\n",
    "        os.system(\"mkdir -p progress/{}/\".format(self.tag))\n",
    "        os.system(\"cp gan.py progress/{}/\".format(self.tag))\n",
    "\n",
    "        self.scaler_type = kwargs[\"scaler_type\"]\n",
    "        self.scaler = None\n",
    "        if self.scaler_type.lower() == \"minmax\":\n",
    "            self.scaler = MinMaxScaler(feature_range=(-1.,1.))\n",
    "        elif self.scaler_type.lower() == \"robust\":\n",
    "            self.scaler = RobustScaler()\n",
    "        elif self.scaler_type.lower() == \"standard\":\n",
    "            self.scaler = StandardScaler()\n",
    "\n",
    "        self.data = None\n",
    "        self.data_ref = None\n",
    "        self.d_epochinfo = {}\n",
    "\n",
    "        # optimizer = Adam(0.0002, 0.5)\n",
    "        optimizer_d = self.optimizer_disc\n",
    "        # optimizer_d = \"sgd\"\n",
    "        optimizer_g = self.optimizer_gen\n",
    "        # optimizer_g = \"adam\"\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        if self.use_mll_loss:\n",
    "            loss = custom_loss(c=self.loss_mll_weight)\n",
    "        else:\n",
    "            loss = \"binary_crossentropy\"\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=loss,\n",
    "            optimizer=optimizer_d,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss=loss, optimizer=optimizer_g)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=self.noise_shape)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=loss, optimizer=optimizer_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(GAN):\n",
    "    \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        ## Head\n",
    "        model.add(Dense(64, input_shape=self.noise_shape))\n",
    "        if self.do_batch_normalization_gen:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        if self.do_concatenate_gen:\n",
    "            model.add(Lambda(lambda x: K.concatenate([x*x,x])))\n",
    "            model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        ## Main Body\n",
    "        if self.depth_gen > 0 and self.width_gen > 0:\n",
    "            for level in xrange(0,self.depth_gen):\n",
    "                model.add(Dense(width_gen/(2**level))) #Triangle with width halved at each level\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "        elif self.beefy_generator:\n",
    "            for size in [128,256,512,1024,1024,512,256,128,64,32]:\n",
    "                model.add(Dense(size))\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "        else:\n",
    "            for size in [128,128,128,64,32]:\n",
    "                model.add(Dense(size))\n",
    "                model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        ## Tail\n",
    "        model.add(Dense(self.output_shape[0]))\n",
    "        if self.do_tanh_gen:\n",
    "            model.add(Activation(\"tanh\"))\n",
    "        elif self.fix_delphes_outputs:\n",
    "            model.add(Lambda(fix_outputs,\n",
    "                input_shape=self.output_shape,\n",
    "                output_shape=self.output_shape\n",
    "                ))\n",
    "\n",
    "#         model.summary()\n",
    "        print \"Generator params: {}\".format(model.count_params())\n",
    "\n",
    "        noise = Input(shape=self.noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(GAN):\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        inputs = Input(self.output_shape)\n",
    "        mll = Lambda(invmass_from_8cartesian_nopy2)(inputs)\n",
    "        x = Dense(128)(inputs)\n",
    "        if self.do_batch_normalization_disc:\n",
    "            x = BatchNormalization()(x)\n",
    "        if self.do_concatenate_disc:\n",
    "            x = Lambda(lambda x: K.concatenate([x*x,x]))(x)\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "        ## Main Body\n",
    "        if self.depth_disc > 0 and self.width_disc > 0:\n",
    "            for level in xrange(0,self.depth_disc):\n",
    "                x = Dense(self.width_disc/(2**level))(x) #Triangle with width halved at each level\n",
    "                x = LeakyReLU(alpha=0.2)(x)\n",
    "        else:\n",
    "            for size in [128]*5 + [64,32,16,8]:\n",
    "                x = Dense(size)(x)\n",
    "                x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "        ## Tail\n",
    "        out = Dense(1,activation='sigmoid')(x)\n",
    "        \n",
    "        if self.use_mll_loss:\n",
    "            model = Model(inputs=inputs, outputs=concatenate([out,mll]))\n",
    "        else:\n",
    "            model = Model(inputs=inputs, outputs=out)\n",
    "#         print model.output_shape\n",
    "#         model.summary()\n",
    "        print \"Discriminator params: {}\".format(model.count_params())\n",
    "        \n",
    "        return model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(GAN):\n",
    "    \n",
    "    def load_data(self):\n",
    "        if self.data is not None: return\n",
    "        \n",
    "        if self.use_delphes:\n",
    "            self.data = np.load(self.input_file)\n",
    "        else:\n",
    "            self.data = np.load(self.input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(GAN):\n",
    "\n",
    "    def get_noise(self, amount=1024):\n",
    "        # nominal\n",
    "        if self.noise_type == 1:\n",
    "            noise_half = np.random.normal(0, 1, (amount//2, self.noise_shape[0]))\n",
    "            noise_full = np.random.normal(0, 1, (amount, self.noise_shape[0]))\n",
    "\n",
    "        elif self.noise_type == 2: # random soup, 4,2,2 have to be modified to sum to noise_shape[0]\n",
    "            ngaus = self.noise_shape[0] // 2\n",
    "            nflat = (self.noise_shape[0] - ngaus) // 2\n",
    "            nexpo = self.noise_shape[0] - nflat - ngaus\n",
    "            noise_gaus = np.random.normal( 0, 1, (amount//2+amount, ngaus))\n",
    "            noise_flat = np.random.uniform(-1, 1, (amount//2+amount, nflat))\n",
    "            noise_expo = np.random.exponential( 1,    (amount//2+amount, nexpo))\n",
    "            noise = np.c_[ noise_gaus,noise_flat,noise_expo ]\n",
    "            noise_half = noise[:amount//2]\n",
    "            noise_full = noise[-amount:]\n",
    "\n",
    "        return noise_half, noise_full\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(GAN):\n",
    "            \n",
    "    def train(self):\n",
    "\n",
    "        self.load_data()\n",
    "        \n",
    "        if self.use_delphes:\n",
    "            lepcoords = np.c_[\n",
    "                self.data[\"lep1_e\"],\n",
    "                self.data[\"lep1_px\"],\n",
    "                self.data[\"lep1_py\"],\n",
    "                self.data[\"lep1_pz\"],\n",
    "                self.data[\"lep2_e\"],\n",
    "                self.data[\"lep2_px\"],\n",
    "                self.data[\"lep2_py\"],\n",
    "                self.data[\"lep2_pz\"],\n",
    "            ]\n",
    "            lepcoords_dphi = cartesian_zerophi2(lepcoords)\n",
    "            \n",
    "            nvtx_smeared = np.round(np.random.normal(self.data[\"nvtxs\"],0.5))\n",
    "            X_train = np.c_[\n",
    "                lepcoords_dphi, # 7 columns\n",
    "                nvtx_smeared, # 1 column\n",
    "                self.data[\"lep1_charge\"], self.data[\"lep2_charge\"],\n",
    "                self.data[\"lep1_iso\"], self.data[\"lep2_iso\"],\n",
    "                self.data[\"met\"], self.data[\"metphi\"],\n",
    "                self.data[\"genjet_pt1\"],\n",
    "                self.data[\"genjet_pt2\"],\n",
    "                self.data[\"genjet_pt3\"],\n",
    "                self.data[\"genjet_pt4\"],\n",
    "                self.data[\"genjet_pt5\"],\n",
    "            ].astype(np.float32)\n",
    "        else:\n",
    "            X_train = self.data[:,range(1,1+8)]\n",
    "            if self.use_ptetaphi_additionally:\n",
    "                X_train = np.c_[X_train, cartesian_to_ptetaphi(X_train)]\n",
    "\n",
    "        # # NOTE. StandardScaler should be fit on training set\n",
    "        # # and applied the same to train and test, otherwise we\n",
    "        # # introduce a bias\n",
    "        if self.scaler:\n",
    "            self.scaler.fit(X_train)\n",
    "            X_train = self.scaler.transform(X_train).astype(np.float32)\n",
    "            pickle.dump(self.scaler, open(\"progress/{}/scaler.pkl\".format(self.tag),'w'))\n",
    "\n",
    "        half_batch = int(self.batch_size / 2)\n",
    "\n",
    "        prev_gen_loss = -1\n",
    "        prev_disc_loss = -1\n",
    "        n_loss_same_gen = 0  # number of epochs for which generator loss has remained ~same (within 0.01%)\n",
    "        n_loss_same_disc = 0  # number of epochs for which discriminator loss has remained ~same (within 0.01%)\n",
    "        old_info = -1, -1\n",
    "        for epoch in range(self.nepochs_max):\n",
    "\n",
    "            if n_loss_same_gen > 500 or n_loss_same_disc > 500:\n",
    "                print \"BREAKING because disc/gen loss has remained the same for {}/{} epochs!\".format(n_loss_same_disc,n_loss_same_gen)\n",
    "                break\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise_half, noise_full = self.get_noise(self.batch_size)\n",
    "            \n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise_half)\n",
    "\n",
    "            # Train the discriminator\n",
    "            ones = np.ones((half_batch, 1))\n",
    "            zeros = np.zeros((half_batch, 1))\n",
    "\n",
    "            if self.do_soft_labels:\n",
    "                ones *= 0.9\n",
    "\n",
    "            if self.do_noisy_labels:\n",
    "                frac = 0.3*np.exp(-epoch/self.nepochs_decay_noisy_labels)\n",
    "                if frac > 0.005:\n",
    "                    ones[np.random.randint(0, len(ones), int(frac*len(ones)))] = 0\n",
    "                    zeros[np.random.randint(0, len(zeros), int(frac*len(zeros)))] = 1\n",
    "\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, ones)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, zeros)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * self.batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise_full, valid_y)\n",
    "\n",
    "            if (g_loss - prev_gen_loss) < 0.0001: n_loss_same_gen += 1\n",
    "            else: n_loss_same_gen = 0\n",
    "            prev_gen_loss = g_loss\n",
    "\n",
    "            if (d_loss[0] - prev_disc_loss) < 0.0001: n_loss_same_disc += 1\n",
    "            else: n_loss_same_disc = 0\n",
    "            prev_disc_loss = d_loss[0]\n",
    "\n",
    "            # Plot the progress\n",
    "#             print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            sys.stdout.write(\"\\r{} [D loss: {}, acc.: {:.2f}%] [G loss: {}] [mll={:.3f}+-{:.3f}]\".format(epoch, d_loss[0], 100.0*d_loss[1], g_loss, old_info[0], old_info[1]))\n",
    "\n",
    "            if epoch % self.nepochs_dump_pred_metrics == 0 and epoch > 0:\n",
    "            \n",
    "                _, noise_test = self.get_noise(self.ntest_samples)\n",
    "            \n",
    "                sys.stdout.write(\"\\n\") # break up the stream of text\n",
    "\n",
    "                gen_imgs = self.generator.predict(noise_test)\n",
    "\n",
    "                if self.scaler:\n",
    "                    gen_imgs = self.scaler.inverse_transform(gen_imgs)\n",
    "\n",
    "                masses = Minv(gen_imgs,nopy2=True)\n",
    "                masses = masses[np.isfinite(masses)]\n",
    "                old_info = masses.mean(), masses.std()\n",
    "\n",
    "                if \"epoch\" not in self.d_epochinfo:\n",
    "                    self.d_epochinfo[\"epoch\"] = []\n",
    "                    self.d_epochinfo[\"d_acc\"] = []\n",
    "                    self.d_epochinfo[\"d_loss\"] = []\n",
    "                    self.d_epochinfo[\"g_loss\"] = []\n",
    "                    self.d_epochinfo[\"mass_mu\"] = []\n",
    "                    self.d_epochinfo[\"mass_sig\"] = []\n",
    "                    self.d_epochinfo[\"time\"] = []\n",
    "                    self.d_epochinfo[\"args\"] = self.args\n",
    "                else:\n",
    "                    self.d_epochinfo[\"epoch\"].append(epoch)\n",
    "                    self.d_epochinfo[\"d_acc\"].append(100*d_loss[1])\n",
    "                    self.d_epochinfo[\"d_loss\"].append(d_loss[0])\n",
    "                    self.d_epochinfo[\"g_loss\"].append(g_loss)\n",
    "                    self.d_epochinfo[\"mass_mu\"].append(masses.mean())\n",
    "                    self.d_epochinfo[\"mass_sig\"].append(masses.std())\n",
    "                    self.d_epochinfo[\"time\"].append(time.time())\n",
    "\n",
    "                pickle.dump(self.d_epochinfo, open(\"progress/{}/history.pkl\".format(self.tag),'w'))\n",
    "\n",
    "            if epoch % self.nepochs_dump_plots == 0 and epoch > 0:\n",
    "                _, noise = self.get_noise(self.ntest_samples)\n",
    "                preds = gan.generator.predict(noise)\n",
    "                reals = self.data[:15000]\n",
    "                _ = make_plots(preds,reals,fname=\"progress/{}/plots_{:06d}.png\".format(self.tag,epoch))\n",
    "            \n",
    "            if epoch % self.nepochs_dump_models == 0 and epoch > 0:\n",
    "                self.discriminator.save(\"progress/{}/disc_{}.weights\".format(self.tag,epoch))\n",
    "                self.generator.save(\"progress/{}/gen_{}.weights\".format(self.tag,epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'width_disc': 0, 'ntest_samples': 10000, 'nepochs_dump_models': 5000, 'output_size': 19, 'input_file': '/home/users/namin/2017/gan/DY-GAN/delphes/data_Nov10.npa', 'use_delphes': True, 'do_batch_normalization_disc': False, 'scaler_type': '', 'batch_size': 200, 'use_ptetaphi_additionally': False, 'do_concatenate_disc': False, 'do_noisy_labels': False, 'do_soft_labels': False, 'depth_gen': 0, 'nepochs_dump_pred_metrics': 250, 'loss_mll_weight': 0.001, 'noise_size': 8, 'do_batch_normalization_gen': False, 'add_invmass_disc': False, 'optimizer_disc': 'adadelta', 'nepochs_max': 30001, 'width_gen': 0, 'depth_disc': 0, 'do_tanh_gen': False, 'fix_delphes_outputs': True, 'do_concatenate_gen': False, 'beefy_generator': False, 'use_mll_loss': True, 'nepochs_dump_plots': 1000, 'nepochs_decay_noisy_labels': 2000, 'optimizer_gen': 'adadelta', 'noise_type': 1}\n",
      "Discriminator params: 96129\n",
      "Generator params: 52883\n"
     ]
    }
   ],
   "source": [
    "# defaults\n",
    "params = {\n",
    "        \"input_file\": \"data_xyz.npy\",\n",
    "        \"output_size\": 8,\n",
    "        \"noise_size\": 8,\n",
    "        \"noise_type\": 1,\n",
    "        \"ntest_samples\": 10000,\n",
    "        \"nepochs_dump_pred_metrics\": 250,\n",
    "        \"nepochs_dump_plots\": 1000,\n",
    "        \"nepochs_dump_models\": 5000,\n",
    "        \"nepochs_max\": 30001,\n",
    "        \"batch_size\": 200,\n",
    "        \"do_concatenate_disc\": False,\n",
    "        \"do_concatenate_gen\": False,\n",
    "        \"do_batch_normalization_disc\": False,\n",
    "        \"do_batch_normalization_gen\": False,\n",
    "        \"do_soft_labels\": False,\n",
    "        \"do_noisy_labels\": False,\n",
    "        \"do_tanh_gen\": False,\n",
    "        \"nepochs_decay_noisy_labels\": 3000,\n",
    "        \"use_ptetaphi_additionally\": False,\n",
    "        \"scaler_type\": \"\",\n",
    "        \"optimizer_disc\": \"adadelta\",\n",
    "        \"optimizer_gen\": \"adadelta\",\n",
    "        \"beefy_generator\": False,\n",
    "        \"depth_gen\": 0,\n",
    "        \"width_gen\": 0,\n",
    "        \"depth_disc\": 0,\n",
    "        \"width_disc\": 0,\n",
    "        \"add_invmass_disc\": False,\n",
    "        \"fix_delphes_outputs\": False,\n",
    "        \"use_delphes\": False,\n",
    "        \"use_mll_loss\": False,\n",
    "        \"loss_mll_weight\": 0.0001,\n",
    "        }\n",
    "\n",
    "# for delphes:\n",
    "params.update({\n",
    "    \"use_delphes\": True,\n",
    "    \"fix_delphes_outputs\": True,\n",
    "    \"do_soft_labels\": False,\n",
    "    \"do_noisy_labels\": False,\n",
    "    \"nepochs_decay_noisy_labels\": 2000,\n",
    "    \"input_file\": \"/home/users/namin/2017/gan/DY-GAN/delphes/data_Nov10.npa\",\n",
    "    \"output_size\": 19,\n",
    "})\n",
    "params.update({\n",
    "    \"use_mll_loss\": True,\n",
    "    \"loss_mll_weight\": 0.001,\n",
    "})\n",
    "print params\n",
    "    \n",
    "# change tag for provenance\n",
    "params[\"tag\"] = \"vtest\"\n",
    "\n",
    "gan = GAN(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 [D loss: 0.27375331521, acc.: 0.00%] [G loss: 4.82521009445] [mll=-1.000+--1.000]]\n",
      "500 [D loss: 0.180833041668, acc.: 0.00%] [G loss: 4.00779771805] [mll=73.657+-8.009]\n",
      "750 [D loss: 0.236024320126, acc.: 0.00%] [G loss: 4.49160575867] [mll=74.564+-4.120]\n",
      "1000 [D loss: 0.326397180557, acc.: 0.00%] [G loss: 3.35379767418] [mll=72.854+-5.321]\n",
      "1250 [D loss: 0.241404145956, acc.: 0.00%] [G loss: 4.51607465744] [mll=75.081+-5.253]\n",
      "1500 [D loss: 0.205980539322, acc.: 0.00%] [G loss: 3.92915582657] [mll=74.064+-3.883]]\n",
      "1750 [D loss: 0.446846187115, acc.: 0.00%] [G loss: 2.90012693405] [mll=72.277+-3.328]]\n",
      "2000 [D loss: 0.37183535099, acc.: 0.00%] [G loss: 3.08211493492] [mll=93.434+-5.432]]]\n",
      "2250 [D loss: 0.447727739811, acc.: 0.00%] [G loss: 2.83144044876] [mll=96.215+-4.357]\n",
      "2500 [D loss: 0.32584503293, acc.: 0.00%] [G loss: 2.61468982697] [mll=87.940+-4.792]]\n",
      "2750 [D loss: 0.323731690645, acc.: 0.00%] [G loss: 2.3019323349] [mll=103.866+-10.026]]\n",
      "3000 [D loss: 0.424069344997, acc.: 0.00%] [G loss: 1.74954712391] [mll=89.762+-5.633]\n",
      "3250 [D loss: 0.443062603474, acc.: 0.00%] [G loss: 2.35834431648] [mll=87.578+-4.827]]\n",
      "3500 [D loss: 0.450516492128, acc.: 0.00%] [G loss: 1.91229259968] [mll=95.093+-5.345]\n",
      "3750 [D loss: 0.417168855667, acc.: 0.00%] [G loss: 2.3370923996] [mll=86.010+-5.965]]\n",
      "4000 [D loss: 0.50798791647, acc.: 0.00%] [G loss: 2.22972083092] [mll=102.386+-12.301]]\n",
      "4250 [D loss: 0.488920450211, acc.: 0.00%] [G loss: 2.46605706215] [mll=91.478+-5.756]\n",
      "4500 [D loss: 0.418380379677, acc.: 0.00%] [G loss: 2.73621463776] [mll=83.745+-6.369]\n",
      "4583 [D loss: 0.298161506653, acc.: 0.00%] [G loss: 2.79538822174] [mll=84.716+-6.277]"
     ]
    }
   ],
   "source": [
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9034bb03d0>]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzt3Xl8VNX9//HXSQIJJCRsYQtL2GSvAlEpbiyKO6LgvuDSqq11qW1tta1+q3Wr/rRaqxYVRUVREQVBREVARUUTRHZkky2BhC0LkECS8/vjDKssIbPcmZv38/HgMZOZO/d+HJP33Dn3LMZai4iI+Fec1wWIiEh4KehFRHxOQS8i4nMKehERn1PQi4j4nIJeRMTnFPQiIj6noBcR8TkFvYiIzyV4XQBA48aNbWZmptdliIjElJycnI3W2vQjbRcVQZ+ZmUl2drbXZYiIxBRjzKqqbKemGxERn1PQi4j4nIJeRMTnFPQiIj6noBcR8TkFvYiIzynoRUR8TkEvUhPkL4aFE7yuQjyioBfxuxUz4MXT4e2r3X2pcRT0In624H0YPQzSWkKDtjDxDti1w+uqJMIU9CJ+9d1L8M610KInXPchnP9v2LwCPn/c68okwhT0In5jLUx/BCbdCcecCVe/D3UbQrt+cOwVMPPfsGGB11VKBCnoRfyksgIm/QGmP+xC/dLXoXbdvc8P+ickpcGE29y2UiMo6EX8orwMxl4H2S/BSbfDkGchvtb+2yQ3grMegXXZkD3Smzol4hT0In5QWuQuui4c787az7gfjDn4tj0uhvYD4NN/QOG6yNYpnlDQi8S6knwYdR78NBOGPA99bz389sbAuU9AZTl8+CfXpi++pqAXiWVbfoKRZ0LBj3D5GDju8qq9rmFb6H83LJkEiz4Ia4niPQW9SKxaPw9eGgTbN8PwCXDMoKN7fZ9boFkPd1ZfWhieGiUqKOhFYtFPM+Hlc8DEw/UfQasTjn4f8Qlw/tOwLd+114tvKehFYs2iifDahVCvGdzwMTTpUv19ZfSCE3/jeuqs/iZ0NUpUUdCLxJKcUW7OmmY94LqPoH6r4PfZ/x5IawUf3O66aIrvKOhFYoG1buqCD26Ddv1dm3xyo9DsOzHF9cIpWAwznwrNPiWqKOhFol1lJXz0F/jsAdcH/vIxUDs5tMc4ZhB0uwg+fww2Lg3tvsVzRwx6Y8xIY0y+MWb+Po81NMZ8YoxZGrhtEHjcGGOeNsYsM8bMNcb0CmfxIr5XvhPG/RpmPQ99fgsXjoCE2uE51tmPQq06rgmnsjI8xxBPVOWM/hXgrAMe+wsw1VrbEZga+BngbKBj4N+NwHOhKVOkBiorgTcvhflj4fT/gzMfgrgwfglPaeJG1a6aCXNeD99xJOKO+Ftjrf0c2HzAwxcAowL3RwFD9nn8Vet8A9Q3xjQPVbEiNca2TfDqYFgxHQY/Ayf//tBTGoRSz6uhzcnw8d+geEP4j+eVhRNq1Aye1T09aGqtzQvcXw80DdzPANbss93awGMiUlVbV7vRrhsWwKWjodfVkTu2MW7e+l073HUBP/r6v67n0ktnwqqvva4mIoL+HmittcBRT5ZhjLnRGJNtjMkuKCgItgwRf8hf5AKoJB+ufg86nxP5Ghp3hFP/BAvGwY9TIn/8cMoeCVPugU7nunEIr19UI5ZXrG7Qb9jdJBO4zQ88vg7Yt2Nvy8BjP2OtHWGtzbLWZqWnp1ezDBEfWT0LRp4FthKunwxt+npXy0l3QHpnN7d9WYl3dYTSD2Ng4p3Q8Uy4+BW36laDTHjjElj6qdfVhVV1g34CMDxwfzgwfp/Hrwn0vukDFO7TxCMih/LjFHj1AqjbyI12bdrN23oSarvpEQrXwLSHvK0lFBa8D+//BtqeApe86v77UprA8InQ+Bh48zJYPMnrKsOmKt0r3wS+BjoZY9YaY24AHgHOMMYsBU4P/AzwIbACWAa8APw2LFWL+MmcN+DNyyG9E1w/BRq08boip/WJkHUDzHoO1uV4XU31/TgF3r0BWh4Pl70JtZL2PpfcCIZ/AM2PhbevgfnjvKszjIyNgrmos7KybHZ2ttdliETezKfgk3vdeq6Xvg6J9byuaH+lhfDMCZCcDjdO+/mKVdFuxQwYfbGbD2j4BLeM4sGUFrkmnDWz4IJnqz7ds8eMMTnW2qwjbaeRsSJeqKx0XRg/udeNSL3i7egLeXDBeM5jsGEefPOs19UcndWz3DelRu3dhe1DhTxAUipc9S5knuKaeLJfjlydEaCgF4m0il0w/rfw1X/ghBth6EuQkOh1VYfWdTB0Pg+mPQybV3pdTdXkfu+WVqzXDK5+H+o2PPJraifDFW9BxzNg4h0w63/hrzNCFPQikbRzG4y5An54E/r/Fc7+V3hHu4bK2f+CuASYdGf0Lz24YaGbxjmpvmuuqdf0yK/ZrVYd14TW+TyYfBd8+e/w1RlBMfAbJuIT2ze7njXLPoXznoTT7orMaNdQSMuA0++D5Z/B3Le9rubQNi1373FCEgwfD2ktj34fCYmu+2X3ofDpfTD90ej/cDuCBK8LEKkRCte5wTmbV8DFo1xzSKzJuh7mvgVT7oYOp4dumuRQ2boaRg124xCumQgN21V/X/G14KIXID4Rpj8E5aUw8N7Y+WA+gM7oRcKtYIlb27VwnbvgF4shDxAXD+c/5XrifPw3r6vZX1EejDofdhbDNe+7rqrBiouHC/4Lva+DL59wI2pj9MxeQS8SLta6ybNGngUVO+G6SdD2VK+rCk7Tbm7U7A9vuAnXosG2ja65ZttGuGqcW30rVOLiXDPbib9xvY4m3RmTUzgr6EXCIXcOvHKemzyrXnO4YYoblOMHp/4JGraHD+5wk595accWeG2Ia7a54i1oecQu5UfPGDjrYTeDaPZImPA7qKwI/XHCSEEvEkpFefD+b2FEP7c037lPwE2fB9deHG1qJbkZLreshBmPeldHWTG8Psw1jV32OmSeHL5jGQMD74N+98Cc0TDuRtdNNkboYqxIKOzcDl8/47rjVe6CvrfCqX88/CCdWNb2VDjuKpj5NHQfBs26R/b4O7fDG5e5/vKXvuYuDoebMdDvz65Xzqf3uQu0w14O34pfIaQzepFgVFa67obPZMG0B6HDQLjlWxj0gH9DfrdBD0CdBm7B8kg2ZZSXwVtXuZWwLhoBnc+N3LEBTr4DznoUFk90dewqjezxq0FBL1Jdq2fBS6e7NV2TG8O1H7qzy4Ztva4sMuo2dOvMrsuB716MzDErdsHY62H5VBj8NPQYFpnjHqjPzXDev2Hpx265x53bvKmjihT0Ikdr62p45zoYOQiKcmHIc/Dr6ZB5kteVRV73oa7ZZOr9ULg2vMeqrHDz0Cye6Ebq9romvMc7kqzr3P/7lZ+7awVlxd7WcxgKepGqKiuGT/8B/8mCJZPhtD/DrTlw3BWxMY1BOBgD5/4/N0hp0h/C18/cWjf/zLx33EXRE28Kz3GO1nGXw9AX3ayXr10IO7Z6XdFB1dDfTpGjUFkBOaPg6V5u4Ey3IXBrNvS/x02EVdM1yHTvxY8fwcLxR9z8qFnr1q+d/arr2nnKnaE/RjC6D4VLRrkuta8OdlNdRBkFvcjhrJgB/zvNXXBs2BZ+9Zm7AFidOVT87MTfuHECk+8K/Vnt1Pth1vPQ57duIrho1OV8uOwNyF8Mr5zr1vyNIgp6kYPZtNzNZf7qYDfkf9hIt/pTy95eVxad4hPc0oPbCuDT/wvdfj9/3H2L6n0tnPlQdM81c8wguPJt2PITvHyOu34TJRT0IvvasQU+uhv+e4K7yDbwXvjdd+7reTSHTDRocZw76855GVZ9Ffz+vn4WPnsAfnEpnPtkbLz/7fq5+YyK18PLZ7sL91FAQS8CrtverP/B0z3hm+fcBdZbZ8Mpf9h/jVE5vP73QFpr+OB219+9unJecbNkdhnslvaLpYvdbfq6idV2bHFn9puWe12Rgl5qOGvd4tHP9XXty816wM1fwOD/HN2CFeLUTobznoCNP8KXT1ZvHz+85ebR6XCGW30rPgYH8LfMcouO79zmwr7gR0/LUdD7hbVu/o1Jf4jJ2fU8sXslojcucT1rLnsTrpkQ2tkPa6KOZ7hpEb74f24emqOxcILrK595sht8FgPTCxxS82Ph2kmu6+kr58CGBZ6VoqD3ixXT3KIQ370IH/81ZufNjoiSAnfG+PxJkDsbznwYfvsNdD4nNtqBY8FZj0Ctuu59ruqJx9JP3KjXjN5w+Ri3rF+sa9oVrvsQ4mq53ji533tShoLeD6yFz/4JqS3dYtPfPAszn/K6quhTXuYmHftPL9cn+/hfw21z4Je/je0zx2iUkg5nPgirv4LZo468/cov3LwxTbvCle9AYkr4a4yUxh1d2NeuB6MugDXfRrwEBb0fLJns5hs57S432VL3YW52ve9He11ZdLAWFrwPzxzv3pfWv3Rn8Of8y83XIuFx3JWQeQp8cp/rhXIoa76FNy51A6+ueg/q1I9YiRHTsK0L++RGrrnwp5kRPbyCPtZVVrpZExu22zsUf8hz0K4/TLgVlnzkdYXeyv3eXQx7Z7i7UHj1e66vc/oxXlfmf8a4ib/KS2Hynw++Te4cN09MvaZwzfjoW4c2lOq3chPfpbaA14fC8mkRO7SCPtYtfB82zId+d7sFjcE1Q1z6GjT/BbxzrZtlsaYpK9m7AMjGH91ycDd9Ae0HeF1ZzdK4A5z2J/d7umTy/s/lL3Jnt0mp7iJ4vWbe1BhJqc1d2Ddq777F/DglIodV0MeyinKY9hCkd3YDevaVWA+ueMedPbxxiRuaXVPsXl7uhzHQ9za4bTZkXR+b3fT8oO/t0KQrTPrj3hkeNy2HV4dAfG13Jl+/lbc1RlJKuut62aQLjLkSFk0M+yGDCnpjzO+NMQuMMfONMW8aY5KMMW2NMbOMMcuMMW8ZY3SVK1zmvQ2blrpBKnHxP38+JR2uHudWxHn9ovBPIxsNSvLdWq15P7iJpmrCAiDRLqE2nP8UFK1znQa2rnaLeVfsdCHfqL3XFUZe3YYwfAK0O82d5YdZtYPeGJMB3AZkWWu7A/HAZcCjwJPW2g7AFuCGUBQqByjfCdMfgWa/cKMHD6VBphuSXVYMr10UlTPrhczWNW7Y+eYVbqHoLud7XZHs1uoEOP5XbvTxyLOhtMiNHm3S2evKvJOU5v42M8I/f1KwTTcJQB1jTAJQF8gDBgBjA8+PAoYEeQw5mDmvw9ZVMODvR+773awHXP6mm2zpjUvdept+s2m5C/mSfHfBVW3x0WfgvVCvuWtau2qsG1AkEVHtoLfWrgMeB1bjAr4QyAG2WmvLA5utBTKCLVIOsKsUZjwGLU9woxCrIvNkt0DC2u/cBdoYWsH+iNbPh5Fnwa7tcO1EaN3H64rkYJJS4frJboqJVid4XU2NEkzTTQPgAqAt0AJIBs46itffaIzJNsZkFxQUVLeMmil7JBTnwoC/Hd1Izq6D3WpAS6e4Saf8MHp2bbYbcRiXANdN1llitGuQWTPb5D0WTNPN6cBKa22BtXYXMA44CagfaMoBaAmsO9iLrbUjrLVZ1tqs9PT0IMqoYcpK3PzcbU91F3KO1vE3uK6Yc0bD1H+Evr5IWvm5u6hXpz5c/xGkd/K6IpGoFEx/s9VAH2NMXWAHMBDIBqYBw4AxwHAgDGuL1WDfjnCLO/QPYtTraX+Gkg1udsHkJm4KgFiz5CN4+xo34vDq9yPSc0EkVgXTRj8Ld9F1NjAvsK8RwJ+BO40xy4BGwEshqFPALdE28ynoOAhan1j9/RgD5zzueutMuRvmvhO6GiNh/rvw1pWuH/K1HyrkRY4gqBEk1tr7gPsOeHgFoCst4fDNs1C6NTTrZsbFw0UvwOgt8P7Nrl9vh4HB7zfccka56wtt+roZDpNSva5IJOppZGys2LbJLa3WZbBbsi0UaiXBZaMhvQu8dbWbGC2affWMW6S7w0C4cqxCXqSKFPSx4qunYGeJGwUbSklprk9zcmMYfTFsXBba/YeCtTDtYTfPftcL3AIhtet6XZVIzFDQx4Li9TBrBPS42LVLh1q9Zm6QEcZNMlWUF/pjVJe1MOWvMOMRN+3t0JGaO17kKCnoY8EXT7h5Qfr9JXzHaNTendnv2Ayjh7kLv16rrHBNNd/8F068GQY/o4nJRKpBQR/ttq6BnJeh55XhH2jSoqeb3rhgCYy5wo3A9Ur5Tnj3V24lqFPvckvTxenXVaQ69JcT7T5/zN2eeldkjtd+AFz4PKyaCe/e4M6qI23XDtd9csE4OON+GPBXreUqEgQFfTTbtBy+fx16XxfZ+bp7DHNLEi6eCJPujOxUCWXFbsWhpZ+4xUJOuj1yxxbxKTV4RrMZj7qFGU65M/LH7nNzYPTsE5DSDPrfHf5jbg9cH8id4/r4/+Li8B9TpAZQ0Eer/MUw923oe6t3S6wNvBe25bseLynpbj7xcCle73r8bFoOl74Onc8J37FEahgFfbSa/hDUToGT7vCuBmPgvKdg20a3DFzdxtAtDMsL7F5xqHiDW7i7Xb/QH0OkBlMbfTTK+wEWjneTjSU38raW+AQY9jK0OhHG/drNGBlKG5e6ueS3b3IrDrXrF9r9i4iCPip99iAk1Yc+UTKrZO26boWqhu3hzSvcB1EorJ/nQr5iJ1w7SYtRiISJgj7arPnWLQxy0m1unvVoUbehW98yKc31itm8Mrj9rfnWLRiSkOgWDGnWIzR1isjPKOijzWcPQHK6GwkabdIy4OpxULnLXTgtya/eflZMh1eHQN1GbsGQxh1DWqaI7E9BH01WzHBt4CffCbWTva7m4NI7wRXvuF4yo4e5fu9HY/GHbvK0Bm3guo+gfuvw1Ckieyjoo4W1MO1BqNcCsq73uprDa3U8XPKqW5R7zJVQXla11819B966yjXTXDsJ6jUNb50iAijoo8eyT2HNLDj1j26e+Gh3zCC44L+wcga8dzNUVh5+++yRrtdOm75wzXjX5i8iEaF+9NHAWtc2X78N9Lza62qq7rjL3YCqT+511xXOfvTgc9LMfMpt0/FMuGQU1KoT+VpFajAFfTRY9IHrsjjkudiba73vbe6i7NfPQEoT941kt93NUZ8/Bt0uggv/F3v/fSI+oKD3WmUFTHsIGnWEHpd4Xc3RMwbOeMCF/e4eQ72Hu6acKXfDrOeh1zVw3r/dOrUiEnEKeq/NHwcFi2DYyNhdVCMuzrXXb98EE++AOg3gx49gzmjocwuc+aCmGRbxUIwmi09U7HJz2jTtDl0v9Lqa4CTUdj1xRp0PbweuM/S7G077s0JexGOxH/TWxm6Q/PAmbF7hFrv2w+pJiSlw5TtuZahOZ8OJN3ldkYgQ690rl0+DVwe7WQ9jTXkZzPgXZPR2oegXyY3d5GQKeZGoEdtBv2MLrPkO/ncqrP7G62qOTs4oKFwDA/4Wu99IRCQmxHbQd78IfvWpm13xlXPh62cju+xdde3cDl88Dm1Ognb9va5GRHwutoMeoFl3+PU0Nxhnyt0w9rqjn38l0r570S3T11+LXotI+MV+0IObzvfS1+H0/3MLdrwwEAqWeF3VwZUVw5dPQvsBkHmS19WISA0QVNAbY+obY8YaYxYbYxYZY35pjGlojPnEGLM0cNsgVMUeVlwcnPx7uPp915/7hQGuj3q0+eY52LHZtc2LiERAsGf0TwEfWWs7A8cCi4C/AFOttR2BqYGfI6fdaXDzF9Ckq2vG+ehu1189GmzfDF/9Bzqd63rbiIhEQLWD3hiTBpwKvARgrd1prd0KXACMCmw2CgjDatJHkNrCTYN7wk3wzbPwynlQlBfxMn7m62dc003/e7yuRERqkGDO6NsCBcDLxpjvjTEvGmOSgabW2t2puh446KTjxpgbjTHZxpjsgoKCIMo4hITacM6/YOhLsH6u64L505ehP05VlRTAN8+7nkLNuntXh4jUOMEEfQLQC3jOWtsT2MYBzTTWWgsctL+jtXaEtTbLWpuVnp4eRBlH0GMY/PozSEqFUYNh5tPedMH88kko3+GmBRARiaBggn4tsNZaOyvw81hc8G8wxjQHCNxWc2HREGrSxXXB7HwufPJ3ePsaKC2K3PGLcl2XymMv1/qoIhJx1Q56a+16YI0xplPgoYHAQmACMDzw2HBgfFAVhkpSqpt0a9A/YfEkeKE/5C+KzLE/fxxsJZx2V2SOJyKyj2B73dwKjDbGzAWOAx4CHgHOMMYsBU4P/BwdjIG+t8LwCe6M/oUBMG9seI+55SeY/aqbk71BZniPJSJyEEHNXmmtnQNkHeSpgcHsN+wyT4abPnfdL9+9wa3VOujB8Kx+NONfYOL2X3lJRCSC/DEytjpSm8PwD9zCGN+OcHPlFK4L7TE2LnVTER//K9flU0TEAzU36AHia8FZD8HFr0D+QtcFc8WM0O1/+sOQUMeN2BUR8UjNDvrdul3oumDWbQSvDYEvngi+C+b6+TD/XehzM6SEsfuoiMgRKOh3S+/kwr7rEJj6DxhzJZQWVn9/0x6CxDR38VdExEMK+n0lprhFus96BJZOgRH93Jn50VqXA0smQd/fuYWyRUQ8pKA/kDHQ5zdurpxdO+DF0+GHMUe3j88ehDoN3X5ERDymoD+U1n1cF8yM3vDeTTDx926d1yNZ9RUsn+ouwCbWC3+dIiJHoKA/nJQmcM146HsbZI+El8+GrWsOvb21MPUBSGnqulSKiEQBBf2RxCfAoAfgkteg4EfXBXPZ1INvu2IarP4KTvmjW8dWRCQKKOirqutguHE61GsGrw+FGY9BZeXe562Fz/4Jaa2g9/BD7UVEJOIU9EejcQf41adu6uNp/4Q3L4MdW9xzSya73jan3QUJid7WKSKyDwX90aqdDBe9AOc8Dss/g/+dBrlzYNqD0LCdm4pYRCSKKOirwxg44ddw3WSoLHdTHm+YD/3ucdMqiIhEEQV9MFod77pgth8Arfq4ZQJFRKJMUNMUC5DcGK56112MNcbrakREfkZn9KGikBeRKKWgFxHxOQW9iIjPKehFRHxOQS8i4nMKehERn1PQi4j4nIJeRMTnFPQiIj6noBcR8TkFvYiIzynoRUR8LuigN8bEG2O+N8ZMDPzc1hgzyxizzBjzljGmdvBliohIdYXijP52YNE+Pz8KPGmt7QBsAW4IwTFERKSaggp6Y0xL4FzgxcDPBhgAjA1sMgoYEswxREQkOMGe0f8buAvYvUp2I2CrtbY88PNaICPIY4iISBCqHfTGmPOAfGttTjVff6MxJtsYk11QUFDdMkRE5AiCOaM/CRhsjPkJGINrsnkKqG+M2b1yVUtg3cFebK0dYa3NstZmpaenB1GGiIgcTrWD3lp7t7W2pbU2E7gM+MxaeyUwDRgW2Gw4MD7oKkVEpNrC0Y/+z8CdxphluDb7l8JwDBERqaKQLA5urZ0OTA/cXwGcEIr9iohI8DQyVkTE5xT0IiI+p6AXEfE5Bb2IiM8p6EVEfE5BLyLicwp6ERGfU9CLiPicgl5ExOcU9CIiPqegFxHxOQW9iIjPKehFRHxOQS8i4nMKehERn1PQi4j4nIJeRMTnFPQiIj6noBcR8TkFvYiIzynoRUR8TkEvIuJzCnoREZ9T0IuI+JyCXkTE5xT0IiI+p6AXEfG5age9MaaVMWaaMWahMWaBMeb2wOMNjTGfGGOWBm4bhK5cERE5WsGc0ZcDf7DWdgX6ALcYY7oCfwGmWms7AlMDP4uIiEeqHfTW2jxr7ezA/WJgEZABXACMCmw2ChgSbJEiIlJ9IWmjN8ZkAj2BWUBTa21e4Kn1QNNQHENERKon6KA3xqQA7wJ3WGuL9n3OWmsBe4jX3WiMyTbGZBcUFARbhoiIHEJQQW+MqYUL+dHW2nGBhzcYY5oHnm8O5B/stdbaEdbaLGttVnp6ejBliIjIYQTT68YALwGLrLVP7PPUBGB44P5wYHz1yxMRkWAlBPHak4CrgXnGmDmBx+4BHgHeNsbcAKwCLgmuRBERCUa1g95a+yVgDvH0wOruV0REQksjY0VEfC6YphsRiQEbikp5fsZycrfu4PaBx9C1RarXJUmEKehFfGpDUSnPTV/OG9+upqLSkpKYwKeLvmT4LzP5/RkdqZdUy+sSJUIU9CI+c2DAD+vVklv6dyC1TgKPTVnCy1+tZOLcXP5+XlfO+0VzXAc68TPjxjR5Kysry2ZnZ3tdhkhMO1TAt25Ud7/t5qzZyt/en8f8dUWc3KEx91/QjXbpKR5VLcEwxuRYa7OOuJ2CXiS2VTXg91VRaRk9axWPTVlC2a5KbjqtHbf070BSrfgIVi7BUtCL+Fx1Av5A+cWlPPzhYt77fh2tGtbhH4O7MaCzpqeKFQp6EZ/KLyrluRnLeWPWasorLUN7ZfC7/h2PKuAP9PXyTfx9/HyW5ZcwqGtT7hvcjYz6dUJYtYSDgl7EZ8IR8PvaWV7JS1+u5OmpSwG4bWBHbji5LbUTNNwmWinoRXwi3AF/oLVbtnP/Bwv5eOEGOjRJ4YELuvPL9o3CciwJjoJeJMZFOuAPNHXRBu6bsIC1W3ZwYc8M7jmnC+n1EiNybKmaqga9+tGLRBmvA363gV2a0rd9Y56dvoznZyzn00Ub+NOZnbjyxDbEx6nvfSzRGb1IlIiWgD+Y5QUl3Dt+PjOXbaJHRhr/HNKdY1vV97qsGk9NNyIxIr+olOdnrGD0rFWUV1ou6pnB7wZ0oE2jZK9L24+1lolz83hg4kIKSsq48sTW/GlQZ9LqaioFr6jpRiTKxUrA72aM4fxjW9CvUzpPfrKUV75ayeR567nnnC5c1CtDUylEMZ3R+8SuikpmLttI4Y5dZNSvQ/P6dWhaL5GEeHWNizaxFvCHsiC3kL+/P5/Zq7dyQmZDHhjSnU7N6nld1kEVFJcxf10h89YVMn9dIQvziqhftxZZbRrSq00Dsto0oEUMjhtQ000NsTC3iHdnr2X8nHVsLNm533NxBpqmJtGifh2ap7nbFmlJNK9fx30YpCXRMLm2zsQixC8Bv6/KSss7OWt4ePJiSkrLueHkttw2sCPJid41FuQXlTJvT6gXMX9dIeuLSvc8365xMl1apLJl207mrNnK9p0VALRIS9rl5QqUAAAKlUlEQVQT+lmZDencrF7Unygp6H1sY0kZ4+fkMjZnLYvyiqgVbxjQuQlDe7Uks3EyuVt3kLu1lLxCd5u7dYe7X1jKzvLK/faVmBD3sw+CFoFvBBn1k2ieVsfTP9qqKiuvYFtZBSWl5ZSUuX/bd5YDEB9niDcGY4y7Hwdxgftxex4zxJlDPW727iMO4g/YJs5w2A9LPwb8gTZv28mjkxfzVvYamqclcd/5XTmzW7OwnkRYa9lQVLYn1BcEbvOLywAwxoV6j4w0ugf+dWuRut/0zOUVlSzKKyZn1WayV20hZ9UW8grdh0Ld2vEc16o+vds0oHebBvRs3YC0OtF1PUJB7zNl5RV8tiifd2evZfqSAsorLb9omcbQXi05/9gWNEyufcR9WGvZtG0neVtLWbc7/Le6D4C8wIdDfnEplQf8SqQmJbgPgfp1aBEI/xb1k2iR5h5rmpp01KMnrbWUlVdSUlbOtrJyikvd7badu+9XUFK2i5KyCraVlbsA3+lut5XtDfPd93dVePt7HGfcB4oxZp8PAvdYSVk5lRZfBvyBclZt5q/vzWfx+mL6dUrnH4O7heS/11pLXmHpfoE+b10RG0tcqMcZaJ+eQo+MNLplpNEjI42uLVJJqcZJSu7WHS70f9pMzuotLMwtotK6D45jmtSjd2YDerduQFZmA1o3rOvpN2IFvQ9Ya5m7tpCxOWv5YG4uW7fvokm9RC7slcHQXi05pmno20N3VVSyoaiUvMLSA74Z7L2/Zfuu/V5jDKSnJO75FtAstQ4W64K7rILi3YEcONveFgjs8gM/UQ4huXY8KUkJJCcmUC/R3e57PyUpgZTEhMB2tUhJjCclsRZ1aruZGCutpbLSUmEtlZUEbi0Vex5ztxWVFmv52eN7t2XvY3se5xDbuvuVFuomxnPFCa19HfD7Kq+oZNTXq3ji4yXsqrTc0q8DN53WrsozY1prWbd1x55ml93t6pu2uabJOAMdm9QLnKWn7gn1urXD881zW1k5c9ZsJWfVFrJXbeH7VVsoLnPfFhunJNK7TX2y2jSkd2YDurVIJTEhcjOAKuhj2PrCUt77fh3vzl7LsvwSEhPiGNStGUN7ZXByh8aetxtu31m+54Mgb2spuYEPgrxC901hfWEp8cbsCeHkxIRA+B4krJMSSK69T1gnutuUwGvr1oonToNzYtL6wlL+OWkhE+fmkdmoLvdf0J1Tj0nfbxtrLWu37NgT6PPWFbIgt4jNgVCPjzN0bJKyX/NL1+apez7EvVBRaVmaX0z2T1uYHQj/1Zu3A1A7IY5jW6YF2vob0rtNgyp9264uBX2M2bGzgo8XrmdszlpmLttIpYWsNg0Y2rsl5/6iOala9k1i1BdLC7h3/AJWbtzGuT2ac2b3ZizMdWfr83ML2Rr4hpgQZzimab1AqKfSPSONLs1TY2KO/PyiUmav3kL2Ty74F+QW7mlObNc4md5tXFNP7zYNaNc4JWQnLwr6GGCtJXvVFsZmr+XDeXkUl5WTUb8OF/XK4KJeLWnbuGZ81Rf/KyuvYMSMFTwzbRll5ZXUijd0auZCvVsL16beqVm9mAj1qijdVcHctYVkr9rM7MBF3t1NnvXr1qJX6wZ7LvIe27J+tb+hKOij2JrN2xk3ex3jvl/Lqk3bqVs7nrO7N2do7wz6tG2kpgrxrQ1FpRQUl9GxaUpE27K9Zq1lxcZt5Py0hexVm8lZtYXlBdsA+Nu5XfjVKe2qtd8aMTJ25rKNTF2UT/O0JJrXT6J5WhLN0qJzoFBJWTmT5+UxNmcts1ZuBqBv+0bcNqAjZ3VvFhNdGEWC1TQ1iaapSV6XEXHGGNqnp9A+PYVLjm8FuC6ps1dtoXPz8A8yi+l0WbqhmDHfrd4z4GG3OAPp9RJplub6hTdLcx8CzdPqBD4M3C9brTB/GFRWWr5esYl3c9Yyef56duyqILNRXf5wxjFc2CuDlg28n6xKRLzRMLk2p3eNzLKNMd90Y62luKycvEDXv/WFpeQWlrK+0PUCyQv0Ed92wIfBni6BgQ+APR8GgcFDzQJnHtVZXWdFQQnvzl7Le7PXkVtYSr3EBM47tgXDemfQq3UDjUQVkZDwtOnGGHMW8BQQD7xorX0kHMcJHIvUpFqkNqt12Hk2ikt37Qn+9YERo+sLS8krKmV5QQkzl23c0zd2775dP9nm+3wjOPDbQZPURBIT4incsYuJc91o1e9XbyXOwCkd0/nLOV0Y1LWpby4yiUjsCXnQG2Pigf8CZwBrge+MMROstQtDfayjUS+pFvWSah12kFFx6S4X/oWlgW8GO/b8vHLjNr5avoni0vKfva5xSiJFpbvYWV7JMU1TuPvszgzpmVEj2yJFJPqE44z+BGCZtXYFgDFmDHAB4GnQV8XuD4OOh/kwKCkrD4T/jj0fCHmFO6hTK4ELe2bQPSNVTTMiElXCEfQZwJp9fl4LnBiG43giJTGBDk1S6NAkxetSRESqxLM+iMaYG40x2caY7IKCAq/KEBHxvXAE/Tqg1T4/tww8th9r7QhrbZa1Nis9Pf3Ap0VEJETCEfTfAR2NMW2NMbWBy4AJYTiOiIhUQcjb6K215caY3wFTcN0rR1prF4T6OCIiUjVh6Udvrf0Q+DAc+xYRkaMTXRPCiIhIyCnoRUR8TkEvIuJzUTGpmTGmAFhVzZc3BjaGsJxYp/djf3o/9tJ7sT8/vB9trLVH7J8eFUEfDGNMdlVmb6sp9H7sT+/HXnov9leT3g813YiI+JyCXkTE5/wQ9CO8LiDK6P3Yn96PvfRe7K/GvB8x30YvIiKH54czehEROYyYDnpjzFnGmCXGmGXGmL94XY9XjDGtjDHTjDELjTELjDG3e11TNDDGxBtjvjfGTPS6Fq8ZY+obY8YaYxYbYxYZY37pdU1eMcb8PvB3Mt8Y86YxxvdLwcVs0O+zZOHZQFfgcmNMV2+r8kw58AdrbVegD3BLDX4v9nU7sMjrIqLEU8BH1trOwLHU0PfFGJMB3AZkWWu74yZevMzbqsIvZoOefZYstNbuBHYvWVjjWGvzrLWzA/eLcX/EGd5W5S1jTEvgXOBFr2vxmjEmDTgVeAnAWrvTWrvV26o8lQDUMcYkAHWBXI/rCbtYDvqDLVlYo8MNwBiTCfQEZnlbief+DdwFVHpdSBRoCxQALweasl40xiR7XZQXrLXrgMeB1UAeUGit/djbqsIvloNeDmCMSQHeBe6w1hZ5XY9XjDHnAfnW2hyva4kSCUAv4DlrbU9gG1Ajr2kZYxrgvvm3BVoAycaYq7ytKvxiOeirtGRhTWGMqYUL+dHW2nFe1+Oxk4DBxpifcE16A4wxr3tbkqfWAmuttbu/5Y3FBX9NdDqw0lpbYK3dBYwD+npcU9jFctBrycIAY4zBtb8ustY+4XU9XrPW3m2tbWmtzcT9XnxmrfX9WduhWGvXA2uMMZ0CDw0EFnpYkpdWA32MMXUDfzcDqQEXpsOywlQkaMnC/ZwEXA3MM8bMCTx2T2ClLxGAW4HRgZOiFcB1HtfjCWvtLGPMWGA2rrfa99SAEbIaGSsi4nOx3HQjIiJVoKAXEfE5Bb2IiM8p6EVEfE5BLyLicwp6ERGfU9CLiPicgl5ExOf+P1k1/TfDmiZ1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gan.d_epochinfo[\"mass_sig\"])\n",
    "plt.plot(gan.d_epochinfo[\"mass_mu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
