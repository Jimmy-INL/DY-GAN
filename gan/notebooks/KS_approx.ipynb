{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation of the KS test statistic\n",
    "\n",
    "This notebook contains the test for an analytic approximation for the Kolmogorov-Smirnov test statistic based on soft maxing and exploiting the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_approx(a,b):\n",
    "    \"\"\"Takes in two lists of numbers, a and b, and returns an approximation to the KS test statistic between them\"\"\"\n",
    "    pdf_scale = 50\n",
    "    max_scale = 200\n",
    "    \n",
    "    c = np.append(a,b)\n",
    "    count_gtr = lambda num, all_nums:  np.sum(1/(1+np.exp(pdf_scale*(a-x))))\n",
    "    a_pdf = np.array([np.sum(1/(1+np.exp(pdf_scale*(a-x)))) for x in c])/a.shape[0]\n",
    "    b_pdf = np.array([np.sum(1/(1+np.exp(pdf_scale*(b-x)))) for x in c])/b.shape[0]\n",
    "    #print(c)\n",
    "    #a_loc = [c-x for x in a]\n",
    "    pdf_diff = (a_pdf - b_pdf)\n",
    "    pdf_diff = np.sqrt(pdf_diff*pdf_diff)\n",
    "    #print(pdf_diff)\n",
    "    return np.log(np.sum(np.exp(max_scale*(pdf_diff))))/max_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_approx_slow(a,b):\n",
    "    \"\"\"Takes in two lists of numbers, a and b, and returns an approximation to the KS test statistic between them\"\"\"\n",
    "    pdf_scale = 50\n",
    "    max_scale = 200\n",
    "    \n",
    "    c = np.append(a,b)\n",
    "    a_pdf = np.array([np.sum(1/(1+np.exp(pdf_scale*(a-x)))) for x in c])/a.shape[0]\n",
    "    b_pdf = np.array([np.sum(1/(1+np.exp(pdf_scale*(b-x)))) for x in c])/b.shape[0]\n",
    "    #print(c)\n",
    "    #a_loc = [c-x for x in a]\n",
    "    pdf_diff = (a_pdf - b_pdf)\n",
    "    pdf_diff = np.sqrt(pdf_diff*pdf_diff)\n",
    "    #print(pdf_diff)\n",
    "    return np.log(np.sum(np.exp(max_scale*(pdf_diff))))/max_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03749999999999998\n",
      "0.056018057216997895\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "a = np.random.rand(512)\n",
    "b = np.random.rand(2000)\n",
    "#print(a)\n",
    "#print(b)\n",
    "print(ks_2samp(a, b)[0])\n",
    "print(ks_approx_slow(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4000127101797548\n",
      "Ks_2sampResult(statistic=0.45, pvalue=0.15820583934355137)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,3,6,7,8,3,23,434,235,4,8,5])\n",
    "b = np.array([1,12,43,24,5,23,244,23,11,2])\n",
    "print(ks_approx(a, b))\n",
    "print(ks_2samp(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Implementation\n",
    "\n",
    "Now we need to get this working with TF tensors and the like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "           \n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, LeakyReLU, Lambda\n",
    "from keras.layers import Input, merge, Concatenate, concatenate, Add\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a =', array([1., 2., 3., 4., 5.], dtype=float32))\n",
      "('c =', array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=float32))\n",
      "('a_pdf =', array([[1.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01],\n",
      "       [3.8574995e-23, 1.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01],\n",
      "       [0.0000000e+00, 3.8574995e-23, 1.0000000e-01, 2.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01],\n",
      "       [0.0000000e+00, 0.0000000e+00, 3.8574995e-23, 1.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01],\n",
      "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8574995e-23,\n",
      "        1.0000000e-01, 2.0000000e-01, 2.0000000e-01, 2.0000000e-01,\n",
      "        2.0000000e-01, 2.0000000e-01]], dtype=float32))\n",
      "('summed a_pdf =', array([0.1, 0.3, 0.5, 0.7, 0.9, 1. , 1. , 1. , 1. , 1. ], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "a = K.variable([1,2,3,4,5])\n",
    "b = K.variable([6,7,8,9,10])\n",
    "\n",
    "pdf_scale = 50\n",
    "max_scale = 200\n",
    "\n",
    "c = K.concatenate([a,b])\n",
    "print(\"a =\",K.eval(a))\n",
    "print(\"c =\",K.eval(c))\n",
    "#a_pdf = K.map_fn(lambda x: 1/(1+K.exp(x)), a)\n",
    "a_len = int(a.shape[0])\n",
    "b_len = int(b.shape[0])\n",
    "a_pdf = K.map_fn(lambda x: 1/((a_len)*(1+K.exp(pdf_scale*(x-c)))), a)\n",
    "print(\"a_pdf =\",K.eval(a_pdf))\n",
    "a_pdf = K.sum(K.map_fn(lambda x: 1/(1+K.exp(pdf_scale*(x-c))), a), axis=0)/int(a.shape[0])\n",
    "print(\"summed a_pdf =\",K.eval(a_pdf))\n",
    "#a_pdf = K.variable([K.sum(1/(1+K.exp(pdf_scale*(a-x)))) for x in c])/a.shape[0]\n",
    "#b_pdf = K.variable([K.sum(1/(1+K.exp(pdf_scale*(b-x)))) for x in c])/b.shape[0]\n",
    "#pdf_diff = (a_pdf - b_pdf)\n",
    "#pdf_diff = K.sqrt(pdf_diff*pdf_diff)\n",
    "#K.log(K.sum(K.exp(max_scale*(pdf_diff))))/max_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "Now with the real data loaded in, like a cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/home/users/bhashemi/Projects/GIT/DY-GAN/delphes/total_Zmumu_13TeV_PU20_v2.npa\")\n",
    "data = data[data[\"genmll\"] > 50.]\n",
    "data = data[np.random.randint(0, data.shape[0], 2000)]\n",
    "mll_true = data[\"mll\"]\n",
    "\n",
    "def ks_approx(a,b):\n",
    "    \"\"\"Takes in two lists of numbers, a and b, and returns an approximation to the KS test statistic between them\"\"\"\n",
    "    pdf_scale = 50\n",
    "    max_scale = 200\n",
    "\n",
    "    c = K.concatenate([a,b])\n",
    "    num_a = K.sum(a)/K.mean(a)\n",
    "    num_b = b.shape[0]\n",
    "    a_pdf = K.sum(K.map_fn(lambda x: 1/(1+K.exp(pdf_scale*(x-c))), a), axis=0)/num_a\n",
    "    b_pdf = K.sum(K.map_fn(lambda x: 1/(1+K.exp(pdf_scale*(x-c))), b), axis=0)/num_b\n",
    "    pdf_diff = (a_pdf - b_pdf)\n",
    "    pdf_diff = K.sqrt(pdf_diff*pdf_diff)\n",
    "    return K.log(K.sum(K.exp(max_scale*(pdf_diff))))/max_scale\n",
    "\n",
    "def loss_func(y_true, y_pred_mll):\n",
    "    y_true = y_true[:,0]\n",
    "    y_pred = y_pred_mll[:,0]\n",
    "    mll_pred = y_pred_mll[:,0]\n",
    "\n",
    "    mll_loss = ks_approx(mll_pred, mll_true)\n",
    "    #mll_loss = 1\n",
    "\n",
    "    return binary_crossentropy(y_true, y_pred) + c*mll_loss\n",
    "\n",
    "\n",
    "\n",
    "input_shape=(8,)\n",
    "noise_shape=input_shape\n",
    "output_shape=(8,)\n",
    "#Gen:\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Dense(64)(inputs)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "for size in [128,256,512,256,128]:\n",
    "    x = Dense(size)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "x = Dense(output_shape[0])(x)\n",
    "gen = Model(inputs=inputs, outputs=[x])\n",
    "\n",
    "#Disc:\n",
    "inputs = Input(input_shape)\n",
    "x = Dense(128)(inputs)\n",
    "for size in [128,256,256,128,64,32,16,8]:\n",
    "    x = Dense(size)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "out = Dense(1,activation='sigmoid')(x)\n",
    "disc = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "gen.compile(loss=loss_func, optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "disc.compile(loss=loss_func, optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "disc.trainable = False #only train the generator\n",
    "z = Input(shape=noise_shape)\n",
    "img = gen(z)\n",
    "valid = disc(img)\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss=loss_func, optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02770312500000005\n",
      "0.04897199190736596\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "a = np.random.rand(512)\n",
    "b = np.random.rand(2000)\n",
    "#print(a)\n",
    "#print(b)\n",
    "print(ks_2samp(a, b)[0])\n",
    "print(ks_approx_slow(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
