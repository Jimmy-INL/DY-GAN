{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import tensorflow\n",
      "import keras\n",
      "import matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sklearn\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# running with non gpu singularity container, so commented out the next line to use CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "print \"import tensorflow\"\n",
    "           \n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, LeakyReLU, Lambda\n",
    "from keras.layers import Input, merge, Concatenate, concatenate, Add, Multiply\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import RMSprop,Adadelta\n",
    "print \"import keras\"\n",
    "\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "print \"import matplotlib\"\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from scipy.stats import binned_statistic_2d\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "print \"import sklearn\"\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Minv(cols,ptetaphi=False,nopy2=True):\n",
    "    \"\"\"\n",
    "    Computes M for two objects given the cartesian momentum projections\n",
    "    if `ptetaphi` is True, then assumes the 8 input columns are cylindrical eptetaphi\n",
    "    if `nopy2` is True, input is 7 columns with no py2\n",
    "    \"\"\"\n",
    "    if ptetaphi:\n",
    "        cols = ptetaphi_to_cartesian(cols)\n",
    "    if nopy2:\n",
    "        M2 = (cols[:,0]+cols[:,4])**2\n",
    "        M2 -= (cols[:,1]+cols[:,5])**2\n",
    "        M2 -= (cols[:,2]          )**2\n",
    "        M2 -= (cols[:,3]+cols[:,6])**2\n",
    "    else:\n",
    "        M2 = (cols[:,0]+cols[:,4])**2\n",
    "        M2 -= (cols[:,1]+cols[:,5])**2\n",
    "        M2 -= (cols[:,2]+cols[:,6])**2\n",
    "        M2 -= (cols[:,3]+cols[:,7])**2\n",
    "    return np.sqrt(M2)\n",
    "\n",
    "def cartesian_to_ptetaphi(eight_cartesian_cols):\n",
    "    \"\"\"\n",
    "    Takes 8 columns as cartesian e px py pz e px py pz\n",
    "    and converts to e pt eta phi e pt eta phi\n",
    "    \"\"\"\n",
    "    e1 =  eight_cartesian_cols[:,0]\n",
    "    e2 =  eight_cartesian_cols[:,4]\n",
    "    px1 = eight_cartesian_cols[:,1]\n",
    "    px2 = eight_cartesian_cols[:,5]\n",
    "    py1 = eight_cartesian_cols[:,2]\n",
    "    py2 = eight_cartesian_cols[:,6]\n",
    "    pz1 = eight_cartesian_cols[:,3]\n",
    "    pz2 = eight_cartesian_cols[:,7]\n",
    "    p1 = np.sqrt(px1**2+py1**2+pz1**2)\n",
    "    p2 = np.sqrt(px2**2+py2**2+pz2**2)\n",
    "    pt1 = np.sqrt(px1**2+py1**2)\n",
    "    pt2 = np.sqrt(px2**2+py2**2)\n",
    "    phi1 = np.arctan2(py1,px1)\n",
    "    phi2 = np.arctan2(py2,px2)\n",
    "    eta1 = np.arctanh(pz1/p1)\n",
    "    eta2 = np.arctanh(pz2/p2)\n",
    "    return np.c_[e1,pt1,eta1,phi1,e2,pt2,eta2,phi2]\n",
    "\n",
    "def ptetaphi_to_cartesian(eight_eptetaphi_cols):\n",
    "    \"\"\"\n",
    "    Takes 8 columns as e pt eta phi e pt eta phi\n",
    "    and converts to e px py pz e px py pz\n",
    "    \"\"\"\n",
    "    e1 =  eight_eptetaphi_cols[:,0]\n",
    "    e2 =  eight_eptetaphi_cols[:,4]\n",
    "    pt1 =  eight_eptetaphi_cols[:,1]\n",
    "    pt2 =  eight_eptetaphi_cols[:,5]\n",
    "    eta1 =  eight_eptetaphi_cols[:,2]\n",
    "    eta2 =  eight_eptetaphi_cols[:,6]\n",
    "    phi1 =  eight_eptetaphi_cols[:,3]\n",
    "    phi2 =  eight_eptetaphi_cols[:,7]\n",
    "    px1 = np.abs(pt1)*np.cos(phi1)\n",
    "    px2 = np.abs(pt2)*np.cos(phi2)\n",
    "    py1 = np.abs(pt1)*np.sin(phi1)\n",
    "    py2 = np.abs(pt2)*np.sin(phi2)\n",
    "    pz1 = np.abs(pt1)/np.tan(2.0*np.arctan(np.exp(-1.*eta1)))\n",
    "    pz2 = np.abs(pt2)/np.tan(2.0*np.arctan(np.exp(-1.*eta2)))\n",
    "    return np.c_[e1,px1,py1,pz1,e2,px2,py2,pz2]\n",
    "\n",
    "def get_dphi(px1,py1,px2,py2):\n",
    "    phi1 = np.arctan2(py1,px1)\n",
    "    phi2 = np.arctan2(py2,px2)\n",
    "    dphi = phi1-phi2\n",
    "    dphi[dphi>np.pi] -= 2*np.pi\n",
    "    dphi[dphi<-np.pi] += 2*np.pi \n",
    "    return dphi\n",
    "\n",
    "def M4(E,px,py,pz):\n",
    "    return np.sqrt(E*E - px*px - py*py - pz*pz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invmass_from_8cartesian_nopy2(x):\n",
    "    \n",
    "    invmass = K.sqrt(\n",
    "                (x[:,0:1]+x[:,4:5])**2-\n",
    "                (x[:,1:2]+x[:,5:6])**2-\n",
    "                (x[:,2:3]         )**2-\n",
    "                (x[:,3:4]+x[:,6:7])**2\n",
    "                )\n",
    "    return invmass\n",
    "\n",
    "\n",
    "# def getKS(real_data, predictions):\n",
    "#     return ks_2samp(real_data[\"mll\"], Minv(predictions))\n",
    "\n",
    "def getKS(real_data, predictions):\n",
    "    return ks_2samp(real_data[\"mll\"], Minv(predictions))[0] + \\\n",
    "     ks_2samp(real_data[\"lep1_e\"], predictions[:,0])[0] + \\\n",
    "     ks_2samp(real_data[\"lep1_px\"], predictions[:,1])[0] + \\\n",
    "     ks_2samp(real_data[\"lep1_py\"], predictions[:,2])[0] + \\\n",
    "     ks_2samp(real_data[\"lep1_pz\"], predictions[:,3])[0] + \\\n",
    "     ks_2samp(real_data[\"lep1_e\"], predictions[:,4])[0] + \\\n",
    "     ks_2samp(real_data[\"lep2_px\"], predictions[:,5])[0] + \\\n",
    "     ks_2samp(real_data[\"lep2_pz\"], predictions[:,6])[0] + \\\n",
    "     ks_2samp(real_data[\"nvtxs\"], np.rint(predictions[:,7]))[0] + \\\n",
    "     ks_2samp(real_data[\"lep1_iso\"], predictions[:,8])[0] + \\\n",
    "     ks_2samp(real_data[\"lep2_iso\"], predictions[:,9])[0] + \\\n",
    "     ks_2samp(real_data[\"met\"]*np.cos(real_data[\"metphi\"]), predictions[:,10])[0] + \\\n",
    "     ks_2samp(real_data[\"met\"]*np.sin(real_data[\"metphi\"]), predictions[:,11])[0] + \\\n",
    "     ks_2samp(real_data[\"jet_pt1\"], predictions[:,12])[0] + \\\n",
    "     ks_2samp(real_data[\"jet_pt2\"], predictions[:,13])[0] + \\\n",
    "     ks_2samp(real_data[\"jet_pt3\"], predictions[:,14])[0] + \\\n",
    "     ks_2samp(real_data[\"jet_pt4\"], predictions[:,15])[0] + \\\n",
    "     ks_2samp(real_data[\"jet_pt5\"], predictions[:,16])[0]\n",
    "\n",
    "# def get_first_N(x,N):\n",
    "#     return x[:,0:N]\n",
    "\n",
    "# def fix_outputs(x):\n",
    "#     \"\"\"\n",
    "#     Take nominal delphes format of 19 columns and fix some columns\n",
    "#     \"\"\"\n",
    "#     return K.concatenate([\n",
    "#         # x[:,0:21],\n",
    "#         x[:,0:7], # epxpypz for lep1,lep2 -1 for no py2\n",
    "#         x[:,7:8], # nvtx\n",
    "#         K.sign(x[:,8:10]), # q1 q2\n",
    "#         x[:,10:12], # iso1 iso2\n",
    "#         x[:,12:14], # met, metphi\n",
    "#         x[:,14:19], # jet pts\n",
    "#         ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(preds,reals,title=\"\",fname=\"\",show_pred=True,show_real=True,wspace=0.1,hspace=0.3,tightlayout=True,visible=True):\n",
    "    nrows, ncols = 5,5\n",
    "    fig, axs = plt.subplots(nrows,ncols,figsize=(16,13))\n",
    "#     fig, axs = plt.subplots(nrows,ncols,figsize=(12,10))\n",
    "#     fig.subplots_adjust(wspace=0.1,hspace=0.3)\n",
    "    fig.subplots_adjust(wspace=wspace,hspace=hspace)\n",
    "\n",
    "\n",
    "    info = [\n",
    "        [\"lep1_e\",(0,250,50)],\n",
    "        [\"lep1_px\",(-100,100,50)],\n",
    "        [\"lep1_py\",(-100,100,50)],\n",
    "        [\"lep1_pz\",(-200,200,50)],\n",
    "        [\"lep2_e\",(0,250,50)],\n",
    "        [\"lep2_px\",(-100,100,50)],\n",
    "        [\"lep2_pz\",(-200,200,50)],\n",
    "        [\"nvtxs\",(0,50,350)],\n",
    "        [\"metx\",(-50,50,100)],\n",
    "        [\"mety\",(-50,50,100)],\n",
    "#         [\"lep1_charge\",(-7,7,30)],\n",
    "#         [\"lep2_charge\",(-7,7,30)],\n",
    "        [\"lep1_iso\",(0,2.0,30)],\n",
    "        [\"lep2_iso\",(0,2.0,30)],\n",
    "        [\"jet_pt1\",(0,100,50)],\n",
    "        [\"jet_pt2\",(0,100,50)],\n",
    "        [\"jet_pt3\",(0,100,50)],\n",
    "        [\"jet_pt4\",(0,100,50)],\n",
    "        [\"jet_pt5\",(0,100,50)],\n",
    "        # derived features\n",
    "        [\"dphi\",(-4,4,50)],\n",
    "        [\"met\",(0,150,50)],\n",
    "        [\"metphi\",(-6,6,50)],\n",
    "        [\"mll\",(60,120,50)],\n",
    "        [\"lep1_mass\",(0,10,50)],\n",
    "        [\"lep2_mass\",(0,10,50)],\n",
    "        [\"njets\",(0,7,7)],\n",
    "    ]\n",
    "    for axx in axs:\n",
    "        for ax in axx:\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            # turn off all axis borders, and turn them on below so they only show\n",
    "            # up for axes we've plotted in\n",
    "            ax.axis('off')\n",
    "    for ic,(cname,crange) in enumerate(info):\n",
    "        if cname == \"mll\":\n",
    "            real = reals[\"mll\"]\n",
    "            pred = Minv(preds)\n",
    "        elif cname == \"lep1_mass\": real, pred = M4(reals[\"lep1_e\"], reals[\"lep1_px\"], reals[\"lep1_py\"], reals[\"lep1_pz\"]), M4(preds[:,0], preds[:,1], preds[:,2], preds[:,3])\n",
    "        elif cname == \"lep2_mass\": real, pred = M4(reals[\"lep2_e\"], reals[\"lep2_px\"], 0, reals[\"lep2_pz\"]), M4(preds[:,4], preds[:,5], preds[:,6], preds[:,7])\n",
    "        elif cname == \"lep1_e\": real, pred = reals[cname], preds[:,0]\n",
    "        elif cname == \"lep1_pz\": real, pred = reals[cname], preds[:,3]\n",
    "        elif cname == \"lep2_e\": real, pred = reals[cname], preds[:,4]\n",
    "        elif cname == \"lep2_pz\": real, pred = reals[cname], preds[:,6]\n",
    "        elif cname == \"lep1_px\": \n",
    "            real = reals[cname]\n",
    "            pred = preds[:,1]\n",
    "        elif cname == \"lep1_py\":\n",
    "            real = reals[cname]\n",
    "            pred = preds[:,2]\n",
    "        elif cname == \"lep2_px\":\n",
    "            real = reals[cname]\n",
    "            pred = preds[:,5]\n",
    "        elif cname == \"dphi\":\n",
    "            real = get_dphi(reals[\"lep1_px\"], reals[\"lep1_py\"], reals[\"lep2_px\"], np.zeros(len(reals)))\n",
    "            pred = get_dphi(preds[:,1], preds[:,2], preds[:,5], np.zeros(len(preds)))\n",
    "        elif cname == \"nvtxs\": real, pred = reals[cname], np.round(preds[:,7])\n",
    "#         elif cname == \"lep1_charge\": real, pred = reals[cname], preds[:,8]\n",
    "#         elif cname == \"lep2_charge\": real, pred = reals[cname], preds[:,9]\n",
    "        elif cname == \"lep1_iso\": real, pred = reals[cname], preds[:,8]\n",
    "        elif cname == \"lep2_iso\": real, pred = reals[cname], preds[:,9]\n",
    "        elif cname == \"metx\": real, pred = reals[\"met\"]*np.cos(reals[\"metphi\"]), preds[:,10]\n",
    "        elif cname == \"mety\": real, pred = reals[\"met\"]*np.sin(reals[\"metphi\"]), preds[:,11]\n",
    "        elif cname == \"met\": real, pred = reals[\"met\"], np.hypot(preds[:,10],preds[:,11])\n",
    "        elif cname == \"metphi\": real, pred = reals[\"metphi\"], np.arctan2(preds[:,11],preds[:,10])\n",
    "        elif cname == \"jet_pt1\": real, pred = reals[cname], preds[:,12]\n",
    "        elif cname == \"jet_pt2\": real, pred = reals[cname], preds[:,13]\n",
    "        elif cname == \"jet_pt3\": real, pred = reals[cname], preds[:,14]\n",
    "        elif cname == \"jet_pt4\": real, pred = reals[cname], preds[:,15]\n",
    "        elif cname == \"jet_pt5\": real, pred = reals[cname], preds[:,16]\n",
    "        elif cname == \"njets\":\n",
    "            real = \\\n",
    "                1*(reals[\"jet_pt1\"] > 15) + \\\n",
    "                1*(reals[\"jet_pt2\"] > 15) + \\\n",
    "                1*(reals[\"jet_pt3\"] > 15) + \\\n",
    "                1*(reals[\"jet_pt4\"] > 15) + \\\n",
    "                1*(reals[\"jet_pt5\"] > 15)\n",
    "            pred = \\\n",
    "                1*(preds[:,12] > 15) + \\\n",
    "                1*(preds[:,13] > 15) + \\\n",
    "                1*(preds[:,14] > 15) + \\\n",
    "                1*(preds[:,15] > 15) + \\\n",
    "                1*(preds[:,16] > 15)\n",
    "        idx = ic // ncols, ic % ncols\n",
    "        if show_real:\n",
    "            bins_real = axs[idx].hist(real, range=crange[:2],bins=crange[-1], histtype=\"step\", lw=1.5,density=True)\n",
    "        if show_pred:\n",
    "            bins_pred = axs[idx].hist(pred, range=crange[:2],bins=crange[-1], histtype=\"step\", lw=1.5,density=True)\n",
    "        axs[idx].set_xlabel(\"{}\".format(cname),fontsize=14)\n",
    "        axs[idx].axis('on')\n",
    "        if cname in [\"mll\",\"lep1_mass\",\"lep2_mass\",\"dphi\",\"met\",\"metphi\",\"njets\"]:\n",
    "            axs[idx].xaxis.label.set_color('blue')\n",
    "    #     axs[idx].set_yscale(\"log\", nonposy='clip')\n",
    "    _ = axs[0,0].legend([\"True\",\"Pred\"], loc='upper right',fontsize=14)\n",
    "    _ = axs[0,0].set_title(title)\n",
    "    if tightlayout:\n",
    "        plt.tight_layout()\n",
    "    if fname:\n",
    "        fig.savefig(fname)\n",
    "    if not visible:\n",
    "        plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recview(data, dtype=\"<f4\"):\n",
    "    \"\"\"\n",
    "    for example, can give it a matrix of values predicted by generator\n",
    "    and this gives a view of the same matrix with dtypes (for easier column selection)\n",
    "    if weird results, like 2 columns per field, use dtype=\"<f8\"\n",
    "    \"\"\"\n",
    "    cnames = [\n",
    "    \"lep1_e\",\n",
    "    \"lep1_px\",\n",
    "    \"lep1_py\",\n",
    "    \"lep1_pz\",\n",
    "    \"lep2_e\",\n",
    "    \"lep2_px\",\n",
    "    \"lep2_pz\",\n",
    "    \"nvtxs\",\n",
    "#     \"lep1_charge\",\n",
    "#     \"lep2_charge\",\n",
    "    \"lep1_iso\",\n",
    "    \"lep2_iso\",\n",
    "    \"metx\",\n",
    "    \"mety\",\n",
    "    \"jet_pt1\",\n",
    "    \"jet_pt2\",\n",
    "    \"jet_pt3\",\n",
    "    \"jet_pt4\",\n",
    "    \"jet_pt5\",\n",
    "    ]\n",
    "    cnames = [(cn,dtype) for cn in cnames]\n",
    "    return data.view(dtype=cnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN class\n",
    "Instantiate the GAN class, then add methods piece by piece (by making a \"new\" class inheriting from the original).\n",
    "I did this so that all these long functions could go into different cells, which makes it easier to navigate/read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.args = dict(kwargs)\n",
    "\n",
    "        self.verbose = kwargs.get(\"verbose\",True)\n",
    "        self.tag = kwargs[\"tag\"]\n",
    "        self.input_file = str(kwargs[\"input_file\"])\n",
    "        self.noise_shape = (int(kwargs[\"noise_size\"]),)\n",
    "        self.output_shape = (int(kwargs[\"output_size\"]),)\n",
    "        self.noise_type = int(kwargs[\"noise_type\"])\n",
    "        self.ntest_samples = int(kwargs[\"ntest_samples\"])\n",
    "        self.nepochs_dump_pred_metrics = int(kwargs[\"nepochs_dump_pred_metrics\"])\n",
    "        self.nepochs_dump_models = int(kwargs[\"nepochs_dump_models\"])\n",
    "        self.nepochs_dump_plots = int(kwargs[\"nepochs_dump_plots\"])\n",
    "        self.nepochs_max = int(kwargs[\"nepochs_max\"])\n",
    "        self.batch_size = int(kwargs[\"batch_size\"])\n",
    "        self.do_soft_labels = kwargs[\"do_soft_labels\"]\n",
    "        self.do_noisy_labels = kwargs[\"do_noisy_labels\"]\n",
    "        self.nepochs_decay_noisy_labels = int(kwargs[\"nepochs_decay_noisy_labels\"])\n",
    "        self.optimizer_gen = kwargs[\"optimizer_gen\"]\n",
    "        self.optimizer_disc = kwargs[\"optimizer_disc\"]\n",
    "        self.depth_disc = kwargs[\"depth_disc\"]\n",
    "        self.width_disc = kwargs[\"width_disc\"]\n",
    "        self.depth_gen = kwargs[\"depth_gen\"]\n",
    "        self.width_gen = kwargs[\"width_gen\"]\n",
    "        self.beefy_generator = kwargs[\"beefy_generator\"]\n",
    "        self.beefy_discriminator = kwargs[\"beefy_discriminator\"]\n",
    "#         self.fix_delphes_outputs = kwargs[\"fix_delphes_outputs\"]\n",
    "        self.use_mll_loss = kwargs[\"use_mll_loss\"]\n",
    "        self.loss_mll_weight = kwargs[\"loss_mll_weight\"]\n",
    "        self.terminate_early = kwargs[\"terminate_early\"]\n",
    "        self.loss_type = kwargs[\"loss_type\"]\n",
    "        self.dropout_discriminator = kwargs[\"dropout_discriminator\"]\n",
    "        self.frac_true = kwargs[\"frac_true\"]\n",
    "\n",
    "        os.system(\"mkdir -p progress/{}/\".format(self.tag))\n",
    "        os.system(\"cp gan_reco.ipynb progress/{}/\".format(self.tag))\n",
    "\n",
    "        self.scaler_type = kwargs[\"scaler_type\"]\n",
    "        self.scaler = None\n",
    "        self.jetscaler = None\n",
    "        self.isoscaler = None\n",
    "        if self.scaler_type.lower() == \"minmax\":\n",
    "            self.scaler = MinMaxScaler(feature_range=(-1.,1.))\n",
    "        elif self.scaler_type.lower() == \"robust\":\n",
    "            self.scaler = RobustScaler()\n",
    "        elif self.scaler_type.lower() == \"standard\":\n",
    "            self.scaler = StandardScaler()\n",
    "        else:\n",
    "            if \"jet\" in self.scaler_type.lower():\n",
    "                print \"Scaling jet pts\"\n",
    "                self.jetscaler = MinMaxScaler(feature_range=(-1.,1.))\n",
    "            if \"iso\" in self.scaler_type.lower():\n",
    "                print \"Scaling lep isos\"\n",
    "                self.isoscaler = MinMaxScaler(feature_range=(-1.,1.))\n",
    "\n",
    "        self.data = None\n",
    "        self.data_ref = None\n",
    "        self.d_epochinfo = {}\n",
    "        self.X_train = None\n",
    "\n",
    "        optimizer_d = self.optimizer_disc\n",
    "        optimizer_g = self.optimizer_gen\n",
    "        \n",
    "        def dosplit(x):\n",
    "            return float(x.split(\"=\")[1].split(\")\")[0].strip())\n",
    "        if \"lr\" in self.optimizer_disc: optimizer_d = Adadelta(lr=dosplit(self.optimizer_disc))\n",
    "        if \"lr\" in self.optimizer_gen: optimizer_g = Adadelta(lr=dosplit(self.optimizer_gen))\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        if self.use_mll_loss:\n",
    "            loss = self.custom_loss(c=self.loss_mll_weight, loss_type=self.loss_type)\n",
    "        else:\n",
    "            loss = \"binary_crossentropy\"\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=loss,\n",
    "            optimizer=optimizer_d,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss=loss, optimizer=optimizer_g)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=self.noise_shape)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=loss, optimizer=optimizer_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(GAN):\n",
    "    \n",
    "    def custom_loss(self, c, loss_type = \"force_mll\"):\n",
    "        mu_z, sig_z = 89.6, 7.73\n",
    "        if loss_type == \"disc\":\n",
    "            def loss_func(y_true, y_pred_mll):\n",
    "                y_true = y_true[:,0]\n",
    "                y_pred = y_pred_mll[:,0]\n",
    "                return binary_crossentropy(y_true, y_pred)\n",
    "            return loss_func\n",
    "        elif loss_type == \"force_mll\":\n",
    "            def loss_func(y_true, y_pred_mll):\n",
    "                y_true = y_true[:,0]\n",
    "                y_pred = y_pred_mll[:,0]\n",
    "                mll_pred = y_pred_mll[:,1]\n",
    "                mll_loss = K.mean(K.abs(mll_pred - mu_z))\n",
    "                return binary_crossentropy(y_true, y_pred) + c*mll_loss\n",
    "            return loss_func\n",
    "        elif loss_type == \"force_z_width\":\n",
    "            def loss_func(y_true, y_pred_mll):\n",
    "                y_true = y_true[:,0]\n",
    "                y_pred = y_pred_mll[:,0]\n",
    "                mll_pred = y_pred_mll[:,1]\n",
    "                mll_loss = K.mean((mll_pred - mu_z)**2)\n",
    "                mll_sigma_loss = (K.std(mll_pred)-sig_z)**2\n",
    "\n",
    "                return binary_crossentropy(y_true, y_pred) + c*mll_loss + c*mll_sigma_loss\n",
    "            return loss_func\n",
    "        else:\n",
    "            raise ValueError(\"Can not make loss function of type %s\" % loss_type)\n",
    "        \n",
    "    def build_generator(self):\n",
    "\n",
    "        inputs = Input(shape=self.noise_shape)\n",
    "\n",
    "        ## Head\n",
    "        x = Dense(64)(inputs)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        if self.depth_gen > 0 and self.width_gen > 0:\n",
    "            for level in xrange(0,self.depth_gen):\n",
    "                x = Dense(width_gen/(2**level))(x) #Triangle with width halved at each level\n",
    "                x = LeakyReLU(alpha=0.2)(x)\n",
    "        elif self.beefy_generator:\n",
    "            for size in [128,256,512,256,128]:\n",
    "                x = Dense(size)(x)\n",
    "                x = LeakyReLU(alpha=0.2)(x)\n",
    "        else:\n",
    "            for size in [128,128,128,64,32]:\n",
    "                x = Dense(size)(x)\n",
    "                x = LeakyReLU(alpha=0.2)(x)\n",
    " \n",
    "    \n",
    "        x = Dense(self.output_shape[0], activation=\"linear\")(x)\n",
    "            \n",
    "#         if self.fix_delphes_outputs:\n",
    "#             x = Lambda(fix_outputs,\n",
    "#                 input_shape=self.output_shape,\n",
    "#                 output_shape=self.output_shape\n",
    "#                 )(x)\n",
    "            \n",
    "        model = Model(inputs=inputs, outputs=[x])\n",
    "        \n",
    "        print \"Generator params: {}\".format(model.count_params())\n",
    "        if self.verbose:\n",
    "            model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "class GAN(GAN):\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        inputs = Input(self.output_shape)\n",
    "        mll = Lambda(invmass_from_8cartesian_nopy2)(inputs)\n",
    "        x = Dense(128)(inputs)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "        ## Main Body\n",
    "        if self.depth_disc > 0 and self.width_disc > 0:\n",
    "            for level in xrange(0,self.depth_disc):\n",
    "                x = Dense(self.width_disc/(2**level))(x) #Triangle with width halved at each level\n",
    "                x = LeakyReLU(alpha=0.2)(x)\n",
    "        elif self.beefy_discriminator:\n",
    "            for size in [128,256,256,128,64,32,16,8]:\n",
    "                x = Dense(size)(x)\n",
    "                if self.dropout_discriminator:\n",
    "                    x = Dropout(0.1)(x)\n",
    "                x = LeakyReLU(alpha=0.2)(x)\n",
    "        else:\n",
    "            for size in [128]*5 + [64,32,16,8]:\n",
    "                x = Dense(size)(x)\n",
    "                x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "        ## Tail\n",
    "        out = Dense(1,activation='sigmoid')(x)\n",
    "        \n",
    "        if self.use_mll_loss:\n",
    "            model = Model(inputs=inputs, outputs=concatenate([out,mll]))\n",
    "        else:\n",
    "            model = Model(inputs=inputs, outputs=out)\n",
    "#         print model.output_shape\n",
    "        if self.verbose:\n",
    "            model.summary()\n",
    "        print \"Discriminator params: {}\".format(model.count_params())\n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(GAN):\n",
    "    \n",
    "    def load_data(self):\n",
    "        if self.data is not None: return\n",
    "        \n",
    "        self.data = np.load(self.input_file)\n",
    "            \n",
    "        # make sure we drop low mass resonances\n",
    "        self.data = self.data[self.data[\"genmll\"] > 50.]\n",
    "        \n",
    "    def make_flat_array(self):\n",
    "        \"\"\"Builds X_train array which is a flat version of the self.data that has any scaling or modifications applied\"\"\"\n",
    "        \n",
    "        lepcoords = np.c_[\n",
    "            self.data[\"lep1_e\"],\n",
    "            self.data[\"lep1_px\"],\n",
    "            self.data[\"lep1_py\"],\n",
    "            self.data[\"lep1_pz\"],\n",
    "            self.data[\"lep2_e\"],\n",
    "            self.data[\"lep2_px\"],\n",
    "            self.data[\"lep2_pz\"],\n",
    "        ]\n",
    "\n",
    "        nvtx_smeared = np.round(np.random.normal(self.data[\"nvtxs\"],0.5))\n",
    "        \n",
    "        isocoords = np.c_[self.data[\"lep1_iso\"], \n",
    "                          self.data[\"lep2_iso\"]]\n",
    "        if self.isoscaler:\n",
    "            print \"scaling lepton isolations\"\n",
    "            self.isoscaler.fit(isocoords)\n",
    "            isocoords = self.isoscaler.transform(isocoords).astype(np.float32)\n",
    "            pickle.dump(self.isoscaler, open(\"progress/{}/isoscaler.pkl\".format(self.tag),'w'))\n",
    "        \n",
    "        jetcoords = np.c_[self.data[\"jet_pt1\"],\n",
    "                          self.data[\"jet_pt2\"],\n",
    "                          self.data[\"jet_pt3\"],\n",
    "                          self.data[\"jet_pt4\"],\n",
    "                          self.data[\"jet_pt5\"]]\n",
    "        \n",
    "        if self.jetscaler:\n",
    "            print \"scaling jet pts\"\n",
    "            self.jetscaler.fit(jetcoords)\n",
    "            jetcoords = self.jetscaler.transform(jetcoords).astype(np.float32)\n",
    "            pickle.dump(self.jetscaler, open(\"progress/{}/jetscaler.pkl\".format(self.tag),'w'))\n",
    "        \n",
    "        self.X_train = np.c_[\n",
    "            lepcoords, # 7 columns\n",
    "            nvtx_smeared, # 1 column\n",
    "            isocoords,\n",
    "            self.data[\"met\"]*np.cos(self.data[\"metphi\"]), # metx\n",
    "            self.data[\"met\"]*np.sin(self.data[\"metphi\"]), # mety\n",
    "            jetcoords\n",
    "        ].astype(np.float32)\n",
    "\n",
    "        # # NOTE. StandardScaler should be fit on training set\n",
    "        # # and applied the same to train and test, otherwise we\n",
    "        # # introduce a bias\n",
    "        if self.scaler:\n",
    "            self.scaler.fit(self.X_train)\n",
    "            self.X_train = self.scaler.transform(self.X_train).astype(np.float32)\n",
    "            pickle.dump(self.scaler, open(\"progress/{}/scaler.pkl\".format(self.tag),'w'))\n",
    "        \n",
    "\n",
    "    def get_noise(self, amount=1024, max_true_samples=-1, max_true_samples_frac=-1):\n",
    "        \"\"\"\n",
    "        `amount` specifies number of noise vectors\n",
    "        `max_true_samples` applies only to truth conditioned noise type\n",
    "            if > 0, then the true samples are sampled from the first \n",
    "            `max_true_samples` of real events (by default, all are allowed)\n",
    "        `max_true_samples_frac` same desc as `max_true_samples`, but specified\n",
    "            instead as fraction of `amount`\n",
    "        \"\"\"\n",
    "        # nominal\n",
    "        if self.noise_type == 1:\n",
    "            noise_half = np.random.normal(0, 1, (amount//2, self.noise_shape[0]))\n",
    "            noise_full = np.random.normal(0, 1, (amount, self.noise_shape[0]))\n",
    "\n",
    "        elif self.noise_type == 2: # random soup, 4,2,2 have to be modified to sum to noise_shape[0]\n",
    "            ngaus = self.noise_shape[0] // 2\n",
    "            nflat = (self.noise_shape[0] - ngaus) // 2\n",
    "            nexpo = self.noise_shape[0] - nflat - ngaus\n",
    "            noise_gaus = np.random.normal( 0, 1, (amount//2+amount, ngaus))\n",
    "            noise_flat = np.random.uniform(-1, 1, (amount//2+amount, nflat))\n",
    "            noise_expo = np.random.exponential( 1,    (amount//2+amount, nexpo))\n",
    "            noise = np.c_[ noise_gaus,noise_flat,noise_expo ]\n",
    "            noise_half = noise[:amount//2]\n",
    "            noise_full = noise[-amount:]\n",
    "        elif self.noise_type == 3: #Flat noise between 0-1, last 4 units are flipped negative\n",
    "            noise_half = np.random.uniform(0, 1, (amount//2, self.noise_shape[0]))\n",
    "            noise_half[:,-4:] *= -1\n",
    "            noise_full = np.random.uniform(0, 1, (amount, self.noise_shape[0]))\n",
    "            noise_full[:,-4:] *= -1\n",
    "            \n",
    "            \n",
    "        return noise_half, noise_full\n",
    "    \n",
    "    def get_available_checkpoints(self):\n",
    "        # check the output folder for all weights files and return list of epochs for existing files\n",
    "        fnames = glob.glob(\"progress/{}/gen_*.weights\".format(self.tag))\n",
    "        return np.array(sorted(map(lambda x: int(x.rsplit(\"_\",1)[1].split(\".\")[0]), fnames)))\n",
    "\n",
    "    def load_checkpoint(self, epoch):\n",
    "        # given an epoch number, load the disc/gen files, overriding self.discriminator/self.generator\n",
    "        # need to give custom_objects to load_model because keras doesn't know what the loss function is otherwise\n",
    "        custom = {\"loss_func\": gan.custom_loss(c=self.loss_mll_weight,loss_type=self.loss_type)}\n",
    "        # make sure data is loaded if we just want to make a gan, load a checkpoint, and predict + pull real samples\n",
    "        self.load_data()\n",
    "        self.discriminator = load_model(\"progress/{}/disc_{}.weights\".format(self.tag,epoch),custom_objects=custom)\n",
    "        self.generator = load_model(\"progress/{}/gen_{}.weights\".format(self.tag,epoch),custom_objects=custom)\n",
    "        self.d_epochinfo = pickle.load(open(\"progress/{}/history.pkl\".format(self.tag),'r'))\n",
    "\n",
    "        \n",
    "    def load_last_checkpoint(self,which=-1):\n",
    "        # convenience function to get last available checkpoint and load it (or `which`th from last)\n",
    "        lastepoch = self.get_available_checkpoints()[which]\n",
    "        print \"Loading last checkpoint for tag {}: epoch {}\".format(self.tag, lastepoch)\n",
    "        self.load_checkpoint(lastepoch)\n",
    "        \n",
    "    def predict(self, N, frac):\n",
    "        \"\"\"Gets prediction from trained generator and undoes any scaling.\"\"\"\n",
    "        _, noise = self.get_noise(N,max_true_samples_frac=frac)\n",
    "        # print preds.shape\n",
    "        preds = self.generator.predict(noise,verbose=1)\n",
    "        \n",
    "        if self.scaler:\n",
    "            preds = self.scaler.inverse_transform(preds)\n",
    "            return preds\n",
    "        \n",
    "        lepcoords = preds[:,0:7]\n",
    "        nvtx = preds[:,7]\n",
    "        isocoords = preds[:,8:10]\n",
    "        metcoords = preds[:,10:12]\n",
    "        jetcoords = preds[:,12:17]\n",
    "        if self.isoscaler:\n",
    "            isocoords = self.isoscaler.inverse_transform(isocoords)\n",
    "        if self.jetscaler:\n",
    "            jetcoords = self.jetscaler.inverse_transform(jetcoords)\n",
    "            \n",
    "        return  np.c_[\n",
    "                lepcoords, # 7 columns\n",
    "                nvtx, # 1 column\n",
    "                isocoords,\n",
    "                metcoords,\n",
    "                jetcoords\n",
    "            ].astype(np.float32)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(GAN):\n",
    "            \n",
    "    def train(self):\n",
    "\n",
    "        self.load_data()\n",
    "        self.make_flat_array()\n",
    "        \n",
    "        # make an alias to save typing\n",
    "        X_train = self.X_train\n",
    "        \n",
    "        half_batch = int(self.batch_size / 2)\n",
    "\n",
    "        prev_gen_loss = -1\n",
    "        prev_disc_loss = -1\n",
    "        n_loss_same_gen = 0  # number of epochs for which generator loss has remained ~same (within 0.01%)\n",
    "        n_loss_same_disc = 0  # number of epochs for which discriminator loss has remained ~same (within 0.01%)\n",
    "        old_info = -1, -1\n",
    "        ks_score = 999.\n",
    "        best_ks_score = 999.\n",
    "        for epoch in range(self.nepochs_max):\n",
    "\n",
    "            if self.terminate_early:\n",
    "                if n_loss_same_gen > 1000 or n_loss_same_disc > 1000:\n",
    "                    print \"BREAKING because disc/gen loss has remained the same for {}/{} epochs!\".format(n_loss_same_disc,n_loss_same_gen)\n",
    "                    break\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise_half, noise_full = self.get_noise(self.batch_size, max_true_samples_frac=self.frac_true)\n",
    "            \n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise_half)\n",
    "\n",
    "            # Train the discriminator\n",
    "            ones = np.ones((half_batch, 1))\n",
    "            zeros = np.zeros((half_batch, 1))\n",
    "\n",
    "            if self.do_soft_labels:\n",
    "                ones *= 0.9\n",
    "\n",
    "            if self.do_noisy_labels:\n",
    "                frac = 0.3*np.exp(-epoch/self.nepochs_decay_noisy_labels)\n",
    "                if frac > 0.005:\n",
    "                    ones[np.random.randint(0, len(ones), int(frac*len(ones)))] = 0\n",
    "                    zeros[np.random.randint(0, len(zeros), int(frac*len(zeros)))] = 1\n",
    "\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, ones)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, zeros)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * self.batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise_full, valid_y)\n",
    "\n",
    "            if (g_loss - prev_gen_loss) < 0.0001: n_loss_same_gen += 1\n",
    "            else: n_loss_same_gen = 0\n",
    "            prev_gen_loss = g_loss\n",
    "\n",
    "            if (d_loss[0] - prev_disc_loss) < 0.0001: n_loss_same_disc += 1\n",
    "            else: n_loss_same_disc = 0\n",
    "            prev_disc_loss = d_loss[0]\n",
    "\n",
    "            # Plot the progress\n",
    "#             print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            sys.stdout.write(\"\\r{} [D loss: {}, acc.: {:.2f}%] [G loss: {}] [mll={:.3f}+-{:.3f}] [ks={:.3f}]\".format(epoch, d_loss[0], 100.0*d_loss[1], g_loss, old_info[0], old_info[1],ks_score))\n",
    "\n",
    "            if epoch % self.nepochs_dump_pred_metrics == 0 and epoch > 0:\n",
    "            \n",
    "                _, noise_test = self.get_noise(self.ntest_samples,  max_true_samples_frac=self.frac_true)\n",
    "            \n",
    "                sys.stdout.write(\"\\n\") # break up the stream of text\n",
    "\n",
    "                gen_imgs = self.generator.predict(noise_test)\n",
    "\n",
    "                if self.scaler:\n",
    "                    gen_imgs = self.scaler.inverse_transform(gen_imgs)\n",
    "\n",
    "                masses = Minv(gen_imgs)\n",
    "                masses = masses[np.isfinite(masses)]\n",
    "                old_info = masses.mean(), masses.std()\n",
    "                ks_score = getKS(self.data[:15000],gen_imgs)\n",
    "\n",
    "                if \"epoch\" not in self.d_epochinfo:\n",
    "                    self.d_epochinfo[\"epoch\"] = []\n",
    "                    self.d_epochinfo[\"d_acc\"] = []\n",
    "                    self.d_epochinfo[\"d_loss\"] = []\n",
    "                    self.d_epochinfo[\"g_loss\"] = []\n",
    "                    self.d_epochinfo[\"mass_mu\"] = []\n",
    "                    self.d_epochinfo[\"mass_sig\"] = []\n",
    "                    self.d_epochinfo[\"ks\"] = []\n",
    "                    self.d_epochinfo[\"time\"] = []\n",
    "                    self.d_epochinfo[\"args\"] = self.args\n",
    "                else:\n",
    "                    self.d_epochinfo[\"epoch\"].append(epoch)\n",
    "                    self.d_epochinfo[\"d_acc\"].append(100*d_loss[1])\n",
    "                    self.d_epochinfo[\"d_loss\"].append(d_loss[0])\n",
    "                    self.d_epochinfo[\"g_loss\"].append(g_loss)\n",
    "                    self.d_epochinfo[\"mass_mu\"].append(masses.mean())\n",
    "                    self.d_epochinfo[\"mass_sig\"].append(masses.std())\n",
    "                    self.d_epochinfo[\"ks\"].append(ks_score)\n",
    "                    self.d_epochinfo[\"time\"].append(time.time())\n",
    "\n",
    "                pickle.dump(self.d_epochinfo, open(\"progress/{}/history.pkl\".format(self.tag),'w'))\n",
    "\n",
    "                # note, nested within nepochs_dump_pred_metrics, so below value must be multiple of that\n",
    "                if epoch % self.nepochs_dump_plots == 0 and epoch > 0:\n",
    "                    preds = self.predict(self.ntest_samples,self.frac_true)\n",
    "                    reals = self.data[:15000]\n",
    "                    _ = make_plots(preds,reals,title=\"{}: epoch {}\".format(self.tag,epoch),\n",
    "                                   fname=\"progress/{}/plots_{:06d}.png\".format(self.tag,epoch),visible=False)\n",
    "\n",
    "                # note, nested within nepochs_dump_pred_metrics, so below value must be multiple of that\n",
    "                if epoch % self.nepochs_dump_models == 0 and epoch > 0:                    \n",
    "                    dfname = \"progress/{}/disc_{}.weights\".format(self.tag,epoch)\n",
    "                    gfname = \"progress/{}/gen_{}.weights\".format(self.tag,epoch)\n",
    "                    self.discriminator.save(dfname)\n",
    "                    self.generator.save(gfname)\n",
    "                    if (ks_score < best_ks_score):\n",
    "                        print \"KS score improved from {:.2f} to {:.2f}, saving models to {}\".format(best_ks_score,ks_score,gfname)\n",
    "                        best_ks_score = ks_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters and instantiate\n",
    "Parameters, plots, epoch metrics, get saved to folder `progress/<tag>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do_skip_connection': False, 'width_disc': 0, 'ntest_samples': 10000, 'optimizer_disc': 'adadelta', 'nepochs_dump_models': 100, 'loss_type': 'force_z_width', 'input_file': '/home/users/bhashemi/Projects/GIT/DY-GAN/delphes/total_Zmumu_13TeV_PU20_v2.npa', 'dropout_discriminator': False, 'terminate_early': True, 'do_batch_normalization_disc': False, 'scaler_type': 'jetiso', 'nepochs_dump_plots': 500, 'batch_size': 512, 'do_concatenate_disc': False, 'do_noisy_labels': False, 'do_soft_labels': False, 'depth_gen': 0, 'nepochs_dump_pred_metrics': 100, 'verbose': True, 'noise_size': 17, 'do_batch_normalization_gen': False, 'output_size': 17, 'frac_true': -1, 'loss_mll_weight': 0.0001, 'nepochs_max': 100001, 'beefy_discriminator': True, 'width_gen': 0, 'depth_disc': 0, 'do_tanh_gen': False, 'do_concatenate_gen': False, 'use_mll_loss': True, 'beefy_generator': True, 'nepochs_decay_noisy_labels': 1000, 'optimizer_gen': 'adadelta', 'noise_type': 3}\n",
      "Scaling jet pts\n",
      "Scaling lep isos\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          2304        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          33024       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 128)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           8256        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           528         leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 8)            136         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 8)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            9           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           dense_10[0][0]                   \n",
      "                                                                 lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 161,537\n",
      "Trainable params: 161,537\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Discriminator params: 161537\n",
      "Generator params: 340497\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 340,497\n",
      "Trainable params: 340,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defaults\n",
    "params = {\n",
    "        \"batch_size\": 512,\n",
    "        \"beefy_discriminator\": True,\n",
    "        \"beefy_generator\": True,\n",
    "        \"depth_disc\": 0,\n",
    "        \"depth_gen\": 0,\n",
    "        \"do_batch_normalization_disc\": False,\n",
    "        \"do_batch_normalization_gen\": False,\n",
    "        \"do_concatenate_disc\": False,\n",
    "        \"do_concatenate_gen\": False,\n",
    "        \"do_noisy_labels\": False,\n",
    "        \"do_soft_labels\": False,\n",
    "#         \"do_noisy_labels\": True,\n",
    "#         \"do_soft_labels\": True,\n",
    "        \"do_skip_connection\": False,\n",
    "        \"do_tanh_gen\": False,\n",
    "        \"dropout_discriminator\": False,\n",
    "        \"frac_true\": -1,\n",
    "        \"input_file\": \"/home/users/bhashemi/Projects/GIT/DY-GAN/delphes/total_Zmumu_13TeV_PU20_v2.npa\",\n",
    "        \"loss_mll_weight\": 0.0001,\n",
    "#         \"loss_type\": \"force_mll\",\n",
    "        \"loss_type\": \"force_z_width\",\n",
    "        \"nepochs_decay_noisy_labels\": 1000,\n",
    "#         \"nepochs_dump_models\": 9999999, # can't dump models? FIXME\n",
    "        \"nepochs_dump_models\": 100, # can't dump models? FIXME\n",
    "        \"nepochs_dump_plots\": 500,\n",
    "        \"nepochs_dump_pred_metrics\": 100,\n",
    "        \"nepochs_max\": 100001,\n",
    "        \"noise_size\": 17,\n",
    "        \"noise_type\": 3,\n",
    "        \"ntest_samples\": 10000,\n",
    "        \"optimizer_disc\": \"adadelta\",\n",
    "        \"optimizer_gen\": \"adadelta\",\n",
    "#         \"optimizer_disc\": \"adadelta(lr=0.1)\",\n",
    "#         \"optimizer_gen\": \"adadelta(lr=0.1)\",\n",
    "        \"output_size\": 17,\n",
    "        \"scaler_type\": \"jetiso\",\n",
    "        \"terminate_early\": True,\n",
    "        \"use_mll_loss\": True,\n",
    "        \"width_disc\": 0,\n",
    "        \"width_gen\": 0,\n",
    "        \"verbose\": True,\n",
    "        }\n",
    "params.update({\n",
    "})\n",
    "print params\n",
    "    \n",
    "# change tag for provenance\n",
    "params[\"tag\"] = \"v3_test\"\n",
    "\n",
    "gan = GAN(**params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling jet pts\n",
      "Scaling lep isos\n",
      "Discriminator params: 161537\n",
      "Generator params: 340497\n",
      "scaling lepton isolations\n",
      "scaling jet pts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [D loss: 0.543494999409, acc.: 0.00%] [G loss: 1.34424138069] [mll=-1.000+--1.000] [ks=999.000]\n",
      "KS score improved from 999.00 to 15.41, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_100.weights\n",
      "200 [D loss: 0.193427175283, acc.: 0.00%] [G loss: 4.62835168839] [mll=42.365+-4.936] [ks=15.409]\n",
      "KS score improved from 15.41 to 14.96, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_200.weights\n",
      "300 [D loss: 0.177920266986, acc.: 0.00%] [G loss: 5.26860952377] [mll=50.267+-5.109] [ks=14.962]]\n",
      "KS score improved from 14.96 to 14.31, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_300.weights\n",
      "400 [D loss: 0.127145722508, acc.: 0.00%] [G loss: 5.10356140137] [mll=37.862+-3.507] [ks=14.312]]\n",
      "500 [D loss: 0.0876420065761, acc.: 0.00%] [G loss: 4.73637056351] [mll=69.735+-6.224] [ks=14.440]\n",
      "10000/10000 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.py:838: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return n/db/n.sum(), bin_edges\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:74: RuntimeWarning: invalid value encountered in sqrt\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.py:780: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.py:781: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS score improved from 14.31 to 13.31, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_500.weights\n",
      "600 [D loss: 0.16150431335, acc.: 0.00%] [G loss: 6.39612531662] [mll=74.326+-6.391] [ks=13.314]]]\n",
      "700 [D loss: 0.129242509604, acc.: 0.00%] [G loss: 5.88102388382] [mll=52.119+-3.219] [ks=14.043]]\n",
      "800 [D loss: 0.495268255472, acc.: 50.00%] [G loss: 5.82737159729] [mll=48.116+-3.303] [ks=13.859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in sqrt\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:92: RuntimeWarning: Mean of empty slice.\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:110: RuntimeWarning: Mean of empty slice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 [D loss: 0.107501775026, acc.: 0.00%] [G loss: 6.36686897278] [mll=nan+-nan] [ks=15.135]]\n",
      "1000 [D loss: 0.280085474253, acc.: 0.00%] [G loss: 9.73246383667] [mll=66.062+-4.684] [ks=14.551]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "1100 [D loss: 0.101195283234, acc.: 0.00%] [G loss: 5.43694496155] [mll=28.478+-1.564] [ks=15.103]]\n",
      "1200 [D loss: 0.0824785083532, acc.: 0.00%] [G loss: 6.25630378723] [mll=54.762+-2.590] [ks=14.905]]\n",
      "1300 [D loss: 0.0819515362382, acc.: 0.00%] [G loss: 5.2771320343] [mll=62.747+-3.537] [ks=14.632]]\n",
      "1400 [D loss: 0.227467954159, acc.: 0.00%] [G loss: 5.94345426559] [mll=79.093+-4.771] [ks=13.683]]\n",
      "1500 [D loss: 0.349878698587, acc.: 0.00%] [G loss: 7.68023633957] [mll=40.112+-3.468] [ks=14.310]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "1600 [D loss: 0.115256547928, acc.: 0.00%] [G loss: 4.33609580994] [mll=55.435+-3.352] [ks=13.844]]\n",
      "KS score improved from 13.31 to 12.72, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_1600.weights\n",
      "1700 [D loss: 0.206292256713, acc.: 0.00%] [G loss: 4.21539306641] [mll=49.243+-11.496] [ks=12.725]]\n",
      "1800 [D loss: 0.168317019939, acc.: 0.00%] [G loss: 3.8672413826] [mll=39.885+-5.982] [ks=13.982]]]\n",
      "1900 [D loss: 0.19427755475, acc.: 0.00%] [G loss: 2.95180916786] [mll=51.826+-7.695] [ks=14.296]]]\n",
      "2000 [D loss: 0.188563376665, acc.: 0.00%] [G loss: 3.36741089821] [mll=64.527+-17.953] [ks=13.263]]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "KS score improved from 12.72 to 12.16, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_2000.weights\n",
      "2100 [D loss: 0.248435288668, acc.: 0.00%] [G loss: 2.93090438843] [mll=81.805+-14.757] [ks=12.160]]\n",
      "KS score improved from 12.16 to 12.07, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_2100.weights\n",
      "2200 [D loss: 0.897901296616, acc.: 0.00%] [G loss: 3.33748817444] [mll=71.458+-12.902] [ks=12.072]\n",
      "KS score improved from 12.07 to 8.68, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_2200.weights\n",
      "2300 [D loss: 0.305789589882, acc.: 0.00%] [G loss: 2.6313970089] [mll=75.634+-25.152] [ks=8.678]]]\n",
      "2400 [D loss: 0.16646271944, acc.: 0.00%] [G loss: 2.24297499657] [mll=89.508+-14.802] [ks=10.313]]]\n",
      "2500 [D loss: 0.423580884933, acc.: 0.00%] [G loss: 3.51768922806] [mll=83.918+-8.893] [ks=10.636]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "2600 [D loss: 0.225835680962, acc.: 0.00%] [G loss: 2.88084435463] [mll=70.370+-22.316] [ks=9.383]]\n",
      "2700 [D loss: 0.415610849857, acc.: 0.00%] [G loss: 2.71900582314] [mll=81.397+-8.634] [ks=9.899]]\n",
      "2800 [D loss: 0.458031386137, acc.: 0.00%] [G loss: 2.09983849525] [mll=90.116+-10.462] [ks=9.180]]\n",
      "2900 [D loss: 0.425613999367, acc.: 0.00%] [G loss: 2.03741574287] [mll=86.627+-12.164] [ks=10.938]]\n",
      "KS score improved from 8.68 to 8.19, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_2900.weights\n",
      "3000 [D loss: 0.279161185026, acc.: 0.00%] [G loss: 2.49971961975] [mll=98.645+-19.023] [ks=8.190]]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "3100 [D loss: 0.435439825058, acc.: 0.00%] [G loss: 2.40345931053] [mll=98.253+-7.506] [ks=9.311]\n",
      "3200 [D loss: 0.682713150978, acc.: 0.00%] [G loss: 1.917953372] [mll=87.434+-9.640] [ks=10.232]2]\n",
      "3300 [D loss: 0.490643024445, acc.: 0.00%] [G loss: 1.69434261322] [mll=88.357+-8.564] [ks=8.794]\n",
      "3400 [D loss: 0.446039736271, acc.: 0.00%] [G loss: 1.69013810158] [mll=92.544+-9.871] [ks=8.719]\n",
      "3500 [D loss: 0.362479746342, acc.: 0.00%] [G loss: 1.82578015327] [mll=78.961+-13.653] [ks=9.584]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "3600 [D loss: 0.257082104683, acc.: 0.00%] [G loss: 2.68659067154] [mll=90.920+-10.960] [ks=8.225]\n",
      "3700 [D loss: 0.451415538788, acc.: 0.00%] [G loss: 1.89639651775] [mll=108.600+-18.950] [ks=9.567]\n",
      "KS score improved from 8.19 to 7.89, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_3700.weights\n",
      "3800 [D loss: 0.500208318233, acc.: 0.00%] [G loss: 1.89672732353] [mll=87.854+-9.217] [ks=7.886]]\n",
      "3900 [D loss: 0.285005658865, acc.: 0.00%] [G loss: 2.11386561394] [mll=108.860+-16.287] [ks=10.297]]\n",
      "4000 [D loss: 1.28969097137, acc.: 0.00%] [G loss: 1.71152889729] [mll=90.847+-7.402] [ks=8.618]]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "4100 [D loss: 0.39248624444, acc.: 0.00%] [G loss: 1.94277870655] [mll=100.156+-12.975] [ks=11.252]]]\n",
      "4200 [D loss: 1.00252401829, acc.: 0.00%] [G loss: 2.09720635414] [mll=91.919+-6.259] [ks=8.816]]]\n",
      "KS score improved from 7.89 to 7.63, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_4200.weights\n",
      "4300 [D loss: 0.526632070541, acc.: 3.71%] [G loss: 1.80239856243] [mll=95.444+-13.713] [ks=7.633]\n",
      "4400 [D loss: 0.64133387804, acc.: 0.00%] [G loss: 2.4471642971] [mll=91.863+-27.540] [ks=9.923]]]\n",
      "4500 [D loss: 0.360147893429, acc.: 0.78%] [G loss: 2.00178551674] [mll=85.886+-7.535] [ks=9.320]]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "4600 [D loss: 0.544599056244, acc.: 0.00%] [G loss: 2.04516220093] [mll=130.758+-39.307] [ks=8.985]]\n",
      "4700 [D loss: 0.208075493574, acc.: 0.00%] [G loss: 2.32825303078] [mll=90.420+-10.311] [ks=9.356]\n",
      "4800 [D loss: 0.35927131772, acc.: 0.00%] [G loss: 1.92559361458] [mll=85.402+-5.017] [ks=8.668]]]\n",
      "4900 [D loss: 0.679570674896, acc.: 0.00%] [G loss: 1.92851340771] [mll=80.909+-5.593] [ks=10.179]]\n",
      "5000 [D loss: 0.527953267097, acc.: 0.00%] [G loss: 2.05748200417] [mll=72.698+-16.355] [ks=8.011]]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "5100 [D loss: 0.443231791258, acc.: 0.00%] [G loss: 1.95985519886] [mll=84.277+-10.767] [ks=7.958]]\n",
      "5200 [D loss: 0.348704278469, acc.: 0.00%] [G loss: 1.90377223492] [mll=91.202+-6.693] [ks=9.078]\n",
      "5300 [D loss: 0.397078096867, acc.: 0.00%] [G loss: 1.76797497272] [mll=80.023+-7.187] [ks=10.567]]\n",
      "5400 [D loss: 0.508524537086, acc.: 0.00%] [G loss: 1.69194889069] [mll=93.379+-6.806] [ks=9.027]]\n",
      "5500 [D loss: 0.197305381298, acc.: 0.00%] [G loss: 2.50123906136] [mll=84.782+-5.565] [ks=7.698]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "5600 [D loss: 0.202849000692, acc.: 0.00%] [G loss: 2.26070380211] [mll=90.372+-7.237] [ks=9.675]]\n",
      "5700 [D loss: 0.167032897472, acc.: 0.00%] [G loss: 2.56990456581] [mll=89.283+-6.939] [ks=12.152]\n",
      "5800 [D loss: 0.195552140474, acc.: 0.00%] [G loss: 2.36937117577] [mll=86.259+-8.001] [ks=10.523]]\n",
      "5900 [D loss: 0.272128194571, acc.: 0.00%] [G loss: 2.30573868752] [mll=87.406+-8.310] [ks=7.836]]\n",
      "6000 [D loss: 0.641157388687, acc.: 0.00%] [G loss: 1.73003196716] [mll=86.409+-6.516] [ks=8.453]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "KS score improved from 7.63 to 6.64, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_6000.weights\n",
      "6100 [D loss: 0.414349913597, acc.: 0.00%] [G loss: 1.80797016621] [mll=86.299+-13.831] [ks=6.644]]\n",
      "6200 [D loss: 0.379470795393, acc.: 0.00%] [G loss: 1.67227733135] [mll=101.905+-10.207] [ks=10.405]\n",
      "6300 [D loss: 0.728227198124, acc.: 0.00%] [G loss: 1.35324335098] [mll=88.871+-11.855] [ks=9.520]]\n",
      "6400 [D loss: 0.481784462929, acc.: 0.00%] [G loss: 1.66913974285] [mll=88.993+-16.360] [ks=7.095]]\n",
      "6500 [D loss: 0.402283877134, acc.: 0.00%] [G loss: 1.97719752789] [mll=90.907+-7.149] [ks=7.741]]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "6600 [D loss: 0.334454894066, acc.: 0.00%] [G loss: 1.83960747719] [mll=88.567+-9.517] [ks=8.443]]\n",
      "6700 [D loss: 0.887376308441, acc.: 0.00%] [G loss: 1.84617984295] [mll=91.192+-5.062] [ks=8.648]\n",
      "6800 [D loss: 0.356617748737, acc.: 0.00%] [G loss: 1.76632905006] [mll=81.962+-9.417] [ks=8.537]]\n",
      "6900 [D loss: 0.500591576099, acc.: 0.00%] [G loss: 1.63716769218] [mll=88.290+-6.857] [ks=7.226]\n",
      "7000 [D loss: 0.336588531733, acc.: 0.00%] [G loss: 1.67828202248] [mll=91.425+-6.903] [ks=7.232]]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "7100 [D loss: 0.20361033082, acc.: 0.00%] [G loss: 2.09305095673] [mll=88.204+-6.463] [ks=7.597]]]\n",
      "7200 [D loss: 0.347610622644, acc.: 0.00%] [G loss: 1.73542702198] [mll=84.737+-7.041] [ks=8.239]\n",
      "7300 [D loss: 0.566400885582, acc.: 0.00%] [G loss: 1.81059348583] [mll=92.521+-7.192] [ks=8.670]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7400 [D loss: 0.529989540577, acc.: 0.00%] [G loss: 1.52250850201] [mll=87.800+-6.529] [ks=7.457]\n",
      "7500 [D loss: 0.199188932776, acc.: 0.00%] [G loss: 1.8483697176] [mll=91.687+-8.821] [ks=7.169]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "7600 [D loss: 0.289612591267, acc.: 0.00%] [G loss: 2.20807266235] [mll=86.884+-6.995] [ks=9.888]]\n",
      "7700 [D loss: 0.228759050369, acc.: 0.00%] [G loss: 2.54881834984] [mll=84.089+-13.085] [ks=7.642]\n",
      "7800 [D loss: 0.347455114126, acc.: 0.00%] [G loss: 2.16551756859] [mll=73.651+-11.201] [ks=8.861]]\n",
      "7900 [D loss: 0.345539480448, acc.: 0.00%] [G loss: 2.08493494987] [mll=81.534+-7.168] [ks=9.508]]\n",
      "8000 [D loss: 0.401921123266, acc.: 0.00%] [G loss: 2.33788275719] [mll=119.204+-17.483] [ks=9.979]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "8100 [D loss: 0.146487385035, acc.: 0.00%] [G loss: 2.70609235764] [mll=86.817+-6.921] [ks=9.978]]\n",
      "8200 [D loss: 0.454458236694, acc.: 0.00%] [G loss: 2.0848531723] [mll=89.925+-10.624] [ks=8.881]]]\n",
      "8300 [D loss: 0.558543920517, acc.: 0.00%] [G loss: 2.10344982147] [mll=95.763+-7.922] [ks=8.969]\n",
      "8400 [D loss: 0.216331645846, acc.: 0.00%] [G loss: 2.47704720497] [mll=92.808+-9.131] [ks=9.328]\n",
      "8500 [D loss: 0.151656255126, acc.: 0.00%] [G loss: 2.38027095795] [mll=92.405+-8.454] [ks=7.453]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "8600 [D loss: 0.431325078011, acc.: 0.00%] [G loss: 2.43369102478] [mll=85.465+-9.708] [ks=9.126]\n",
      "8700 [D loss: 0.235934704542, acc.: 0.00%] [G loss: 3.06002759933] [mll=86.062+-8.515] [ks=7.481]\n",
      "8800 [D loss: 0.632326066494, acc.: 0.00%] [G loss: 2.48380756378] [mll=73.361+-8.181] [ks=9.899]\n",
      "KS score improved from 6.64 to 6.16, saving models to progress/jetisoscale_mllwidth_flatNegNoise_1/gen_8800.weights\n",
      "8900 [D loss: 0.220624580979, acc.: 0.00%] [G loss: 2.94775557518] [mll=86.098+-8.886] [ks=6.157]\n",
      "9000 [D loss: 0.175894930959, acc.: 0.00%] [G loss: 3.79158425331] [mll=79.300+-12.403] [ks=8.094]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "9100 [D loss: 0.345356523991, acc.: 0.00%] [G loss: 4.21570158005] [mll=58.041+-12.355] [ks=9.817]\n",
      "9200 [D loss: 0.171756625175, acc.: 0.00%] [G loss: 4.44502639771] [mll=36.093+-8.977] [ks=10.873]\n",
      "9300 [D loss: 0.159783378243, acc.: 0.00%] [G loss: 5.07649421692] [mll=49.243+-13.384] [ks=10.311]\n",
      "9400 [D loss: 0.65938526392, acc.: 0.20%] [G loss: 2.50991630554] [mll=46.881+-11.194] [ks=11.382]]\n",
      "9500 [D loss: 0.837359905243, acc.: 0.20%] [G loss: 1.66438496113] [mll=101.127+-18.073] [ks=7.854]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "9600 [D loss: 0.6589230299, acc.: 0.00%] [G loss: 1.48557400703] [mll=106.359+-29.129] [ks=7.830]0]\n",
      "9700 [D loss: 0.826374650002, acc.: 0.00%] [G loss: 1.26430857182] [mll=97.646+-11.196] [ks=7.674]\n",
      "9800 [D loss: 0.746355056763, acc.: 0.00%] [G loss: 1.1018654108] [mll=99.051+-12.058] [ks=7.361]]\n",
      "9900 [D loss: 0.710566163063, acc.: 0.00%] [G loss: 0.94828659296] [mll=94.293+-9.596] [ks=7.052]]\n",
      "10000 [D loss: 0.721437215805, acc.: 0.00%] [G loss: 0.931895315647] [mll=93.545+-8.597] [ks=7.146]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "10100 [D loss: 0.766725718975, acc.: 0.00%] [G loss: 0.980145812035] [mll=94.092+-8.789] [ks=6.750]\n",
      "10200 [D loss: 0.707005739212, acc.: 0.00%] [G loss: 0.878199160099] [mll=93.136+-6.642] [ks=7.401]\n",
      "10300 [D loss: 0.686866343021, acc.: 0.00%] [G loss: 0.928254663944] [mll=92.732+-5.887] [ks=7.386]\n",
      "10400 [D loss: 0.708736538887, acc.: 0.00%] [G loss: 0.816827833652] [mll=86.211+-5.995] [ks=7.057]\n",
      "10500 [D loss: 0.697224080563, acc.: 0.00%] [G loss: 0.807670474052] [mll=92.892+-5.718] [ks=7.128]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "10600 [D loss: 0.680984020233, acc.: 0.00%] [G loss: 0.903666496277] [mll=89.800+-5.353] [ks=7.573]\n",
      "10700 [D loss: 0.717883825302, acc.: 0.00%] [G loss: 0.857198596001] [mll=88.752+-5.205] [ks=7.303]\n",
      "10800 [D loss: 0.699153125286, acc.: 0.00%] [G loss: 0.770576238632] [mll=90.767+-5.021] [ks=7.422]\n",
      "10900 [D loss: 0.560614466667, acc.: 0.00%] [G loss: 0.77241140604] [mll=96.780+-8.660] [ks=8.023]]\n",
      "11000 [D loss: 0.68988597393, acc.: 0.00%] [G loss: 0.989890575409] [mll=87.735+-7.301] [ks=8.484]]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "11100 [D loss: 0.656450867653, acc.: 0.00%] [G loss: 0.84568965435] [mll=88.424+-6.204] [ks=7.421]]\n",
      "11200 [D loss: 0.197561860085, acc.: 0.00%] [G loss: 10.8510293961] [mll=91.685+-4.925] [ks=8.108]]\n",
      "11300 [D loss: 0.38950279355, acc.: 2.93%] [G loss: 8.54395198822] [mll=25.845+-6.530] [ks=13.181]1]\n",
      "11400 [D loss: 0.331681698561, acc.: 11.91%] [G loss: 9.79171466827] [mll=9.420+-11.431] [ks=13.377]\n",
      "11500 [D loss: 0.344260752201, acc.: 2.54%] [G loss: 8.75701808929] [mll=18.831+-13.854] [ks=12.149]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "11600 [D loss: 0.162918537855, acc.: 0.00%] [G loss: 9.56455612183] [mll=33.396+-21.132] [ks=10.875]\n",
      "11700 [D loss: 0.190179675817, acc.: 0.59%] [G loss: 8.25743579865] [mll=41.478+-21.761] [ks=10.946]\n",
      "11800 [D loss: 0.501457750797, acc.: 0.00%] [G loss: 1.66852211952] [mll=41.356+-19.417] [ks=10.826]\n",
      "11900 [D loss: 0.447331726551, acc.: 0.00%] [G loss: 1.77071261406] [mll=98.728+-25.878] [ks=9.487]\n",
      "12000 [D loss: 0.659853935242, acc.: 0.00%] [G loss: 1.31129789352] [mll=95.754+-13.540] [ks=9.289]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "12100 [D loss: 0.716202259064, acc.: 0.00%] [G loss: 0.94585287571] [mll=96.532+-12.178] [ks=8.892]]\n",
      "12200 [D loss: 0.70390856266, acc.: 0.00%] [G loss: 0.87599003315] [mll=99.985+-15.584] [ks=8.039]]]\n",
      "12300 [D loss: 0.696954250336, acc.: 0.00%] [G loss: 0.810418665409] [mll=91.881+-9.297] [ks=7.876]\n",
      "12400 [D loss: 0.698713779449, acc.: 0.00%] [G loss: 0.796290278435] [mll=91.913+-7.557] [ks=7.672]\n",
      "12500 [D loss: 0.730632305145, acc.: 0.00%] [G loss: 0.788831472397] [mll=90.159+-5.992] [ks=7.756]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "12600 [D loss: 0.733965575695, acc.: 0.39%] [G loss: 0.892134785652] [mll=90.401+-5.973] [ks=7.464]\n",
      "12700 [D loss: 0.710888624191, acc.: 0.00%] [G loss: 0.752193510532] [mll=94.228+-15.350] [ks=8.478]\n",
      "12800 [D loss: 0.703051924706, acc.: 0.00%] [G loss: 0.77872377634] [mll=89.355+-5.379] [ks=7.734]]\n",
      "12900 [D loss: 0.704571068287, acc.: 0.00%] [G loss: 0.760212004185] [mll=90.059+-5.545] [ks=7.584]\n",
      "13000 [D loss: 0.696172237396, acc.: 0.00%] [G loss: 0.758602082729] [mll=88.703+-5.647] [ks=7.384]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "13100 [D loss: 0.714317798615, acc.: 0.00%] [G loss: 0.747400403023] [mll=90.652+-5.091] [ks=7.973]\n",
      "13200 [D loss: 0.706588447094, acc.: 0.00%] [G loss: 0.726671218872] [mll=95.334+-19.581] [ks=7.474]\n",
      "13300 [D loss: 0.701441943645, acc.: 0.00%] [G loss: 0.730863511562] [mll=89.776+-5.187] [ks=7.978]\n",
      "13400 [D loss: 0.701830863953, acc.: 0.00%] [G loss: 0.726912558079] [mll=93.032+-4.904] [ks=7.735]\n",
      "13500 [D loss: 0.644997000694, acc.: 0.39%] [G loss: 0.772101342678] [mll=89.394+-5.311] [ks=7.978]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "13600 [D loss: 0.700012922287, acc.: 0.00%] [G loss: 0.734914720058] [mll=110.937+-21.746] [ks=9.266]\n",
      "13700 [D loss: 0.737430810928, acc.: 0.00%] [G loss: 0.739755094051] [mll=89.634+-4.940] [ks=7.155]\n",
      "13800 [D loss: 0.704102396965, acc.: 0.00%] [G loss: 0.715689659119] [mll=86.469+-9.510] [ks=7.855]\n",
      "13900 [D loss: 0.702721714973, acc.: 0.00%] [G loss: 0.717637956142] [mll=90.432+-5.050] [ks=7.525]\n",
      "14000 [D loss: 0.706471562386, acc.: 0.00%] [G loss: 0.711401224136] [mll=90.649+-4.620] [ks=7.395]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "14100 [D loss: 0.710967898369, acc.: 0.00%] [G loss: 0.723169744015] [mll=89.260+-4.960] [ks=7.955]\n",
      "14200 [D loss: 0.702132582664, acc.: 0.00%] [G loss: 0.730462014675] [mll=90.331+-5.037] [ks=7.532]\n",
      "14300 [D loss: 0.703139781952, acc.: 0.00%] [G loss: 0.719818592072] [mll=81.325+-6.201] [ks=8.129]\n",
      "14400 [D loss: 0.695603013039, acc.: 0.00%] [G loss: 0.710482954979] [mll=89.589+-4.451] [ks=7.829]\n",
      "14500 [D loss: 0.69992929697, acc.: 0.00%] [G loss: 0.726752400398] [mll=88.863+-4.825] [ks=7.443]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/step\n",
      "14600 [D loss: 0.707489192486, acc.: 0.00%] [G loss: 0.724672734737] [mll=95.793+-17.790] [ks=7.803]\n",
      "14700 [D loss: 0.69804251194, acc.: 0.00%] [G loss: 0.71768373251] [mll=89.927+-4.895] [ks=7.718]8]\n",
      "14800 [D loss: 0.69869440794, acc.: 0.00%] [G loss: 0.717407763004] [mll=89.955+-4.341] [ks=7.712]]\n",
      "14900 [D loss: 0.729879498482, acc.: 0.78%] [G loss: 0.742880105972] [mll=89.848+-4.982] [ks=7.398]\n",
      "15000 [D loss: 0.701477646828, acc.: 0.00%] [G loss: 0.71712833643] [mll=98.493+-19.875] [ks=7.885]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "15100 [D loss: 0.710075974464, acc.: 0.00%] [G loss: 0.713878393173] [mll=89.963+-4.731] [ks=7.839]\n",
      "15200 [D loss: 0.700734555721, acc.: 0.00%] [G loss: 0.712180018425] [mll=90.927+-5.560] [ks=7.512]\n",
      "15300 [D loss: 0.690126180649, acc.: 0.00%] [G loss: 0.72252124548] [mll=89.795+-4.994] [ks=7.338]]\n",
      "15400 [D loss: 0.704541683197, acc.: 0.00%] [G loss: 0.717221856117] [mll=89.674+-4.972] [ks=8.340]\n",
      "15500 [D loss: 0.699070930481, acc.: 0.00%] [G loss: 0.705382883549] [mll=90.155+-4.904] [ks=7.834]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "15600 [D loss: 0.712285399437, acc.: 0.00%] [G loss: 0.713163256645] [mll=89.498+-4.853] [ks=7.504]\n",
      "15700 [D loss: 0.703846335411, acc.: 0.00%] [G loss: 0.718062996864] [mll=89.209+-4.759] [ks=7.531]\n",
      "15800 [D loss: 0.761289000511, acc.: 0.20%] [G loss: 0.747161924839] [mll=90.312+-4.545] [ks=7.342]\n",
      "15900 [D loss: 0.711236953735, acc.: 0.00%] [G loss: 0.711097121239] [mll=90.903+-18.326] [ks=7.639]\n",
      "16000 [D loss: 0.704364955425, acc.: 0.00%] [G loss: 0.714070320129] [mll=90.295+-5.007] [ks=7.567]\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "16100 [D loss: 0.700371026993, acc.: 0.00%] [G loss: 0.707501649857] [mll=89.623+-4.304] [ks=7.751]\n",
      "16200 [D loss: 0.729635953903, acc.: 1.56%] [G loss: 0.760600626469] [mll=89.814+-4.538] [ks=7.631]\n",
      "16300 [D loss: 0.69905102253, acc.: 0.00%] [G loss: 0.713477373123] [mll=115.471+-23.397] [ks=9.200]]\n",
      "16400 [D loss: 0.702321112156, acc.: 0.00%] [G loss: 0.712344706059] [mll=91.262+-5.207] [ks=7.425]\n",
      "16500 [D loss: 0.704253673553, acc.: 0.00%] [G loss: 0.707785248756] [mll=93.202+-7.186] [ks=8.000]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "16600 [D loss: 0.702652990818, acc.: 0.00%] [G loss: 0.707931876183] [mll=89.546+-4.541] [ks=7.633]\n",
      "16700 [D loss: 0.709797263145, acc.: 0.20%] [G loss: 0.71113216877] [mll=89.623+-4.509] [ks=7.602]]\n",
      "16800 [D loss: 0.699889481068, acc.: 0.00%] [G loss: 0.75849366188] [mll=91.789+-7.521] [ks=8.010]]\n",
      "16900 [D loss: 0.71039557457, acc.: 0.00%] [G loss: 0.710087060928] [mll=89.479+-4.489] [ks=7.587]]\n",
      "17000 [D loss: 0.699000000954, acc.: 0.00%] [G loss: 0.712596416473] [mll=90.804+-4.261] [ks=7.711]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "17100 [D loss: 0.704932272434, acc.: 0.00%] [G loss: 0.71931552887] [mll=89.824+-4.404] [ks=7.555]]\n",
      "17200 [D loss: 0.700586557388, acc.: 0.00%] [G loss: 0.709706366062] [mll=88.073+-7.315] [ks=8.114]\n",
      "17300 [D loss: 0.708848714828, acc.: 0.00%] [G loss: 0.71263307333] [mll=89.980+-4.827] [ks=8.473]]\n",
      "17400 [D loss: 0.700271725655, acc.: 0.00%] [G loss: 0.716091096401] [mll=89.469+-4.779] [ks=7.674]\n",
      "17500 [D loss: 0.699120640755, acc.: 0.00%] [G loss: 0.723040103912] [mll=88.825+-4.971] [ks=7.851]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "17600 [D loss: 0.700001478195, acc.: 0.00%] [G loss: 0.711082220078] [mll=92.691+-4.618] [ks=7.393]\n",
      "17700 [D loss: 0.700978636742, acc.: 0.00%] [G loss: 0.709244966507] [mll=89.748+-4.529] [ks=7.581]\n",
      "17800 [D loss: 0.700844407082, acc.: 0.00%] [G loss: 0.706905901432] [mll=88.130+-4.624] [ks=8.453]\n",
      "17900 [D loss: 0.700065970421, acc.: 0.00%] [G loss: 0.711312174797] [mll=90.351+-4.678] [ks=7.040]\n",
      "18000 [D loss: 0.702637910843, acc.: 0.00%] [G loss: 0.707762360573] [mll=89.578+-4.246] [ks=7.893]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "18100 [D loss: 0.707860648632, acc.: 0.00%] [G loss: 0.706833720207] [mll=90.069+-3.940] [ks=7.790]\n",
      "18200 [D loss: 0.703128933907, acc.: 0.00%] [G loss: 0.720836281776] [mll=85.389+-5.800] [ks=7.612]\n",
      "18300 [D loss: 0.704494655132, acc.: 0.00%] [G loss: 0.713850438595] [mll=86.790+-6.606] [ks=6.968]\n",
      "18400 [D loss: 0.708937883377, acc.: 0.00%] [G loss: 0.710107564926] [mll=89.065+-4.606] [ks=7.556]\n",
      "18500 [D loss: 0.702510356903, acc.: 0.00%] [G loss: 0.707223474979] [mll=92.126+-4.602] [ks=7.743]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "18600 [D loss: 0.701928973198, acc.: 0.00%] [G loss: 0.707697808743] [mll=89.488+-4.272] [ks=7.686]\n",
      "18700 [D loss: 0.70264929533, acc.: 0.00%] [G loss: 0.711076676846] [mll=89.095+-4.863] [ks=7.892]]\n",
      "18800 [D loss: 0.701547622681, acc.: 0.00%] [G loss: 0.706002175808] [mll=88.904+-4.609] [ks=7.622]\n",
      "18900 [D loss: 0.697615385056, acc.: 0.00%] [G loss: 0.702628076077] [mll=89.101+-3.969] [ks=7.293]\n",
      "19000 [D loss: 0.711036324501, acc.: 0.00%] [G loss: 0.705906510353] [mll=90.479+-4.411] [ks=7.659]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "19100 [D loss: 0.705776929855, acc.: 0.00%] [G loss: 0.709915578365] [mll=90.364+-4.314] [ks=7.515]\n",
      "19200 [D loss: 0.703101992607, acc.: 0.20%] [G loss: 0.719289422035] [mll=89.396+-4.840] [ks=8.315]\n",
      "19300 [D loss: 0.71176636219, acc.: 0.00%] [G loss: 0.710467278957] [mll=95.662+-12.287] [ks=7.836]]\n",
      "19400 [D loss: 0.696467757225, acc.: 0.00%] [G loss: 0.70969671011] [mll=90.580+-4.630] [ks=8.267]]\n",
      "19500 [D loss: 0.706934690475, acc.: 0.00%] [G loss: 0.709642350674] [mll=89.602+-5.816] [ks=7.960]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "19600 [D loss: 0.699286937714, acc.: 0.00%] [G loss: 0.720733165741] [mll=89.258+-4.205] [ks=7.789]\n",
      "19700 [D loss: 0.699646711349, acc.: 0.00%] [G loss: 0.708502054214] [mll=88.826+-4.569] [ks=7.796]\n",
      "19800 [D loss: 0.711875498295, acc.: 0.00%] [G loss: 0.731540799141] [mll=89.793+-4.463] [ks=7.632]\n",
      "19900 [D loss: 0.704079329967, acc.: 0.00%] [G loss: 0.711399972439] [mll=89.658+-5.289] [ks=7.635]\n",
      "20000 [D loss: 0.702819824219, acc.: 0.00%] [G loss: 0.71252810955] [mll=89.479+-4.567] [ks=7.556]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "20100 [D loss: 0.728337466717, acc.: 0.00%] [G loss: 0.696385324001] [mll=90.858+-4.928] [ks=8.233]\n",
      "20200 [D loss: 0.700810074806, acc.: 0.00%] [G loss: 0.709437310696] [mll=90.336+-4.296] [ks=7.825]\n",
      "20300 [D loss: 0.720366120338, acc.: 0.00%] [G loss: 0.713273525238] [mll=89.649+-4.062] [ks=7.689]\n",
      "20400 [D loss: 0.714829325676, acc.: 0.00%] [G loss: 0.710695147514] [mll=89.795+-4.158] [ks=8.315]\n",
      "20500 [D loss: 0.723059356213, acc.: 0.00%] [G loss: 0.740845739841] [mll=89.144+-4.163] [ks=7.934]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "20600 [D loss: 0.699347019196, acc.: 0.00%] [G loss: 0.706382513046] [mll=94.621+-17.008] [ks=7.635]\n",
      "20700 [D loss: 0.701593220234, acc.: 0.00%] [G loss: 0.707633376122] [mll=89.418+-4.258] [ks=7.759]\n",
      "20800 [D loss: 0.717248618603, acc.: 0.00%] [G loss: 0.70603376627] [mll=89.941+-4.731] [ks=7.709]]\n",
      "20900 [D loss: 0.701892971992, acc.: 0.00%] [G loss: 0.710566878319] [mll=92.825+-4.678] [ks=7.867]\n",
      "21000 [D loss: 0.707755327225, acc.: 0.00%] [G loss: 0.708787977695] [mll=89.493+-4.803] [ks=7.986]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "21100 [D loss: 0.725095033646, acc.: 0.00%] [G loss: 0.710668027401] [mll=91.553+-4.162] [ks=7.950]\n",
      "21200 [D loss: 0.704995036125, acc.: 0.00%] [G loss: 0.703059673309] [mll=87.878+-4.148] [ks=7.516]\n",
      "21300 [D loss: 0.702812850475, acc.: 0.00%] [G loss: 0.719937741756] [mll=89.924+-4.057] [ks=7.676]\n",
      "21400 [D loss: 0.697327375412, acc.: 0.00%] [G loss: 0.706986427307] [mll=89.515+-4.540] [ks=7.455]\n",
      "21500 [D loss: 0.713357686996, acc.: 0.00%] [G loss: 0.711047887802] [mll=89.648+-4.339] [ks=7.570]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "21600 [D loss: 0.697749376297, acc.: 0.00%] [G loss: 0.706293165684] [mll=88.116+-4.599] [ks=7.634]\n",
      "21700 [D loss: 0.706132531166, acc.: 0.00%] [G loss: 0.70611011982] [mll=89.721+-4.480] [ks=6.992]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21800 [D loss: 0.704530537128, acc.: 0.00%] [G loss: 0.73368793726] [mll=89.283+-3.830] [ks=7.842]]\n",
      "21900 [D loss: 0.698805332184, acc.: 0.00%] [G loss: 0.714124202728] [mll=90.157+-4.602] [ks=7.663]\n",
      "22000 [D loss: 0.693287134171, acc.: 0.00%] [G loss: 0.71126806736] [mll=90.162+-4.044] [ks=7.735]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "22100 [D loss: 0.7067527771, acc.: 0.00%] [G loss: 0.720172464848] [mll=90.184+-5.136] [ks=8.390]0]\n",
      "22200 [D loss: 0.704232573509, acc.: 0.00%] [G loss: 0.710765600204] [mll=89.314+-3.916] [ks=7.625]\n",
      "22300 [D loss: 0.710889101028, acc.: 0.00%] [G loss: 0.710898816586] [mll=89.792+-4.171] [ks=7.660]\n",
      "22400 [D loss: 0.698935031891, acc.: 0.00%] [G loss: 0.713433504105] [mll=89.616+-4.547] [ks=8.367]\n",
      "22500 [D loss: 0.70094871521, acc.: 0.00%] [G loss: 0.709793508053] [mll=89.806+-3.870] [ks=7.765]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "22600 [D loss: 0.702661395073, acc.: 0.00%] [G loss: 0.710049152374] [mll=89.905+-4.239] [ks=7.908]\n",
      "22700 [D loss: 0.702098429203, acc.: 0.00%] [G loss: 0.707544922829] [mll=89.405+-4.610] [ks=8.252]\n",
      "22800 [D loss: 0.701909780502, acc.: 0.00%] [G loss: 0.706914365292] [mll=85.499+-6.388] [ks=7.728]\n",
      "22900 [D loss: 0.712539315224, acc.: 0.00%] [G loss: 0.73546230793] [mll=90.193+-4.289] [ks=7.512]]\n",
      "23000 [D loss: 0.702683448792, acc.: 0.00%] [G loss: 0.706120550632] [mll=89.160+-6.491] [ks=7.716]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "23100 [D loss: 0.702919125557, acc.: 0.00%] [G loss: 0.711601257324] [mll=90.200+-4.030] [ks=8.006]\n",
      "23200 [D loss: 0.704662561417, acc.: 0.00%] [G loss: 0.705561220646] [mll=91.019+-5.214] [ks=7.332]\n",
      "23300 [D loss: 0.700563311577, acc.: 0.00%] [G loss: 0.712097227573] [mll=88.815+-4.152] [ks=7.916]\n",
      "23400 [D loss: 0.701128959656, acc.: 0.00%] [G loss: 0.70448589325] [mll=89.416+-6.480] [ks=7.621]]\n",
      "23500 [D loss: 0.652154326439, acc.: 0.00%] [G loss: 0.731002867222] [mll=90.616+-4.096] [ks=7.495]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "23600 [D loss: 0.71023774147, acc.: 0.00%] [G loss: 0.73398244381] [mll=89.560+-6.818] [ks=10.618]8]\n",
      "23700 [D loss: 0.705714225769, acc.: 0.00%] [G loss: 0.715456902981] [mll=89.808+-4.504] [ks=7.236]\n",
      "23800 [D loss: 0.699528694153, acc.: 0.00%] [G loss: 0.710022807121] [mll=88.063+-6.138] [ks=7.630]\n",
      "23900 [D loss: 0.699610769749, acc.: 0.00%] [G loss: 0.710003435612] [mll=88.545+-4.422] [ks=7.955]\n",
      "24000 [D loss: 0.680704236031, acc.: 0.00%] [G loss: 0.730331003666] [mll=88.060+-4.219] [ks=7.905]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "24100 [D loss: 0.704107761383, acc.: 0.00%] [G loss: 0.724697172642] [mll=89.153+-5.591] [ks=8.671]\n",
      "24200 [D loss: 0.701950848103, acc.: 0.00%] [G loss: 0.714225053787] [mll=89.322+-4.183] [ks=8.014]\n",
      "24300 [D loss: 0.700500845909, acc.: 0.00%] [G loss: 0.714079380035] [mll=88.920+-4.041] [ks=7.602]\n",
      "24400 [D loss: 0.6983897686, acc.: 0.00%] [G loss: 0.7091537714] [mll=88.203+-4.720] [ks=7.662]62]]\n",
      "24500 [D loss: 0.713798284531, acc.: 0.00%] [G loss: 0.738543629646] [mll=89.729+-4.053] [ks=7.505]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "24600 [D loss: 0.702925443649, acc.: 0.00%] [G loss: 0.725243151188] [mll=90.001+-5.146] [ks=7.611]\n",
      "24700 [D loss: 0.695785284042, acc.: 0.00%] [G loss: 0.71235704422] [mll=89.269+-4.465] [ks=7.565]]\n",
      "24800 [D loss: 0.742745101452, acc.: 0.20%] [G loss: 1.47039520741] [mll=89.252+-4.246] [ks=8.125]]\n",
      "24900 [D loss: 0.707138359547, acc.: 0.00%] [G loss: 0.709188103676] [mll=98.088+-13.958] [ks=8.929]\n",
      "25000 [D loss: 0.697815537453, acc.: 0.00%] [G loss: 0.705509245396] [mll=89.433+-4.532] [ks=7.669]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "25100 [D loss: 0.701451718807, acc.: 0.00%] [G loss: 0.705754041672] [mll=88.807+-4.663] [ks=8.029]\n",
      "25200 [D loss: 0.713790178299, acc.: 0.00%] [G loss: 0.959275364876] [mll=89.286+-4.042] [ks=7.434]\n",
      "25300 [D loss: 0.701980650425, acc.: 0.00%] [G loss: 0.71210706234] [mll=83.330+-6.446] [ks=8.397]]\n",
      "25400 [D loss: 0.705575048923, acc.: 0.00%] [G loss: 0.705892026424] [mll=89.501+-4.417] [ks=7.530]\n",
      "25500 [D loss: 0.690843462944, acc.: 0.00%] [G loss: 0.710500180721] [mll=88.613+-5.226] [ks=8.114]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "25600 [D loss: 0.703983187675, acc.: 0.00%] [G loss: 0.707753717899] [mll=90.255+-3.913] [ks=7.878]\n",
      "25700 [D loss: 0.698575735092, acc.: 0.00%] [G loss: 0.708933591843] [mll=89.179+-4.328] [ks=7.816]\n",
      "25800 [D loss: 0.705902099609, acc.: 0.00%] [G loss: 0.707227647305] [mll=89.630+-4.197] [ks=7.622]\n",
      "25900 [D loss: 0.704120516777, acc.: 0.00%] [G loss: 0.714546144009] [mll=89.486+-3.804] [ks=8.047]\n",
      "26000 [D loss: 0.674013137817, acc.: 0.00%] [G loss: 0.724113404751] [mll=89.747+-4.451] [ks=7.818]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "26100 [D loss: 0.701345086098, acc.: 0.00%] [G loss: 0.711323022842] [mll=89.697+-5.204] [ks=8.767]\n",
      "26200 [D loss: 0.700978040695, acc.: 0.00%] [G loss: 0.707339763641] [mll=89.099+-4.089] [ks=7.569]\n",
      "26300 [D loss: 0.670027494431, acc.: 0.00%] [G loss: 0.721426069736] [mll=90.301+-4.060] [ks=6.965]\n",
      "26400 [D loss: 0.703320860863, acc.: 0.00%] [G loss: 0.710161685944] [mll=89.491+-4.124] [ks=8.415]\n",
      "26500 [D loss: 0.713513612747, acc.: 0.00%] [G loss: 0.70760679245] [mll=90.891+-4.047] [ks=7.799]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "26600 [D loss: 0.709051847458, acc.: 0.00%] [G loss: 0.706767976284] [mll=89.459+-3.963] [ks=6.268]\n",
      "26700 [D loss: 0.705113530159, acc.: 0.20%] [G loss: 0.72218221426] [mll=90.655+-4.891] [ks=7.828]]\n",
      "26800 [D loss: 0.708007216454, acc.: 0.00%] [G loss: 0.723792612553] [mll=96.978+-13.207] [ks=7.610]\n",
      "26900 [D loss: 0.702825784683, acc.: 0.00%] [G loss: 0.710246622562] [mll=90.358+-6.509] [ks=7.689]\n",
      "27000 [D loss: 0.709816396236, acc.: 0.00%] [G loss: 0.712015092373] [mll=89.693+-4.274] [ks=8.181]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "27100 [D loss: 0.699934959412, acc.: 0.00%] [G loss: 0.705895543098] [mll=89.572+-6.161] [ks=8.930]\n",
      "27200 [D loss: 0.709851145744, acc.: 0.00%] [G loss: 0.711376667023] [mll=88.262+-3.924] [ks=7.461]\n",
      "27300 [D loss: 0.70149731636, acc.: 0.00%] [G loss: 0.70685428381] [mll=89.379+-4.015] [ks=7.415]5]\n",
      "27400 [D loss: 0.702132225037, acc.: 0.00%] [G loss: 0.722146868706] [mll=89.000+-3.817] [ks=7.494]\n",
      "27500 [D loss: 0.697833538055, acc.: 0.00%] [G loss: 0.711794793606] [mll=89.861+-4.192] [ks=7.727]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "27600 [D loss: 0.710199832916, acc.: 0.20%] [G loss: 0.72604995966] [mll=90.264+-4.218] [ks=7.750]]\n",
      "27700 [D loss: 0.703545808792, acc.: 0.00%] [G loss: 0.707948625088] [mll=92.057+-15.174] [ks=7.715]\n",
      "27800 [D loss: 0.712291240692, acc.: 0.00%] [G loss: 0.72503054142] [mll=90.232+-4.437] [ks=7.618]]\n",
      "27900 [D loss: 0.711385965347, acc.: 0.00%] [G loss: 0.709370672703] [mll=93.470+-17.257] [ks=7.952]\n",
      "28000 [D loss: 0.703522920609, acc.: 0.00%] [G loss: 0.707180738449] [mll=89.820+-4.202] [ks=7.525]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "28100 [D loss: 0.707015097141, acc.: 0.00%] [G loss: 0.707100331783] [mll=90.832+-3.987] [ks=7.472]\n",
      "28200 [D loss: 0.718856871128, acc.: 0.00%] [G loss: 0.751123964787] [mll=89.359+-3.708] [ks=7.253]\n",
      "28300 [D loss: 0.703340888023, acc.: 0.00%] [G loss: 0.706586360931] [mll=96.046+-11.767] [ks=7.656]\n",
      "28400 [D loss: 0.718019723892, acc.: 0.00%] [G loss: 0.708038747311] [mll=90.004+-4.075] [ks=7.511]\n",
      "28500 [D loss: 0.705920815468, acc.: 0.00%] [G loss: 0.702723920345] [mll=89.656+-4.289] [ks=8.055]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "28600 [D loss: 0.721496701241, acc.: 0.00%] [G loss: 0.97861969471] [mll=88.768+-4.434] [ks=7.779]]\n",
      "28700 [D loss: 0.724328756332, acc.: 0.00%] [G loss: 0.72983366251] [mll=74.594+-7.272] [ks=10.549]]\n",
      "28800 [D loss: 0.703002750874, acc.: 0.00%] [G loss: 0.711666584015] [mll=89.432+-6.629] [ks=7.666]\n",
      "28900 [D loss: 0.702839612961, acc.: 0.00%] [G loss: 0.708131372929] [mll=89.618+-4.613] [ks=7.431]\n",
      "29000 [D loss: 0.710664272308, acc.: 0.00%] [G loss: 0.727671563625] [mll=90.853+-4.093] [ks=7.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 44us/step\n",
      "29100 [D loss: 0.699584305286, acc.: 0.00%] [G loss: 0.715140283108] [mll=81.301+-6.222] [ks=9.518]\n",
      "29200 [D loss: 0.706179857254, acc.: 0.00%] [G loss: 0.708771705627] [mll=89.553+-4.522] [ks=7.608]\n",
      "29300 [D loss: 0.698622465134, acc.: 0.00%] [G loss: 0.707758963108] [mll=90.048+-4.289] [ks=7.482]\n",
      "29400 [D loss: 0.705752909184, acc.: 0.00%] [G loss: 0.706907808781] [mll=89.804+-4.114] [ks=7.733]\n",
      "29500 [D loss: 0.679814338684, acc.: 0.00%] [G loss: 1.09984064102] [mll=89.376+-4.220] [ks=7.757]]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "29600 [D loss: 0.70498073101, acc.: 0.00%] [G loss: 0.715115964413] [mll=90.087+-6.447] [ks=8.413]]\n",
      "29700 [D loss: 0.706032454967, acc.: 0.00%] [G loss: 0.709192693233] [mll=89.479+-4.531] [ks=7.531]\n",
      "29800 [D loss: 0.702247023582, acc.: 0.00%] [G loss: 0.703200757504] [mll=89.334+-4.634] [ks=7.919]\n",
      "29900 [D loss: 0.704947650433, acc.: 0.00%] [G loss: 0.706388831139] [mll=89.070+-3.654] [ks=7.853]\n",
      "30000 [D loss: 0.720814228058, acc.: 0.00%] [G loss: 0.719064593315] [mll=89.164+-4.014] [ks=7.872]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "30100 [D loss: 0.718280553818, acc.: 0.00%] [G loss: 0.708437919617] [mll=89.530+-4.165] [ks=7.311]\n",
      "30200 [D loss: 0.703397750854, acc.: 0.00%] [G loss: 0.704884767532] [mll=89.495+-4.372] [ks=7.730]\n",
      "30300 [D loss: 0.710255861282, acc.: 0.00%] [G loss: 0.717617154121] [mll=90.618+-3.892] [ks=7.052]\n",
      "30400 [D loss: 0.70324921608, acc.: 0.00%] [G loss: 0.707472801208] [mll=90.167+-4.737] [ks=7.085]]\n",
      "30500 [D loss: 0.699709415436, acc.: 0.00%] [G loss: 0.707041621208] [mll=89.841+-4.090] [ks=7.953]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "30600 [D loss: 0.705487072468, acc.: 0.00%] [G loss: 0.708996236324] [mll=89.313+-5.603] [ks=8.707]\n",
      "30700 [D loss: 0.70376932621, acc.: 0.00%] [G loss: 0.706058442593] [mll=89.896+-4.097] [ks=7.596]]\n",
      "30800 [D loss: 0.701865613461, acc.: 0.00%] [G loss: 0.705296456814] [mll=89.757+-3.801] [ks=7.203]\n",
      "30900 [D loss: 0.702176213264, acc.: 0.00%] [G loss: 0.709626734257] [mll=92.039+-4.628] [ks=7.134]\n",
      "31000 [D loss: 0.704460024834, acc.: 0.00%] [G loss: 0.707770287991] [mll=90.328+-4.001] [ks=7.098]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "31100 [D loss: 0.703501522541, acc.: 0.00%] [G loss: 0.71065145731] [mll=85.232+-5.032] [ks=7.706]]\n",
      "31200 [D loss: 0.705423474312, acc.: 0.00%] [G loss: 0.706381857395] [mll=89.485+-4.503] [ks=7.059]\n",
      "31300 [D loss: 0.716927170753, acc.: 0.00%] [G loss: 0.71602678299] [mll=84.509+-7.272] [ks=8.486]]\n",
      "31400 [D loss: 0.700525283813, acc.: 0.00%] [G loss: 0.706600308418] [mll=89.279+-4.960] [ks=7.096]\n",
      "31500 [D loss: 0.701275587082, acc.: 0.00%] [G loss: 0.702781260014] [mll=89.314+-3.735] [ks=7.070]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "31600 [D loss: 0.704967856407, acc.: 0.00%] [G loss: 0.704695761204] [mll=89.259+-4.160] [ks=7.486]\n",
      "31700 [D loss: 0.703187227249, acc.: 0.00%] [G loss: 0.714833140373] [mll=89.671+-4.430] [ks=7.076]\n",
      "31800 [D loss: 0.710126936436, acc.: 0.00%] [G loss: 0.706055402756] [mll=89.320+-4.348] [ks=7.036]\n",
      "31900 [D loss: 0.708960771561, acc.: 0.00%] [G loss: 0.705114603043] [mll=89.888+-3.860] [ks=7.777]\n",
      "32000 [D loss: 0.703201532364, acc.: 0.00%] [G loss: 0.702868103981] [mll=88.901+-3.864] [ks=7.750]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "32100 [D loss: 0.698523581028, acc.: 0.00%] [G loss: 0.710297048092] [mll=89.862+-4.175] [ks=7.425]\n",
      "32200 [D loss: 0.702302694321, acc.: 0.00%] [G loss: 0.71486133337] [mll=89.228+-4.337] [ks=8.291]]\n",
      "32300 [D loss: 0.705286026001, acc.: 0.00%] [G loss: 0.711585640907] [mll=90.673+-4.440] [ks=7.423]\n",
      "32400 [D loss: 0.703902482986, acc.: 0.00%] [G loss: 0.705101490021] [mll=89.108+-3.893] [ks=7.727]\n",
      "32500 [D loss: 0.701431453228, acc.: 0.00%] [G loss: 0.711202859879] [mll=89.706+-3.772] [ks=7.673]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "32600 [D loss: 0.703406214714, acc.: 0.00%] [G loss: 0.705172300339] [mll=89.639+-4.306] [ks=7.490]\n",
      "32700 [D loss: 0.703514814377, acc.: 0.00%] [G loss: 0.708651661873] [mll=89.481+-3.822] [ks=7.662]\n",
      "32800 [D loss: 0.700797438622, acc.: 0.00%] [G loss: 0.703479409218] [mll=88.960+-3.908] [ks=7.453]\n",
      "32900 [D loss: 0.704503536224, acc.: 0.00%] [G loss: 0.704611361027] [mll=89.929+-4.066] [ks=7.090]\n",
      "33000 [D loss: 0.711119830608, acc.: 0.00%] [G loss: 0.712892949581] [mll=88.802+-4.492] [ks=7.853]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "33100 [D loss: 0.711114883423, acc.: 0.00%] [G loss: 0.706215977669] [mll=89.410+-4.446] [ks=7.689]\n",
      "33200 [D loss: 0.704196929932, acc.: 0.00%] [G loss: 0.703794836998] [mll=89.665+-4.033] [ks=7.263]\n",
      "33300 [D loss: 0.713573157787, acc.: 0.00%] [G loss: 0.706205248833] [mll=89.099+-4.628] [ks=7.269]\n",
      "33400 [D loss: 0.701787233353, acc.: 0.00%] [G loss: 0.705019235611] [mll=90.064+-4.576] [ks=7.193]\n",
      "33500 [D loss: 0.704580664635, acc.: 0.00%] [G loss: 0.721814215183] [mll=89.054+-4.325] [ks=7.212]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "33600 [D loss: 0.703770637512, acc.: 0.00%] [G loss: 0.709879338741] [mll=88.879+-4.625] [ks=7.409]\n",
      "33700 [D loss: 0.699923038483, acc.: 0.00%] [G loss: 0.711260676384] [mll=89.974+-4.166] [ks=7.498]\n",
      "33800 [D loss: 0.702875435352, acc.: 0.00%] [G loss: 0.707174837589] [mll=89.326+-4.500] [ks=7.949]\n",
      "33900 [D loss: 0.703749835491, acc.: 0.00%] [G loss: 0.701346993446] [mll=89.775+-4.224] [ks=7.640]\n",
      "34000 [D loss: 0.703047513962, acc.: 0.00%] [G loss: 0.705370306969] [mll=90.108+-3.766] [ks=7.621]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "34100 [D loss: 0.722351074219, acc.: 0.00%] [G loss: 0.704239428043] [mll=93.545+-7.838] [ks=7.144]\n",
      "34200 [D loss: 0.74189466238, acc.: 0.00%] [G loss: 0.712848782539] [mll=91.648+-4.813] [ks=7.106]]\n",
      "34300 [D loss: 0.708160281181, acc.: 0.00%] [G loss: 0.705533921719] [mll=84.526+-4.920] [ks=8.653]\n",
      "34400 [D loss: 0.704303860664, acc.: 0.00%] [G loss: 0.703487455845] [mll=89.106+-3.968] [ks=7.280]\n",
      "34500 [D loss: 0.726189374924, acc.: 0.78%] [G loss: 0.738067567348] [mll=88.458+-4.025] [ks=7.837]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "34600 [D loss: 0.707923173904, acc.: 0.00%] [G loss: 0.707878649235] [mll=93.669+-9.734] [ks=7.491]\n",
      "34700 [D loss: 0.703818738461, acc.: 0.00%] [G loss: 0.706589579582] [mll=85.290+-7.124] [ks=7.461]\n",
      "34800 [D loss: 0.69460952282, acc.: 0.00%] [G loss: 0.959918856621] [mll=89.170+-3.786] [ks=7.316]]\n",
      "34900 [D loss: 0.703515529633, acc.: 0.00%] [G loss: 0.707471132278] [mll=87.572+-4.786] [ks=8.046]\n",
      "35000 [D loss: 0.706387042999, acc.: 0.00%] [G loss: 0.708339691162] [mll=89.740+-4.413] [ks=7.287]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "35100 [D loss: 0.702727854252, acc.: 0.00%] [G loss: 0.70464861393] [mll=90.180+-4.258] [ks=7.187]]\n",
      "35200 [D loss: 0.702980577946, acc.: 0.00%] [G loss: 0.706472456455] [mll=89.916+-3.858] [ks=7.548]\n",
      "35300 [D loss: 0.702930808067, acc.: 0.00%] [G loss: 0.702808260918] [mll=90.923+-4.676] [ks=7.514]\n",
      "35400 [D loss: 0.70244383812, acc.: 0.00%] [G loss: 0.706149458885] [mll=88.313+-4.277] [ks=7.697]]\n",
      "35500 [D loss: 0.702509760857, acc.: 0.00%] [G loss: 0.703366339207] [mll=88.881+-4.371] [ks=7.540]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "35600 [D loss: 0.704074859619, acc.: 0.00%] [G loss: 0.707878112793] [mll=90.175+-3.698] [ks=7.596]\n",
      "35700 [D loss: 0.703077912331, acc.: 0.00%] [G loss: 0.703698396683] [mll=89.953+-3.984] [ks=7.835]\n",
      "35800 [D loss: 0.703432202339, acc.: 0.00%] [G loss: 0.706347465515] [mll=89.137+-4.056] [ks=7.540]\n",
      "35900 [D loss: 0.717727541924, acc.: 0.00%] [G loss: 0.703260302544] [mll=87.883+-5.550] [ks=7.626]\n",
      "36000 [D loss: 0.701755583286, acc.: 0.00%] [G loss: 0.70614439249] [mll=89.355+-3.837] [ks=7.488]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "36100 [D loss: 0.698288083076, acc.: 0.00%] [G loss: 0.707119524479] [mll=89.590+-3.985] [ks=7.310]\n",
      "36200 [D loss: 0.717514812946, acc.: 0.00%] [G loss: 0.705633103848] [mll=88.832+-4.734] [ks=8.790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36300 [D loss: 0.700850009918, acc.: 0.00%] [G loss: 0.702917993069] [mll=89.566+-4.179] [ks=7.574]\n",
      "36400 [D loss: 0.70106780529, acc.: 0.00%] [G loss: 0.704869329929] [mll=89.265+-4.640] [ks=8.159]]\n",
      "36500 [D loss: 0.704256176949, acc.: 0.00%] [G loss: 0.707608699799] [mll=90.125+-4.338] [ks=8.029]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "36600 [D loss: 0.709282040596, acc.: 0.20%] [G loss: 0.719597697258] [mll=88.484+-4.435] [ks=7.303]\n",
      "36700 [D loss: 0.703079462051, acc.: 0.00%] [G loss: 0.707965135574] [mll=97.410+-19.901] [ks=7.514]\n",
      "36800 [D loss: 0.704142689705, acc.: 0.00%] [G loss: 0.706653118134] [mll=90.452+-4.134] [ks=7.569]\n",
      "36900 [D loss: 0.708222985268, acc.: 0.00%] [G loss: 0.703884482384] [mll=90.535+-4.233] [ks=7.727]\n",
      "37000 [D loss: 0.701650500298, acc.: 0.00%] [G loss: 0.704204797745] [mll=89.729+-3.809] [ks=7.581]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "37100 [D loss: 0.709186553955, acc.: 0.20%] [G loss: 0.726942062378] [mll=90.895+-4.064] [ks=7.952]\n",
      "37200 [D loss: 0.702797293663, acc.: 0.00%] [G loss: 0.705707550049] [mll=98.393+-12.930] [ks=7.987]\n",
      "37300 [D loss: 0.714846372604, acc.: 0.00%] [G loss: 0.702658712864] [mll=89.756+-4.616] [ks=7.866]\n",
      "37400 [D loss: 0.706498384476, acc.: 0.00%] [G loss: 0.703085422516] [mll=89.351+-3.930] [ks=7.972]\n",
      "37500 [D loss: 0.703635513783, acc.: 0.00%] [G loss: 0.702686190605] [mll=90.040+-3.716] [ks=7.211]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "37600 [D loss: 0.710160255432, acc.: 0.00%] [G loss: 0.707535207272] [mll=89.247+-3.707] [ks=7.780]\n",
      "37700 [D loss: 0.704938292503, acc.: 0.00%] [G loss: 0.711510121822] [mll=82.226+-9.329] [ks=7.908]\n",
      "37800 [D loss: 0.711804449558, acc.: 0.00%] [G loss: 0.705846786499] [mll=89.705+-4.418] [ks=7.569]\n",
      "37900 [D loss: 0.700785815716, acc.: 0.00%] [G loss: 0.709657669067] [mll=89.776+-4.110] [ks=7.870]\n",
      "38000 [D loss: 0.70431637764, acc.: 0.00%] [G loss: 0.708472371101] [mll=89.557+-4.454] [ks=7.874]]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "38100 [D loss: 0.702884197235, acc.: 0.00%] [G loss: 0.705860078335] [mll=84.872+-8.625] [ks=7.909]\n",
      "38200 [D loss: 0.703205823898, acc.: 0.00%] [G loss: 0.703321456909] [mll=88.706+-4.876] [ks=7.540]\n",
      "38300 [D loss: 0.706349253654, acc.: 0.00%] [G loss: 0.704162955284] [mll=88.988+-3.798] [ks=7.900]\n",
      "38400 [D loss: 0.708200573921, acc.: 0.00%] [G loss: 0.708171784878] [mll=89.368+-3.598] [ks=7.486]\n",
      "38500 [D loss: 0.70666629076, acc.: 0.00%] [G loss: 0.701600015163] [mll=83.295+-11.699] [ks=7.943]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "38600 [D loss: 0.707785129547, acc.: 0.00%] [G loss: 0.707362234592] [mll=89.657+-4.121] [ks=8.003]\n",
      "38700 [D loss: 0.708031177521, acc.: 0.00%] [G loss: 0.704025030136] [mll=89.147+-4.551] [ks=7.999]\n",
      "38800 [D loss: 0.709589242935, acc.: 0.00%] [G loss: 0.712434649467] [mll=90.513+-4.923] [ks=8.163]\n",
      "38900 [D loss: 0.704985380173, acc.: 0.00%] [G loss: 0.703028202057] [mll=89.503+-4.645] [ks=7.569]\n",
      "39000 [D loss: 0.704048871994, acc.: 0.00%] [G loss: 0.704808950424] [mll=88.427+-4.090] [ks=7.459]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "39100 [D loss: 0.706122159958, acc.: 0.00%] [G loss: 0.703927874565] [mll=89.253+-3.985] [ks=7.496]\n",
      "39200 [D loss: 0.706003129482, acc.: 0.00%] [G loss: 0.703278124332] [mll=89.443+-4.256] [ks=7.565]\n",
      "39300 [D loss: 0.703964471817, acc.: 0.00%] [G loss: 0.709343969822] [mll=87.826+-4.547] [ks=7.658]\n",
      "39400 [D loss: 0.702083110809, acc.: 0.00%] [G loss: 0.711584329605] [mll=88.761+-4.424] [ks=7.692]\n",
      "39500 [D loss: 0.702261447906, acc.: 0.00%] [G loss: 0.703950047493] [mll=90.019+-4.359] [ks=7.667]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "39600 [D loss: 0.704788327217, acc.: 0.00%] [G loss: 0.707743883133] [mll=88.931+-3.827] [ks=7.580]\n",
      "39700 [D loss: 0.702739238739, acc.: 0.00%] [G loss: 0.704402804375] [mll=89.562+-4.233] [ks=7.515]\n",
      "39800 [D loss: 0.704511582851, acc.: 0.00%] [G loss: 0.71172529459] [mll=89.440+-4.294] [ks=7.670]]\n",
      "39900 [D loss: 0.704093515873, acc.: 0.00%] [G loss: 0.706227779388] [mll=89.781+-4.167] [ks=7.586]\n",
      "40000 [D loss: 0.703188300133, acc.: 0.00%] [G loss: 0.712622582912] [mll=86.257+-4.628] [ks=7.840]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "40100 [D loss: 0.703000724316, acc.: 0.00%] [G loss: 0.704824507236] [mll=89.582+-5.057] [ks=7.591]\n",
      "40200 [D loss: 0.70510661602, acc.: 0.00%] [G loss: 0.70362842083] [mll=89.929+-4.028] [ks=7.066]6]\n",
      "40300 [D loss: 0.706593215466, acc.: 0.00%] [G loss: 0.723280370235] [mll=91.196+-4.666] [ks=7.375]\n",
      "40400 [D loss: 0.702668905258, acc.: 0.00%] [G loss: 0.705026209354] [mll=88.400+-4.186] [ks=8.356]\n",
      "40500 [D loss: 0.703228831291, acc.: 0.00%] [G loss: 0.703223347664] [mll=91.570+-4.989] [ks=6.902]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "40600 [D loss: 0.70699429512, acc.: 0.00%] [G loss: 0.715272963047] [mll=89.166+-4.055] [ks=7.293]]\n",
      "40700 [D loss: 0.708550453186, acc.: 0.00%] [G loss: 0.705528855324] [mll=89.775+-4.673] [ks=7.700]\n",
      "40800 [D loss: 0.705542206764, acc.: 0.00%] [G loss: 0.704909801483] [mll=89.849+-4.238] [ks=7.316]\n",
      "40900 [D loss: 0.709576368332, acc.: 0.00%] [G loss: 0.703562676907] [mll=89.257+-3.683] [ks=7.735]\n",
      "41000 [D loss: 0.706946372986, acc.: 0.00%] [G loss: 0.708230555058] [mll=91.769+-4.716] [ks=7.622]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "41100 [D loss: 0.708038985729, acc.: 0.00%] [G loss: 0.702201366425] [mll=90.442+-4.784] [ks=7.244]\n",
      "41200 [D loss: 0.715698599815, acc.: 0.00%] [G loss: 0.707263529301] [mll=89.372+-4.432] [ks=7.504]\n",
      "41300 [D loss: 0.702968597412, acc.: 0.00%] [G loss: 0.704726696014] [mll=89.098+-4.626] [ks=6.922]\n",
      "41400 [D loss: 0.728425502777, acc.: 0.00%] [G loss: 0.703603208065] [mll=90.397+-3.899] [ks=7.370]\n",
      "41500 [D loss: 0.710096418858, acc.: 0.00%] [G loss: 0.713441371918] [mll=90.662+-4.111] [ks=7.583]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "41600 [D loss: 0.706024169922, acc.: 0.00%] [G loss: 0.704246520996] [mll=85.142+-9.368] [ks=7.619]\n",
      "41700 [D loss: 0.700954318047, acc.: 0.00%] [G loss: 0.703669130802] [mll=89.632+-4.046] [ks=7.406]\n",
      "41800 [D loss: 0.73209053278, acc.: 0.00%] [G loss: 0.708319723606] [mll=88.950+-5.184] [ks=8.843]]\n",
      "41900 [D loss: 0.702471315861, acc.: 0.00%] [G loss: 0.703992843628] [mll=87.903+-4.223] [ks=7.425]\n",
      "42000 [D loss: 0.711070895195, acc.: 0.00%] [G loss: 0.703667163849] [mll=88.277+-4.337] [ks=7.258]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "42100 [D loss: 0.703598976135, acc.: 0.00%] [G loss: 0.70326590538] [mll=90.063+-3.801] [ks=7.073]]\n",
      "42200 [D loss: 0.784073829651, acc.: 0.20%] [G loss: 1.27448785305] [mll=90.445+-4.332] [ks=7.258]]\n",
      "42300 [D loss: 0.702447712421, acc.: 0.00%] [G loss: 0.711559355259] [mll=66.012+-8.038] [ks=10.101]\n",
      "42400 [D loss: 0.703194737434, acc.: 0.00%] [G loss: 0.704984128475] [mll=88.574+-4.101] [ks=7.838]\n",
      "42500 [D loss: 0.708266735077, acc.: 0.00%] [G loss: 0.708727777004] [mll=89.908+-4.131] [ks=7.345]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "42600 [D loss: 0.704284906387, acc.: 0.00%] [G loss: 0.703947603703] [mll=90.033+-4.374] [ks=7.478]\n",
      "42700 [D loss: 0.707229435444, acc.: 0.00%] [G loss: 0.702917695045] [mll=89.928+-4.330] [ks=7.498]\n",
      "42800 [D loss: 0.704037070274, acc.: 0.00%] [G loss: 0.708225667477] [mll=89.966+-4.112] [ks=7.570]\n",
      "42900 [D loss: 0.772181391716, acc.: 0.00%] [G loss: 0.704805374146] [mll=89.215+-3.941] [ks=7.654]\n",
      "43000 [D loss: 0.716367959976, acc.: 0.00%] [G loss: 0.701926290989] [mll=89.145+-4.183] [ks=7.626]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "43100 [D loss: 0.703529119492, acc.: 0.00%] [G loss: 0.702746748924] [mll=89.464+-4.450] [ks=7.233]\n",
      "43200 [D loss: 0.738233983517, acc.: 0.00%] [G loss: 0.715968608856] [mll=90.341+-4.345] [ks=7.763]\n",
      "43300 [D loss: 0.710748791695, acc.: 0.00%] [G loss: 0.715305864811] [mll=87.065+-6.820] [ks=9.112]\n",
      "43400 [D loss: 0.725694179535, acc.: 0.00%] [G loss: 0.705718934536] [mll=89.586+-4.432] [ks=7.611]\n",
      "43500 [D loss: 0.704682767391, acc.: 0.00%] [G loss: 0.706533074379] [mll=89.497+-3.984] [ks=8.058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 48us/step\n",
      "43600 [D loss: 0.702058196068, acc.: 0.00%] [G loss: 0.70624679327] [mll=89.707+-4.074] [ks=7.435]]\n",
      "43700 [D loss: 0.705079555511, acc.: 0.00%] [G loss: 0.709217607975] [mll=90.302+-3.949] [ks=7.169]\n",
      "43800 [D loss: 0.706666350365, acc.: 0.00%] [G loss: 0.701327264309] [mll=89.836+-4.126] [ks=7.628]\n",
      "43900 [D loss: 0.707773566246, acc.: 0.00%] [G loss: 0.711154997349] [mll=88.522+-4.408] [ks=7.386]\n",
      "44000 [D loss: 0.686545968056, acc.: 0.00%] [G loss: 0.711919784546] [mll=99.165+-12.428] [ks=8.220]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "44100 [D loss: 0.701729536057, acc.: 0.00%] [G loss: 0.708920121193] [mll=90.115+-4.443] [ks=8.599]\n",
      "44200 [D loss: 0.702679395676, acc.: 0.00%] [G loss: 0.704012334347] [mll=88.837+-4.206] [ks=7.280]\n",
      "44300 [D loss: 0.70795416832, acc.: 0.00%] [G loss: 0.707663416862] [mll=88.876+-4.228] [ks=7.793]]\n",
      "44400 [D loss: 0.701652050018, acc.: 0.00%] [G loss: 0.702817976475] [mll=89.773+-4.294] [ks=7.492]\n",
      "44500 [D loss: 0.708823442459, acc.: 0.00%] [G loss: 0.702533662319] [mll=89.230+-4.034] [ks=7.536]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "44600 [D loss: 0.706250846386, acc.: 0.00%] [G loss: 0.718023836613] [mll=86.759+-4.184] [ks=7.277]\n",
      "44700 [D loss: 0.705218613148, acc.: 0.00%] [G loss: 0.70520401001] [mll=88.620+-4.536] [ks=7.600]]\n",
      "44800 [D loss: 0.722583770752, acc.: 0.00%] [G loss: 1.32283866405] [mll=89.755+-4.106] [ks=7.607]]\n",
      "44900 [D loss: 0.704047739506, acc.: 0.00%] [G loss: 0.715133666992] [mll=84.762+-6.438] [ks=8.873]\n",
      "45000 [D loss: 0.715952277184, acc.: 0.00%] [G loss: 0.705943644047] [mll=90.270+-3.985] [ks=7.191]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "45100 [D loss: 0.707856178284, acc.: 0.00%] [G loss: 0.70545142889] [mll=89.936+-4.027] [ks=7.237]]\n",
      "45200 [D loss: 0.705187499523, acc.: 0.00%] [G loss: 0.706248819828] [mll=89.650+-4.500] [ks=7.204]\n",
      "45300 [D loss: 0.708896100521, acc.: 0.00%] [G loss: 0.706584870815] [mll=90.025+-4.306] [ks=7.286]\n",
      "45400 [D loss: 0.705535888672, acc.: 0.20%] [G loss: 0.703299939632] [mll=89.685+-4.233] [ks=7.669]\n",
      "45500 [D loss: 0.705542802811, acc.: 0.00%] [G loss: 0.702076494694] [mll=92.566+-5.357] [ks=7.795]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "45600 [D loss: 0.704234004021, acc.: 0.00%] [G loss: 0.701756477356] [mll=89.816+-4.481] [ks=7.588]\n",
      "45700 [D loss: 0.703449606895, acc.: 0.00%] [G loss: 0.703981280327] [mll=89.870+-4.691] [ks=7.771]\n",
      "45800 [D loss: 0.678181231022, acc.: 0.00%] [G loss: 0.701812207699] [mll=90.276+-3.960] [ks=7.299]\n",
      "45900 [D loss: 0.710998177528, acc.: 0.00%] [G loss: 0.712767124176] [mll=87.398+-5.168] [ks=9.162]\n",
      "46000 [D loss: 0.704566240311, acc.: 0.00%] [G loss: 0.705786287785] [mll=92.467+-5.264] [ks=7.826]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "46100 [D loss: 0.704744815826, acc.: 0.00%] [G loss: 0.70153003931] [mll=89.538+-4.058] [ks=7.586]]\n",
      "46200 [D loss: 0.708228230476, acc.: 0.00%] [G loss: 0.703838407993] [mll=89.601+-4.837] [ks=7.869]\n",
      "46300 [D loss: 0.711993277073, acc.: 0.00%] [G loss: 0.706379532814] [mll=89.404+-4.241] [ks=7.889]\n",
      "46400 [D loss: 0.704443156719, acc.: 0.00%] [G loss: 0.707269728184] [mll=88.924+-4.166] [ks=8.233]\n",
      "46500 [D loss: 0.709719777107, acc.: 0.00%] [G loss: 0.703413426876] [mll=92.213+-5.928] [ks=7.551]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "46600 [D loss: 0.706542730331, acc.: 0.00%] [G loss: 0.70475935936] [mll=89.107+-4.594] [ks=7.772]]\n",
      "46700 [D loss: 0.704201579094, acc.: 0.00%] [G loss: 0.706184864044] [mll=89.004+-4.434] [ks=7.602]\n",
      "46800 [D loss: 0.704581439495, acc.: 0.00%] [G loss: 0.704301834106] [mll=89.294+-4.334] [ks=7.864]\n",
      "46900 [D loss: 0.704093039036, acc.: 0.00%] [G loss: 0.709275782108] [mll=89.270+-4.909] [ks=7.715]\n",
      "47000 [D loss: 0.704338550568, acc.: 0.00%] [G loss: 0.702460408211] [mll=89.652+-3.872] [ks=7.812]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "47100 [D loss: 0.713317811489, acc.: 0.59%] [G loss: 0.741029798985] [mll=90.269+-3.973] [ks=8.059]\n",
      "47200 [D loss: 0.713113903999, acc.: 0.00%] [G loss: 0.704658091068] [mll=94.470+-15.777] [ks=7.742]\n",
      "47300 [D loss: 0.704198181629, acc.: 0.00%] [G loss: 0.706597268581] [mll=88.090+-4.230] [ks=7.797]\n",
      "47400 [D loss: 0.703168332577, acc.: 0.00%] [G loss: 0.704563736916] [mll=89.562+-4.036] [ks=7.349]\n",
      "47500 [D loss: 0.737462103367, acc.: 0.00%] [G loss: 0.708742380142] [mll=89.263+-4.361] [ks=8.275]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "47600 [D loss: 0.704540014267, acc.: 0.00%] [G loss: 0.707204818726] [mll=89.512+-4.334] [ks=7.564]\n",
      "47700 [D loss: 0.704653263092, acc.: 0.00%] [G loss: 0.703354299068] [mll=89.558+-4.392] [ks=7.832]\n",
      "47800 [D loss: 0.707283854485, acc.: 0.00%] [G loss: 0.70490449667] [mll=89.322+-4.477] [ks=7.819]]\n",
      "47900 [D loss: 0.718616366386, acc.: 0.78%] [G loss: 0.739027440548] [mll=90.309+-4.228] [ks=7.899]\n",
      "48000 [D loss: 0.704937577248, acc.: 0.00%] [G loss: 0.704812288284] [mll=92.953+-11.739] [ks=7.948]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "48100 [D loss: 0.702898859978, acc.: 0.00%] [G loss: 0.705393850803] [mll=89.581+-4.485] [ks=7.359]\n",
      "48200 [D loss: 0.705890417099, acc.: 0.00%] [G loss: 0.70508813858] [mll=89.803+-4.221] [ks=7.247]]\n",
      "48300 [D loss: 0.716644763947, acc.: 0.00%] [G loss: 0.733866631985] [mll=88.687+-4.556] [ks=7.705]\n",
      "48400 [D loss: 0.703059315681, acc.: 0.00%] [G loss: 0.707490324974] [mll=84.756+-9.267] [ks=7.697]\n",
      "48500 [D loss: 0.72129046917, acc.: 0.00%] [G loss: 0.705996096134] [mll=91.193+-5.012] [ks=7.812]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "48600 [D loss: 0.704937458038, acc.: 0.00%] [G loss: 0.70608907938] [mll=88.776+-4.375] [ks=7.718]]\n",
      "48700 [D loss: 0.70262157917, acc.: 0.00%] [G loss: 0.710593163967] [mll=90.251+-4.249] [ks=7.570]]\n",
      "48800 [D loss: 0.709108233452, acc.: 0.00%] [G loss: 0.705761671066] [mll=89.937+-4.048] [ks=7.553]\n",
      "48900 [D loss: 0.704161286354, acc.: 0.00%] [G loss: 0.707636713982] [mll=87.084+-4.768] [ks=7.873]\n",
      "49000 [D loss: 0.706192731857, acc.: 0.00%] [G loss: 0.708283305168] [mll=85.544+-5.915] [ks=8.070]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "49100 [D loss: 0.740391016006, acc.: 0.00%] [G loss: 0.705196797848] [mll=95.361+-9.903] [ks=7.654]\n",
      "49200 [D loss: 0.727136313915, acc.: 1.37%] [G loss: 0.733143866062] [mll=89.582+-4.147] [ks=7.726]\n",
      "49300 [D loss: 0.703586578369, acc.: 0.00%] [G loss: 0.70783239603] [mll=95.062+-12.748] [ks=8.085]]\n",
      "49400 [D loss: 0.705739617348, acc.: 0.00%] [G loss: 0.705260276794] [mll=91.001+-5.205] [ks=7.746]\n",
      "49500 [D loss: 0.708503723145, acc.: 0.00%] [G loss: 0.702949941158] [mll=89.301+-4.424] [ks=7.421]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "49600 [D loss: 0.704923212528, acc.: 0.00%] [G loss: 0.708642840385] [mll=89.951+-4.430] [ks=7.516]\n",
      "49700 [D loss: 0.738011598587, acc.: 0.00%] [G loss: 0.704869866371] [mll=89.586+-3.971] [ks=7.630]\n",
      "49800 [D loss: 0.703606963158, acc.: 0.00%] [G loss: 0.703662335873] [mll=89.118+-4.814] [ks=7.935]\n",
      "49900 [D loss: 0.731547176838, acc.: 0.00%] [G loss: 0.704877793789] [mll=89.510+-4.695] [ks=8.439]\n",
      "50000 [D loss: 0.704360127449, acc.: 0.00%] [G loss: 0.705553770065] [mll=89.211+-4.331] [ks=7.670]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "50100 [D loss: 0.755123734474, acc.: 0.00%] [G loss: 0.710615217686] [mll=88.819+-4.223] [ks=7.766]\n",
      "50200 [D loss: 0.702218174934, acc.: 0.00%] [G loss: 0.703976690769] [mll=83.687+-7.855] [ks=8.038]\n",
      "50300 [D loss: 0.715358614922, acc.: 0.00%] [G loss: 0.706205785275] [mll=88.947+-4.773] [ks=7.893]\n",
      "50400 [D loss: 0.706441402435, acc.: 0.00%] [G loss: 0.703765630722] [mll=89.595+-4.013] [ks=7.696]\n",
      "50500 [D loss: 0.705992698669, acc.: 0.00%] [G loss: 0.709995627403] [mll=91.076+-4.344] [ks=7.694]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "50600 [D loss: 0.718424916267, acc.: 0.00%] [G loss: 0.711157798767] [mll=84.493+-7.543] [ks=8.221]\n",
      "50700 [D loss: 0.705571651459, acc.: 0.00%] [G loss: 0.706470012665] [mll=84.014+-5.315] [ks=7.921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50800 [D loss: 0.707016468048, acc.: 0.00%] [G loss: 0.70303195715] [mll=87.537+-5.345] [ks=8.419]]\n",
      "50900 [D loss: 0.698057711124, acc.: 0.00%] [G loss: 0.717700362206] [mll=89.903+-4.082] [ks=7.229]\n",
      "51000 [D loss: 0.703081488609, acc.: 0.00%] [G loss: 0.709699213505] [mll=89.323+-4.606] [ks=7.826]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "51100 [D loss: 0.706293940544, acc.: 0.00%] [G loss: 0.703754007816] [mll=90.375+-4.292] [ks=7.495]\n",
      "51200 [D loss: 0.722046613693, acc.: 0.00%] [G loss: 0.759471833706] [mll=90.272+-4.428] [ks=7.233]\n",
      "51300 [D loss: 0.704047083855, acc.: 0.00%] [G loss: 0.70835506916] [mll=83.375+-9.112] [ks=8.285]]\n",
      "51400 [D loss: 0.711969614029, acc.: 0.00%] [G loss: 0.705494463444] [mll=89.570+-4.078] [ks=7.854]\n",
      "51500 [D loss: 0.707624554634, acc.: 0.00%] [G loss: 0.705308914185] [mll=90.538+-3.819] [ks=8.124]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "51600 [D loss: 0.715994417667, acc.: 0.00%] [G loss: 0.7110850811] [mll=89.634+-4.336] [ks=7.652]]]\n",
      "51700 [D loss: 0.718114316463, acc.: 0.20%] [G loss: 0.717502951622] [mll=89.337+-4.373] [ks=7.668]\n",
      "51800 [D loss: 0.709078788757, acc.: 0.00%] [G loss: 0.703235149384] [mll=95.524+-10.196] [ks=8.178]\n",
      "51900 [D loss: 0.710155427456, acc.: 0.00%] [G loss: 0.70453286171] [mll=89.328+-4.346] [ks=7.484]]\n",
      "52000 [D loss: 0.703482925892, acc.: 0.00%] [G loss: 0.710837781429] [mll=89.548+-4.171] [ks=7.966]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "52100 [D loss: 0.706130623817, acc.: 0.00%] [G loss: 0.705341339111] [mll=89.444+-4.233] [ks=7.806]\n",
      "52200 [D loss: 0.713198661804, acc.: 0.00%] [G loss: 0.712857365608] [mll=89.296+-4.029] [ks=7.769]\n",
      "52300 [D loss: 0.706825017929, acc.: 0.00%] [G loss: 0.709132254124] [mll=89.330+-4.549] [ks=7.429]\n",
      "52400 [D loss: 0.705463171005, acc.: 0.00%] [G loss: 0.70452362299] [mll=90.855+-4.448] [ks=7.474]]\n",
      "52500 [D loss: 0.703462362289, acc.: 0.00%] [G loss: 0.706301271915] [mll=89.235+-3.896] [ks=7.763]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "52600 [D loss: 0.702991604805, acc.: 0.00%] [G loss: 0.706354498863] [mll=91.010+-4.413] [ks=7.647]\n",
      "52700 [D loss: 0.706699848175, acc.: 0.00%] [G loss: 0.706263899803] [mll=90.408+-4.112] [ks=7.690]\n",
      "52800 [D loss: 0.70365524292, acc.: 0.00%] [G loss: 0.706238687038] [mll=89.048+-4.943] [ks=7.368]]\n",
      "52900 [D loss: 0.709170818329, acc.: 0.00%] [G loss: 0.704019606113] [mll=89.053+-4.337] [ks=7.545]\n",
      "53000 [D loss: 0.711247205734, acc.: 0.00%] [G loss: 0.704235136509] [mll=89.373+-4.779] [ks=8.156]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "53100 [D loss: 0.709619283676, acc.: 0.00%] [G loss: 0.702456355095] [mll=88.234+-4.522] [ks=7.823]\n",
      "53200 [D loss: 0.711459875107, acc.: 0.00%] [G loss: 0.707790791988] [mll=89.300+-5.057] [ks=7.420]\n",
      "53300 [D loss: 0.707229018211, acc.: 0.00%] [G loss: 0.70635420084] [mll=89.462+-5.140] [ks=7.721]]\n",
      "53400 [D loss: 0.732319951057, acc.: 0.00%] [G loss: 0.700349271297] [mll=89.289+-4.682] [ks=7.746]\n",
      "53500 [D loss: 0.708835721016, acc.: 0.00%] [G loss: 0.706222593784] [mll=90.124+-4.111] [ks=8.178]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "53600 [D loss: 0.728145837784, acc.: 0.00%] [G loss: 0.710962831974] [mll=87.691+-4.529] [ks=7.569]\n",
      "53700 [D loss: 0.710287213326, acc.: 0.00%] [G loss: 0.705363333225] [mll=89.633+-5.068] [ks=7.800]\n",
      "53800 [D loss: 0.711405754089, acc.: 0.00%] [G loss: 0.708570837975] [mll=89.162+-4.454] [ks=7.552]\n",
      "53900 [D loss: 0.717625260353, acc.: 0.00%] [G loss: 0.706908941269] [mll=88.434+-5.062] [ks=7.466]\n",
      "54000 [D loss: 0.70597743988, acc.: 0.00%] [G loss: 0.705054819584] [mll=86.454+-7.800] [ks=8.152]]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "54100 [D loss: 0.718074977398, acc.: 0.00%] [G loss: 0.706017613411] [mll=88.509+-4.363] [ks=7.729]\n",
      "54200 [D loss: 0.707826852798, acc.: 0.00%] [G loss: 0.70541036129] [mll=89.517+-4.451] [ks=7.778]]\n",
      "54300 [D loss: 0.702239990234, acc.: 0.00%] [G loss: 0.707560956478] [mll=89.607+-3.895] [ks=7.942]\n",
      "54400 [D loss: 0.704190373421, acc.: 0.00%] [G loss: 0.703364133835] [mll=89.792+-4.432] [ks=8.214]\n",
      "54500 [D loss: 0.704968571663, acc.: 0.00%] [G loss: 0.705725073814] [mll=90.298+-4.649] [ks=7.845]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "54600 [D loss: 0.703691244125, acc.: 0.00%] [G loss: 0.711986005306] [mll=88.852+-4.270] [ks=7.620]\n",
      "54700 [D loss: 0.70315438509, acc.: 0.00%] [G loss: 0.705609083176] [mll=89.580+-4.159] [ks=7.643]]\n",
      "54800 [D loss: 0.704500198364, acc.: 0.00%] [G loss: 0.706427931786] [mll=89.407+-4.220] [ks=7.812]\n",
      "54900 [D loss: 0.721902966499, acc.: 0.00%] [G loss: 0.703329443932] [mll=89.603+-4.093] [ks=7.420]\n",
      "55000 [D loss: 0.700830042362, acc.: 0.00%] [G loss: 0.703081011772] [mll=88.797+-4.946] [ks=8.171]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "55100 [D loss: 0.702575445175, acc.: 0.00%] [G loss: 0.703401446342] [mll=93.273+-5.812] [ks=7.778]\n",
      "55200 [D loss: 0.703452825546, acc.: 0.00%] [G loss: 0.709135591984] [mll=89.949+-4.034] [ks=7.943]\n",
      "55300 [D loss: 0.711294472218, acc.: 0.00%] [G loss: 0.704068779945] [mll=90.638+-5.430] [ks=7.422]\n",
      "55400 [D loss: 0.704662203789, acc.: 0.00%] [G loss: 0.705012381077] [mll=88.907+-4.503] [ks=8.053]\n",
      "55500 [D loss: 0.691414237022, acc.: 0.00%] [G loss: 0.701380491257] [mll=89.679+-5.014] [ks=7.610]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "55600 [D loss: 0.704916298389, acc.: 0.00%] [G loss: 0.707240641117] [mll=89.107+-4.324] [ks=8.400]\n",
      "55700 [D loss: 0.707588911057, acc.: 0.00%] [G loss: 0.705419898033] [mll=89.943+-3.938] [ks=7.674]\n",
      "55800 [D loss: 0.706245183945, acc.: 0.00%] [G loss: 0.699561059475] [mll=89.540+-3.879] [ks=7.907]\n",
      "55900 [D loss: 0.705394268036, acc.: 0.00%] [G loss: 0.706010878086] [mll=88.932+-4.618] [ks=7.965]\n",
      "56000 [D loss: 0.714925289154, acc.: 0.00%] [G loss: 0.717355310917] [mll=89.617+-4.035] [ks=7.463]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "56100 [D loss: 0.709617853165, acc.: 0.00%] [G loss: 0.720166683197] [mll=90.000+-4.729] [ks=8.113]\n",
      "56200 [D loss: 0.704733133316, acc.: 0.00%] [G loss: 0.705048561096] [mll=89.134+-6.068] [ks=7.936]\n",
      "56300 [D loss: 0.705902099609, acc.: 0.00%] [G loss: 0.706850647926] [mll=90.255+-4.385] [ks=7.350]\n",
      "56400 [D loss: 0.709623634815, acc.: 0.00%] [G loss: 0.705039262772] [mll=88.892+-4.295] [ks=7.708]\n",
      "56500 [D loss: 0.704720437527, acc.: 0.00%] [G loss: 0.703502714634] [mll=90.882+-4.429] [ks=7.594]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "56600 [D loss: 0.702118456364, acc.: 0.00%] [G loss: 0.717998147011] [mll=91.224+-5.322] [ks=8.626]\n",
      "56700 [D loss: 0.704693973064, acc.: 0.00%] [G loss: 0.70686686039] [mll=90.769+-4.535] [ks=7.899]]\n",
      "56800 [D loss: 0.7274954319, acc.: 0.00%] [G loss: 0.703956186771] [mll=88.878+-4.165] [ks=7.803]3]\n",
      "56900 [D loss: 0.704985260963, acc.: 0.00%] [G loss: 0.705557286739] [mll=89.464+-4.174] [ks=6.817]\n",
      "57000 [D loss: 0.715049386024, acc.: 0.00%] [G loss: 0.704103589058] [mll=89.709+-4.211] [ks=7.429]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "57100 [D loss: 0.705594539642, acc.: 0.00%] [G loss: 0.705063223839] [mll=89.925+-4.100] [ks=7.520]\n",
      "57200 [D loss: 0.704053640366, acc.: 0.00%] [G loss: 0.70544141531] [mll=88.156+-4.268] [ks=7.799]]\n",
      "57300 [D loss: 0.703800797462, acc.: 0.00%] [G loss: 0.703411519527] [mll=89.366+-4.440] [ks=7.573]\n",
      "57400 [D loss: 0.704449892044, acc.: 0.00%] [G loss: 0.706334531307] [mll=89.987+-4.543] [ks=7.657]\n",
      "57500 [D loss: 0.704812288284, acc.: 0.00%] [G loss: 0.716145098209] [mll=89.135+-4.337] [ks=7.640]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "57600 [D loss: 0.70526689291, acc.: 0.00%] [G loss: 0.703778207302] [mll=89.882+-4.505] [ks=7.828]]\n",
      "57700 [D loss: 0.704934358597, acc.: 0.00%] [G loss: 0.703508973122] [mll=88.902+-4.505] [ks=7.888]\n",
      "57800 [D loss: 0.700283408165, acc.: 0.00%] [G loss: 0.705352902412] [mll=89.110+-3.803] [ks=8.277]\n",
      "57900 [D loss: 0.709106683731, acc.: 0.00%] [G loss: 0.705479741096] [mll=89.504+-4.278] [ks=7.635]\n",
      "58000 [D loss: 0.711475193501, acc.: 0.00%] [G loss: 0.797442018986] [mll=89.671+-4.488] [ks=7.634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 38us/step\n",
      "58100 [D loss: 0.706942439079, acc.: 0.00%] [G loss: 0.716605603695] [mll=89.148+-5.291] [ks=8.000]\n",
      "58200 [D loss: 0.703076839447, acc.: 0.00%] [G loss: 0.70525097847] [mll=89.330+-4.323] [ks=7.708]]\n",
      "58300 [D loss: 0.704707980156, acc.: 0.00%] [G loss: 0.711091518402] [mll=87.926+-4.249] [ks=7.713]\n",
      "58400 [D loss: 0.706251740456, acc.: 0.00%] [G loss: 0.708497107029] [mll=89.642+-4.295] [ks=7.576]\n",
      "58500 [D loss: 0.728201150894, acc.: 0.00%] [G loss: 0.70405870676] [mll=84.576+-6.464] [ks=7.860]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "58600 [D loss: 0.709462046623, acc.: 0.00%] [G loss: 0.702560901642] [mll=88.716+-4.134] [ks=7.946]\n",
      "58700 [D loss: 0.706125617027, acc.: 0.00%] [G loss: 0.717983722687] [mll=89.010+-4.438] [ks=7.822]\n",
      "58800 [D loss: 0.704645872116, acc.: 0.00%] [G loss: 0.705519318581] [mll=88.886+-4.755] [ks=7.687]\n",
      "58900 [D loss: 0.704095363617, acc.: 0.00%] [G loss: 0.708274304867] [mll=89.726+-4.031] [ks=7.555]\n",
      "59000 [D loss: 0.705397486687, acc.: 0.00%] [G loss: 0.704969406128] [mll=89.716+-7.171] [ks=8.263]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "59100 [D loss: 0.703533232212, acc.: 0.00%] [G loss: 0.705332517624] [mll=90.460+-5.688] [ks=7.288]\n",
      "59200 [D loss: 0.713008582592, acc.: 0.00%] [G loss: 0.762138426304] [mll=90.396+-3.989] [ks=7.476]\n",
      "59300 [D loss: 0.707278013229, acc.: 0.00%] [G loss: 0.709494173527] [mll=86.328+-5.685] [ks=8.881]\n",
      "59400 [D loss: 0.72166621685, acc.: 0.00%] [G loss: 0.704488515854] [mll=90.070+-4.475] [ks=7.532]]\n",
      "59500 [D loss: 0.706896722317, acc.: 0.00%] [G loss: 0.705913901329] [mll=87.538+-4.473] [ks=7.875]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "59600 [D loss: 0.706826686859, acc.: 0.00%] [G loss: 0.705285608768] [mll=89.358+-4.275] [ks=7.508]\n",
      "59700 [D loss: 0.704357266426, acc.: 0.00%] [G loss: 0.705873429775] [mll=89.496+-4.201] [ks=7.562]\n",
      "59800 [D loss: 0.689377129078, acc.: 0.00%] [G loss: 0.7242000103] [mll=89.359+-4.229] [ks=7.548]8]\n",
      "59900 [D loss: 0.707107841969, acc.: 0.00%] [G loss: 0.710213899612] [mll=90.705+-5.515] [ks=8.575]\n",
      "60000 [D loss: 0.70422410965, acc.: 0.00%] [G loss: 0.704608917236] [mll=89.258+-4.657] [ks=7.587]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "60100 [D loss: 0.708459615707, acc.: 0.00%] [G loss: 0.71518433094] [mll=89.523+-3.849] [ks=7.667]]\n",
      "60200 [D loss: 0.714993357658, acc.: 0.00%] [G loss: 0.706434369087] [mll=89.263+-4.330] [ks=7.830]\n",
      "60300 [D loss: 0.705738067627, acc.: 0.00%] [G loss: 0.704298615456] [mll=89.493+-4.338] [ks=7.834]\n",
      "60400 [D loss: 0.705009698868, acc.: 0.00%] [G loss: 0.705521643162] [mll=88.670+-4.921] [ks=7.631]\n",
      "60500 [D loss: 0.706007838249, acc.: 0.00%] [G loss: 0.706089615822] [mll=90.195+-4.045] [ks=7.888]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "60600 [D loss: 0.704517245293, acc.: 0.00%] [G loss: 0.70953553915] [mll=89.690+-4.321] [ks=7.572]]\n",
      "60700 [D loss: 0.703102350235, acc.: 0.00%] [G loss: 0.706592023373] [mll=90.159+-4.089] [ks=7.788]\n",
      "60800 [D loss: 0.695198178291, acc.: 0.00%] [G loss: 0.703660547733] [mll=88.669+-5.148] [ks=8.259]\n",
      "60900 [D loss: 0.71796131134, acc.: 0.00%] [G loss: 0.710280179977] [mll=88.854+-4.175] [ks=8.406]]\n",
      "61000 [D loss: 0.708417654037, acc.: 0.00%] [G loss: 0.711111009121] [mll=88.669+-5.335] [ks=7.810]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "61100 [D loss: 0.715871930122, acc.: 0.00%] [G loss: 0.714307367802] [mll=96.125+-11.246] [ks=8.165]\n",
      "61200 [D loss: 0.703936040401, acc.: 0.00%] [G loss: 0.708831787109] [mll=89.560+-4.604] [ks=7.846]\n",
      "61300 [D loss: 0.708149075508, acc.: 0.00%] [G loss: 0.706898927689] [mll=89.504+-5.434] [ks=7.911]\n",
      "61400 [D loss: 0.705969929695, acc.: 0.00%] [G loss: 0.7084030509] [mll=89.953+-3.775] [ks=7.942]2]\n",
      "61500 [D loss: 0.711749076843, acc.: 0.00%] [G loss: 0.706237375736] [mll=89.247+-4.609] [ks=7.954]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "61600 [D loss: 0.704745948315, acc.: 0.00%] [G loss: 0.713010847569] [mll=89.618+-4.365] [ks=7.628]\n",
      "61700 [D loss: 0.702924072742, acc.: 0.00%] [G loss: 0.705757200718] [mll=89.692+-4.754] [ks=7.486]\n",
      "61800 [D loss: 0.706341743469, acc.: 0.00%] [G loss: 0.716520667076] [mll=88.813+-4.640] [ks=7.651]\n",
      "61900 [D loss: 0.707607746124, acc.: 0.00%] [G loss: 0.714230954647] [mll=92.639+-6.867] [ks=8.199]\n",
      "62000 [D loss: 0.704799234867, acc.: 0.00%] [G loss: 0.709216535091] [mll=85.552+-6.556] [ks=8.126]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "62100 [D loss: 0.702611625195, acc.: 0.00%] [G loss: 0.71426320076] [mll=89.616+-4.062] [ks=7.733]]\n",
      "62200 [D loss: 0.708235502243, acc.: 0.00%] [G loss: 0.716834783554] [mll=90.241+-4.342] [ks=7.508]\n",
      "62300 [D loss: 0.704921126366, acc.: 0.00%] [G loss: 0.703329503536] [mll=90.008+-4.718] [ks=7.761]\n",
      "62400 [D loss: 0.70915722847, acc.: 0.00%] [G loss: 0.729352414608] [mll=89.216+-5.428] [ks=8.351]]\n",
      "62500 [D loss: 0.703428387642, acc.: 0.00%] [G loss: 0.706454753876] [mll=85.351+-7.528] [ks=8.020]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "62600 [D loss: 0.711700677872, acc.: 0.00%] [G loss: 0.706952095032] [mll=89.080+-3.884] [ks=7.948]\n",
      "62700 [D loss: 0.706108093262, acc.: 0.00%] [G loss: 0.718761444092] [mll=90.849+-6.521] [ks=7.637]\n",
      "62800 [D loss: 0.70961356163, acc.: 0.00%] [G loss: 0.705257475376] [mll=90.014+-4.472] [ks=7.791]]\n",
      "62900 [D loss: 0.709942758083, acc.: 0.00%] [G loss: 0.706084251404] [mll=89.367+-4.482] [ks=7.921]\n",
      "63000 [D loss: 0.728770017624, acc.: 0.00%] [G loss: 0.710685133934] [mll=85.684+-6.300] [ks=7.582]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "63100 [D loss: 0.705611765385, acc.: 0.00%] [G loss: 0.704263925552] [mll=89.296+-4.204] [ks=7.725]\n",
      "63200 [D loss: 0.705160021782, acc.: 0.00%] [G loss: 0.702370166779] [mll=89.832+-4.130] [ks=7.624]\n",
      "63300 [D loss: 0.70493555069, acc.: 0.00%] [G loss: 0.769291341305] [mll=89.341+-4.163] [ks=7.455]]\n",
      "63400 [D loss: 0.704903960228, acc.: 0.00%] [G loss: 0.704198420048] [mll=89.694+-4.268] [ks=7.291]\n",
      "63500 [D loss: 0.698790311813, acc.: 0.00%] [G loss: 0.706547379494] [mll=88.770+-4.255] [ks=7.560]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "63600 [D loss: 0.708878397942, acc.: 0.00%] [G loss: 0.710346281528] [mll=89.189+-4.576] [ks=8.110]\n",
      "63700 [D loss: 0.706235706806, acc.: 0.00%] [G loss: 0.704686701298] [mll=89.851+-4.519] [ks=7.583]\n",
      "63800 [D loss: 0.704460501671, acc.: 0.00%] [G loss: 0.704560875893] [mll=90.057+-4.441] [ks=7.588]\n",
      "63900 [D loss: 0.703125, acc.: 0.00%] [G loss: 0.704926073551] [mll=89.493+-4.476] [ks=7.547].547]]\n",
      "64000 [D loss: 0.708221197128, acc.: 0.00%] [G loss: 0.708570420742] [mll=89.387+-3.999] [ks=7.804]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "64100 [D loss: 0.699051141739, acc.: 0.00%] [G loss: 0.707852840424] [mll=90.560+-4.518] [ks=7.513]\n",
      "64200 [D loss: 0.704004704952, acc.: 0.00%] [G loss: 0.704337656498] [mll=89.407+-4.176] [ks=8.013]\n",
      "64300 [D loss: 0.703625679016, acc.: 0.00%] [G loss: 0.705339431763] [mll=89.515+-4.243] [ks=7.554]\n",
      "64400 [D loss: 0.710473775864, acc.: 0.00%] [G loss: 0.706362009048] [mll=89.018+-4.135] [ks=8.237]\n",
      "64500 [D loss: 0.714672327042, acc.: 0.00%] [G loss: 0.703030586243] [mll=89.370+-4.079] [ks=7.799]\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "64600 [D loss: 0.704634189606, acc.: 0.00%] [G loss: 0.705836176872] [mll=89.826+-4.023] [ks=7.450]\n",
      "64700 [D loss: 0.706011533737, acc.: 0.00%] [G loss: 0.706482291222] [mll=89.082+-3.862] [ks=7.644]\n",
      "64800 [D loss: 0.695800423622, acc.: 0.00%] [G loss: 0.705428063869] [mll=88.824+-4.620] [ks=7.746]\n",
      "64900 [D loss: 0.705693900585, acc.: 0.00%] [G loss: 0.70599591732] [mll=89.392+-4.995] [ks=8.149]]\n",
      "65000 [D loss: 0.706297338009, acc.: 0.00%] [G loss: 0.706633508205] [mll=89.389+-4.335] [ks=7.498]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "65100 [D loss: 0.707103610039, acc.: 0.00%] [G loss: 0.706030726433] [mll=88.143+-5.909] [ks=7.644]\n",
      "65200 [D loss: 0.704328298569, acc.: 0.00%] [G loss: 0.724182963371] [mll=90.104+-4.350] [ks=7.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65300 [D loss: 0.702761352062, acc.: 0.00%] [G loss: 0.707858324051] [mll=87.899+-5.067] [ks=7.754]\n",
      "65400 [D loss: 0.70861184597, acc.: 0.00%] [G loss: 0.704893052578] [mll=86.926+-4.163] [ks=7.918]]\n",
      "65500 [D loss: 0.706847786903, acc.: 0.00%] [G loss: 0.714886724949] [mll=89.630+-4.477] [ks=7.754]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "65600 [D loss: 0.705080688, acc.: 0.00%] [G loss: 0.705821871758] [mll=88.988+-4.524] [ks=8.038]38]\n",
      "65700 [D loss: 0.703048467636, acc.: 0.00%] [G loss: 0.70515024662] [mll=88.884+-4.350] [ks=7.388]]\n",
      "65800 [D loss: 0.697033464909, acc.: 0.00%] [G loss: 0.744991838932] [mll=87.484+-5.420] [ks=8.275]\n",
      "65900 [D loss: 0.707593739033, acc.: 0.00%] [G loss: 0.717441618443] [mll=89.783+-4.943] [ks=7.608]\n",
      "66000 [D loss: 0.695333600044, acc.: 0.00%] [G loss: 0.718168020248] [mll=87.424+-4.652] [ks=8.119]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "66100 [D loss: 0.704408288002, acc.: 0.00%] [G loss: 0.707244455814] [mll=89.202+-4.989] [ks=8.417]\n",
      "66200 [D loss: 0.70658916235, acc.: 0.00%] [G loss: 0.707147359848] [mll=89.693+-4.767] [ks=7.457]]\n",
      "66300 [D loss: 0.706390857697, acc.: 0.00%] [G loss: 0.712418198586] [mll=89.234+-4.775] [ks=7.758]\n",
      "66400 [D loss: 0.703602671623, acc.: 0.00%] [G loss: 0.70695823431] [mll=89.353+-5.161] [ks=7.775]]\n",
      "66500 [D loss: 0.703580737114, acc.: 0.00%] [G loss: 0.706410646439] [mll=89.393+-4.536] [ks=7.826]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "66600 [D loss: 0.70436924696, acc.: 0.00%] [G loss: 0.703706979752] [mll=91.747+-5.074] [ks=8.148]]\n",
      "66700 [D loss: 0.70719063282, acc.: 0.00%] [G loss: 0.706196248531] [mll=90.006+-4.735] [ks=7.546]]\n",
      "66800 [D loss: 0.703844428062, acc.: 0.00%] [G loss: 0.713531494141] [mll=89.497+-5.264] [ks=7.522]\n",
      "66900 [D loss: 0.712611198425, acc.: 0.00%] [G loss: 0.713063776493] [mll=85.873+-7.396] [ks=8.219]\n",
      "67000 [D loss: 0.70846426487, acc.: 0.00%] [G loss: 0.702361702919] [mll=89.446+-4.519] [ks=7.813]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "67100 [D loss: 0.727309584618, acc.: 0.00%] [G loss: 0.721558988094] [mll=89.142+-4.913] [ks=8.231]\n",
      "67200 [D loss: 0.707341074944, acc.: 0.00%] [G loss: 0.711315691471] [mll=86.263+-6.705] [ks=8.354]\n",
      "67300 [D loss: 0.707735002041, acc.: 0.00%] [G loss: 0.706101298332] [mll=89.534+-4.612] [ks=7.522]\n",
      "67400 [D loss: 0.707414567471, acc.: 0.00%] [G loss: 0.729238033295] [mll=89.574+-4.289] [ks=7.533]\n",
      "67500 [D loss: 0.705072045326, acc.: 0.00%] [G loss: 0.708274900913] [mll=89.240+-5.438] [ks=7.720]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "67600 [D loss: 0.702448129654, acc.: 0.00%] [G loss: 0.708043515682] [mll=88.603+-4.497] [ks=7.870]\n",
      "67700 [D loss: 0.707162737846, acc.: 0.00%] [G loss: 0.708312630653] [mll=89.693+-4.776] [ks=8.240]\n",
      "67800 [D loss: 0.711369991302, acc.: 0.00%] [G loss: 0.706529200077] [mll=89.166+-4.444] [ks=7.871]\n",
      "67900 [D loss: 0.707110464573, acc.: 0.00%] [G loss: 0.708028912544] [mll=89.368+-4.592] [ks=7.711]\n",
      "68000 [D loss: 0.705908358097, acc.: 0.00%] [G loss: 0.713969707489] [mll=90.192+-4.567] [ks=7.584]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "68100 [D loss: 0.704969882965, acc.: 0.00%] [G loss: 0.70651614666] [mll=89.072+-4.960] [ks=7.595]]\n",
      "68200 [D loss: 0.697466135025, acc.: 0.00%] [G loss: 0.737366735935] [mll=88.372+-4.519] [ks=7.514]\n",
      "68300 [D loss: 0.703053534031, acc.: 0.00%] [G loss: 0.716045379639] [mll=89.105+-4.332] [ks=8.054]\n",
      "68400 [D loss: 0.704288959503, acc.: 0.00%] [G loss: 0.704802393913] [mll=90.184+-4.397] [ks=7.685]\n",
      "68500 [D loss: 0.719517767429, acc.: 0.00%] [G loss: 0.707180023193] [mll=89.970+-4.440] [ks=7.616]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "68600 [D loss: 0.722460985184, acc.: 0.00%] [G loss: 0.702773034573] [mll=88.973+-5.073] [ks=8.101]\n",
      "68700 [D loss: 0.707151174545, acc.: 0.00%] [G loss: 0.714425325394] [mll=89.695+-4.551] [ks=7.925]\n",
      "68800 [D loss: 0.70422577858, acc.: 0.00%] [G loss: 0.706846177578] [mll=90.037+-5.476] [ks=7.830]]\n",
      "68900 [D loss: 0.710554718971, acc.: 0.00%] [G loss: 0.707267820835] [mll=88.272+-4.970] [ks=8.086]\n",
      "69000 [D loss: 0.830224573612, acc.: 0.00%] [G loss: 0.732061445713] [mll=88.981+-5.293] [ks=8.102]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "69100 [D loss: 0.709846556187, acc.: 0.00%] [G loss: 0.709605276585] [mll=87.550+-6.574] [ks=7.986]\n",
      "69200 [D loss: 0.718869328499, acc.: 0.00%] [G loss: 0.7075330019] [mll=89.024+-5.252] [ks=7.682]]]\n",
      "69300 [D loss: 0.704389810562, acc.: 0.00%] [G loss: 0.704938471317] [mll=89.808+-4.289] [ks=7.421]\n",
      "69400 [D loss: 0.708352804184, acc.: 0.00%] [G loss: 0.706196188927] [mll=89.719+-4.387] [ks=7.968]\n",
      "69500 [D loss: 0.706373393536, acc.: 0.00%] [G loss: 0.705364465714] [mll=89.487+-4.857] [ks=7.859]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "69600 [D loss: 0.706304907799, acc.: 0.00%] [G loss: 0.737335264683] [mll=92.325+-5.893] [ks=7.543]\n",
      "69700 [D loss: 0.72765403986, acc.: 0.00%] [G loss: 0.710080564022] [mll=89.581+-4.404] [ks=7.778]]\n",
      "69800 [D loss: 0.700862646103, acc.: 0.00%] [G loss: 0.700761318207] [mll=90.138+-4.784] [ks=7.971]\n",
      "69900 [D loss: 0.707265734673, acc.: 0.00%] [G loss: 0.705216288567] [mll=89.291+-4.843] [ks=8.415]\n",
      "70000 [D loss: 0.704001545906, acc.: 0.00%] [G loss: 0.706335663795] [mll=89.790+-4.291] [ks=7.644]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "70100 [D loss: 0.702257633209, acc.: 0.00%] [G loss: 0.708200335503] [mll=89.119+-4.530] [ks=7.684]\n",
      "70200 [D loss: 0.685889959335, acc.: 0.00%] [G loss: 0.712861478329] [mll=88.660+-4.595] [ks=7.907]\n",
      "70300 [D loss: 0.705178260803, acc.: 0.00%] [G loss: 0.710746645927] [mll=88.673+-4.842] [ks=8.187]\n",
      "70400 [D loss: 0.707154154778, acc.: 0.00%] [G loss: 0.705808579922] [mll=88.939+-4.667] [ks=7.670]\n",
      "70500 [D loss: 0.704288005829, acc.: 0.00%] [G loss: 0.706576108932] [mll=90.396+-4.270] [ks=7.566]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "70600 [D loss: 0.702396452427, acc.: 0.00%] [G loss: 0.707960665226] [mll=89.183+-4.730] [ks=8.076]\n",
      "70700 [D loss: 0.704226255417, acc.: 0.00%] [G loss: 0.709916472435] [mll=89.074+-4.378] [ks=8.057]\n",
      "70800 [D loss: 0.705460071564, acc.: 0.00%] [G loss: 0.716585755348] [mll=89.331+-4.605] [ks=7.778]\n",
      "70900 [D loss: 0.723331212997, acc.: 0.00%] [G loss: 0.747556746006] [mll=88.411+-5.674] [ks=7.752]\n",
      "71000 [D loss: 0.708542823792, acc.: 0.00%] [G loss: 0.715645372868] [mll=78.060+-11.475] [ks=8.913]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "71100 [D loss: 0.704221606255, acc.: 0.00%] [G loss: 0.710478067398] [mll=86.054+-7.860] [ks=8.730]\n",
      "71200 [D loss: 0.703382968903, acc.: 0.00%] [G loss: 0.711088061333] [mll=89.856+-4.582] [ks=7.487]\n",
      "71300 [D loss: 0.704903364182, acc.: 0.00%] [G loss: 0.705159425735] [mll=88.166+-5.047] [ks=8.154]\n",
      "71400 [D loss: 0.709774553776, acc.: 0.00%] [G loss: 0.709886133671] [mll=87.739+-5.468] [ks=7.755]\n",
      "71500 [D loss: 0.710003554821, acc.: 0.00%] [G loss: 0.705104112625] [mll=88.817+-4.624] [ks=7.658]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "71600 [D loss: 0.705031275749, acc.: 0.00%] [G loss: 0.70696491003] [mll=88.214+-5.577] [ks=7.661]]\n",
      "71700 [D loss: 0.707698225975, acc.: 0.00%] [G loss: 0.710357666016] [mll=89.457+-4.384] [ks=7.595]\n",
      "71800 [D loss: 0.726882100105, acc.: 0.00%] [G loss: 1.16136991978] [mll=89.654+-4.884] [ks=7.646]]\n",
      "71900 [D loss: 0.705138623714, acc.: 0.00%] [G loss: 0.709960460663] [mll=79.990+-9.936] [ks=9.967]\n",
      "72000 [D loss: 0.706898212433, acc.: 0.00%] [G loss: 0.711040735245] [mll=90.218+-6.971] [ks=7.489]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "72100 [D loss: 0.707604646683, acc.: 0.00%] [G loss: 0.708861231804] [mll=89.141+-4.655] [ks=8.222]\n",
      "72200 [D loss: 0.739777028561, acc.: 1.76%] [G loss: 0.789520680904] [mll=89.318+-4.892] [ks=7.806]\n",
      "72300 [D loss: 0.88874745369, acc.: 0.39%] [G loss: 0.84045124054] [mll=90.676+-16.847] [ks=8.061]]]\n",
      "72400 [D loss: 0.707409381866, acc.: 0.00%] [G loss: 0.715845167637] [mll=73.897+-8.791] [ks=10.310]\n",
      "72500 [D loss: 0.704431533813, acc.: 0.00%] [G loss: 0.706688821316] [mll=89.244+-4.708] [ks=7.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/step\n",
      "72600 [D loss: 0.695140480995, acc.: 0.00%] [G loss: 0.710871756077] [mll=89.457+-4.550] [ks=7.644]\n",
      "72700 [D loss: 0.706516265869, acc.: 0.00%] [G loss: 0.711598336697] [mll=89.550+-4.584] [ks=8.381]\n",
      "72800 [D loss: 0.703250527382, acc.: 0.00%] [G loss: 0.706912279129] [mll=90.267+-4.226] [ks=7.815]\n",
      "72900 [D loss: 0.702127218246, acc.: 0.00%] [G loss: 0.71602845192] [mll=90.533+-5.490] [ks=7.544]]\n",
      "73000 [D loss: 0.702574789524, acc.: 0.00%] [G loss: 0.705981612206] [mll=89.434+-4.178] [ks=7.734]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "73100 [D loss: 0.694884061813, acc.: 0.00%] [G loss: 0.716850042343] [mll=89.828+-4.868] [ks=7.477]\n",
      "73200 [D loss: 0.709050297737, acc.: 0.00%] [G loss: 0.711908400059] [mll=89.599+-4.316] [ks=8.840]\n",
      "73300 [D loss: 0.71434879303, acc.: 0.00%] [G loss: 0.765931546688] [mll=89.144+-4.250] [ks=8.069]]\n",
      "73400 [D loss: 0.708480060101, acc.: 0.00%] [G loss: 0.746765553951] [mll=89.499+-4.705] [ks=8.287]\n",
      "73500 [D loss: 0.705338358879, acc.: 0.00%] [G loss: 0.712935864925] [mll=89.874+-4.803] [ks=8.619]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "73600 [D loss: 0.707144677639, acc.: 0.00%] [G loss: 0.716840863228] [mll=90.177+-3.925] [ks=7.697]\n",
      "73700 [D loss: 0.706596374512, acc.: 0.00%] [G loss: 0.73251581192] [mll=90.988+-4.150] [ks=7.736]]\n",
      "73800 [D loss: 0.706765174866, acc.: 0.00%] [G loss: 0.718820035458] [mll=90.780+-4.144] [ks=7.194]\n",
      "73900 [D loss: 0.716243445873, acc.: 0.00%] [G loss: 0.708106458187] [mll=89.097+-3.990] [ks=7.670]\n",
      "74000 [D loss: 0.707161545753, acc.: 0.00%] [G loss: 0.706943929195] [mll=90.763+-5.065] [ks=7.523]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "74100 [D loss: 0.705824136734, acc.: 0.00%] [G loss: 0.70550429821] [mll=85.557+-7.968] [ks=8.368]]\n",
      "74200 [D loss: 0.704169750214, acc.: 0.00%] [G loss: 0.707179665565] [mll=89.191+-3.602] [ks=8.326]\n",
      "74300 [D loss: 0.70421397686, acc.: 0.00%] [G loss: 0.709599137306] [mll=88.657+-4.108] [ks=7.765]]\n",
      "74400 [D loss: 0.703057348728, acc.: 0.00%] [G loss: 0.71656870842] [mll=88.681+-5.138] [ks=7.460]]\n",
      "74500 [D loss: 0.703920960426, acc.: 0.00%] [G loss: 0.710180222988] [mll=88.433+-5.062] [ks=8.794]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "74600 [D loss: 0.711655795574, acc.: 0.00%] [G loss: 0.720765650272] [mll=88.722+-3.450] [ks=7.434]\n",
      "74700 [D loss: 0.64975631237, acc.: 0.00%] [G loss: 1.12845885754] [mll=89.719+-3.545] [ks=7.882]]]\n",
      "74800 [D loss: 0.494595021009, acc.: 2.15%] [G loss: 2.51114106178] [mll=84.836+-4.121] [ks=9.198]]\n",
      "74900 [D loss: 0.0142944697291, acc.: 0.00%] [G loss: 16.1395702362] [mll=16.951+-6.204] [ks=13.620]\n",
      "75000 [D loss: 0.012282198295, acc.: 0.00%] [G loss: 16.1298389435] [mll=86.248+-12.979] [ks=12.989]]]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "75100 [D loss: 0.00706287845969, acc.: 0.00%] [G loss: 16.1233768463] [mll=80.221+-6.601] [ks=13.590]\n",
      "75200 [D loss: 0.0179849639535, acc.: 0.00%] [G loss: 16.1246509552] [mll=84.174+-5.051] [ks=13.297]]\n",
      "75300 [D loss: 0.00526615604758, acc.: 0.00%] [G loss: 16.1237392426] [mll=83.010+-4.269] [ks=13.380]\n",
      "75400 [D loss: 0.00977083854377, acc.: 0.00%] [G loss: 16.1226978302] [mll=83.369+-3.822] [ks=13.572]\n",
      "75500 [D loss: 0.0121606197208, acc.: 0.00%] [G loss: 16.121421814] [mll=84.870+-3.836] [ks=13.598]8]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "75600 [D loss: 0.00704658962786, acc.: 0.00%] [G loss: 16.1228199005] [mll=87.573+-3.938] [ks=13.414]\n",
      "75700 [D loss: 0.00496974727139, acc.: 0.00%] [G loss: 16.1216030121] [mll=85.194+-3.731] [ks=13.624]\n",
      "75800 [D loss: 0.00579745089635, acc.: 0.00%] [G loss: 16.1225299835] [mll=87.021+-3.798] [ks=13.473]\n",
      "75900 [D loss: 0.00612801639363, acc.: 0.00%] [G loss: 16.1215343475] [mll=85.574+-3.678] [ks=13.594]\n",
      "76000 [D loss: 0.012767332606, acc.: 0.00%] [G loss: 16.1226902008] [mll=91.817+-4.249] [ks=13.277]7]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "76100 [D loss: 0.0108461789787, acc.: 0.00%] [G loss: 16.1213855743] [mll=93.178+-4.212] [ks=13.413]]\n",
      "76200 [D loss: 0.00568092148751, acc.: 0.00%] [G loss: 16.1213665009] [mll=91.314+-3.986] [ks=13.211]\n",
      "76300 [D loss: 0.00657485518605, acc.: 0.00%] [G loss: 16.1215190887] [mll=91.244+-4.002] [ks=13.189]\n",
      "76400 [D loss: 0.00906326249242, acc.: 0.00%] [G loss: 16.1211624146] [mll=90.948+-4.020] [ks=13.143]\n",
      "76500 [D loss: 0.0091494359076, acc.: 0.00%] [G loss: 16.1210842133] [mll=88.636+-3.851] [ks=13.266]]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "76600 [D loss: 0.00554787693545, acc.: 0.00%] [G loss: 16.1210918427] [mll=89.766+-3.841] [ks=13.140]\n",
      "76700 [D loss: 0.00651254085824, acc.: 0.00%] [G loss: 16.1213512421] [mll=89.333+-3.867] [ks=13.172]\n",
      "76800 [D loss: 0.00483292434365, acc.: 0.00%] [G loss: 16.121843338] [mll=88.015+-3.829] [ks=13.303]]\n",
      "76900 [D loss: 0.0075167240575, acc.: 0.00%] [G loss: 16.1211452484] [mll=91.960+-4.033] [ks=13.176]]\n",
      "77000 [D loss: 0.0133000202477, acc.: 0.00%] [G loss: 16.1211166382] [mll=90.171+-4.067] [ks=13.058]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "77100 [D loss: 0.0083741825074, acc.: 0.00%] [G loss: 16.1212520599] [mll=88.941+-3.892] [ks=13.190]]\n",
      "77200 [D loss: 0.00593446334824, acc.: 0.00%] [G loss: 16.1212768555] [mll=90.690+-3.893] [ks=13.072]\n",
      "77300 [D loss: 0.00578840682283, acc.: 0.00%] [G loss: 16.121175766] [mll=88.339+-3.773] [ks=13.242]]\n",
      "77400 [D loss: 0.00615430017933, acc.: 0.00%] [G loss: 16.1211853027] [mll=88.307+-3.804] [ks=13.247]\n",
      "77500 [D loss: 0.00689180754125, acc.: 0.00%] [G loss: 16.1210842133] [mll=88.857+-3.787] [ks=13.176]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "77600 [D loss: 0.00532656442374, acc.: 0.00%] [G loss: 16.1211032867] [mll=89.543+-3.850] [ks=13.112]\n",
      "77700 [D loss: 0.00723953638226, acc.: 0.00%] [G loss: 16.1212444305] [mll=88.982+-3.908] [ks=13.180]\n",
      "77800 [D loss: 0.00610243622214, acc.: 0.00%] [G loss: 16.1211147308] [mll=90.772+-3.895] [ks=13.052]\n",
      "77900 [D loss: 0.17928057909, acc.: 0.00%] [G loss: 16.1211261749] [mll=89.963+-3.882] [ks=13.061]61]\n",
      "78000 [D loss: 0.0145069435239, acc.: 0.00%] [G loss: 16.1211929321] [mll=88.865+-3.793] [ks=13.183]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "78100 [D loss: 0.25096860528, acc.: 0.00%] [G loss: 16.1210956573] [mll=88.640+-3.920] [ks=13.200]00]\n",
      "78200 [D loss: 0.0058999764733, acc.: 0.00%] [G loss: 16.1210956573] [mll=89.129+-3.807] [ks=13.165]]\n",
      "78300 [D loss: 0.00702305883169, acc.: 0.00%] [G loss: 16.1211681366] [mll=90.048+-3.915] [ks=13.037]\n",
      "78400 [D loss: 0.00646181870252, acc.: 0.00%] [G loss: 16.1210842133] [mll=90.816+-3.935] [ks=13.044]\n",
      "78500 [D loss: 0.00598483718932, acc.: 0.00%] [G loss: 16.1212787628] [mll=89.746+-3.984] [ks=13.092]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "78600 [D loss: 0.38981166482, acc.: 16.02%] [G loss: 16.6946716309] [mll=88.523+-3.797] [ks=13.218]]]\n",
      "78700 [D loss: 0.281492859125, acc.: 0.20%] [G loss: 6.36724042892] [mll=22.067+-13.714] [ks=11.950]]\n",
      "78800 [D loss: 0.210229054093, acc.: 0.00%] [G loss: 9.77799606323] [mll=26.574+-15.678] [ks=11.836]\n",
      "78900 [D loss: 0.202999085188, acc.: 0.59%] [G loss: 5.14699172974] [mll=37.383+-15.695] [ks=11.638]\n",
      "79000 [D loss: 0.585071802139, acc.: 0.00%] [G loss: 1.40732383728] [mll=41.589+-15.661] [ks=11.084]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "79100 [D loss: 0.676457941532, acc.: 0.20%] [G loss: 1.04017794132] [mll=99.962+-11.495] [ks=9.074]\n",
      "79200 [D loss: 0.725250840187, acc.: 0.00%] [G loss: 1.58446967602] [mll=103.435+-17.222] [ks=8.661]]\n",
      "79300 [D loss: 0.616489768028, acc.: 0.20%] [G loss: 0.976929306984] [mll=80.919+-12.037] [ks=9.397]\n",
      "79400 [D loss: 0.690012693405, acc.: 0.00%] [G loss: 0.88850748539] [mll=92.641+-7.976] [ks=7.967]]\n",
      "79500 [D loss: 0.70943582058, acc.: 0.00%] [G loss: 0.81804984808] [mll=91.356+-6.023] [ks=7.588]8]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "79600 [D loss: 0.743656098843, acc.: 1.17%] [G loss: 0.799752295017] [mll=88.904+-5.859] [ks=7.739]\n",
      "79700 [D loss: 0.710202157497, acc.: 0.00%] [G loss: 0.759328782558] [mll=97.383+-16.010] [ks=7.755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79800 [D loss: 0.705422759056, acc.: 0.00%] [G loss: 0.749280571938] [mll=89.751+-5.255] [ks=7.401]\n",
      "79900 [D loss: 0.706346035004, acc.: 0.00%] [G loss: 0.734133780003] [mll=87.079+-5.390] [ks=7.523]\n",
      "80000 [D loss: 0.702314376831, acc.: 0.00%] [G loss: 0.729128420353] [mll=89.424+-4.820] [ks=7.126]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "80100 [D loss: 0.691939949989, acc.: 0.00%] [G loss: 0.726843357086] [mll=90.220+-4.678] [ks=7.102]\n",
      "80200 [D loss: 0.570588707924, acc.: 0.00%] [G loss: 0.806951522827] [mll=90.500+-4.915] [ks=7.087]\n",
      "80300 [D loss: 0.65716445446, acc.: 0.00%] [G loss: 0.805899679661] [mll=85.477+-8.091] [ks=9.009]]\n",
      "80400 [D loss: 0.709477782249, acc.: 0.00%] [G loss: 0.764591157436] [mll=89.741+-5.016] [ks=7.749]\n",
      "80500 [D loss: 0.640580296516, acc.: 0.00%] [G loss: 0.763883531094] [mll=91.421+-6.481] [ks=7.952]\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "80600 [D loss: 0.700973749161, acc.: 0.00%] [G loss: 0.732680916786] [mll=88.678+-5.714] [ks=7.940]\n",
      "80700 [D loss: 0.718721032143, acc.: 0.00%] [G loss: 0.722054958344] [mll=89.557+-4.089] [ks=7.933]\n",
      "80800 [D loss: 0.702906847, acc.: 0.00%] [G loss: 0.719645261765] [mll=90.395+-4.320] [ks=7.545]5]]\n",
      "80900 [D loss: 0.701765298843, acc.: 0.00%] [G loss: 0.717853546143] [mll=90.140+-4.104] [ks=7.482]\n",
      "81000 [D loss: 0.70302772522, acc.: 0.00%] [G loss: 0.718961298466] [mll=87.469+-3.995] [ks=7.891]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "81100 [D loss: 0.707947552204, acc.: 0.00%] [G loss: 0.718866407871] [mll=89.918+-4.554] [ks=7.764]\n",
      "81200 [D loss: 0.700613737106, acc.: 0.00%] [G loss: 0.726629793644] [mll=89.020+-4.666] [ks=7.705]\n",
      "81300 [D loss: 0.69943022728, acc.: 0.00%] [G loss: 0.71789509058] [mll=89.361+-4.373] [ks=7.547]7]\n",
      "81400 [D loss: 0.699929475784, acc.: 0.00%] [G loss: 0.711722910404] [mll=89.302+-4.158] [ks=7.581]\n",
      "81500 [D loss: 0.711595773697, acc.: 0.00%] [G loss: 0.707730233669] [mll=88.728+-4.087] [ks=7.780]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "81600 [D loss: 0.700896501541, acc.: 0.00%] [G loss: 0.709590554237] [mll=89.853+-4.010] [ks=7.578]\n",
      "81700 [D loss: 0.701777815819, acc.: 0.00%] [G loss: 0.720652580261] [mll=88.402+-4.448] [ks=7.561]\n",
      "81800 [D loss: 0.714764297009, acc.: 0.00%] [G loss: 0.711977422237] [mll=89.381+-4.380] [ks=7.751]\n",
      "81900 [D loss: 0.722578108311, acc.: 0.00%] [G loss: 0.752205908298] [mll=90.753+-4.108] [ks=7.552]\n",
      "82000 [D loss: 0.701327383518, acc.: 0.00%] [G loss: 0.712819218636] [mll=92.523+-10.976] [ks=7.683]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "82100 [D loss: 0.709431767464, acc.: 0.00%] [G loss: 0.713551580906] [mll=89.788+-4.954] [ks=7.320]\n",
      "82200 [D loss: 0.697259426117, acc.: 0.00%] [G loss: 0.709121227264] [mll=89.724+-4.430] [ks=7.676]\n",
      "82300 [D loss: 0.701877593994, acc.: 0.00%] [G loss: 0.709100782871] [mll=89.047+-4.373] [ks=7.772]\n",
      "82400 [D loss: 0.653924703598, acc.: 0.00%] [G loss: 0.751187682152] [mll=90.507+-4.484] [ks=7.820]\n",
      "82500 [D loss: 0.712240099907, acc.: 0.00%] [G loss: 0.726225495338] [mll=89.540+-4.472] [ks=8.589]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "82600 [D loss: 0.699178338051, acc.: 0.00%] [G loss: 0.71469026804] [mll=90.334+-4.612] [ks=7.400]]\n",
      "82700 [D loss: 0.69917422533, acc.: 0.00%] [G loss: 0.714094221592] [mll=89.800+-4.230] [ks=8.196]]\n",
      "82800 [D loss: 0.70233720541, acc.: 0.00%] [G loss: 0.725187659264] [mll=89.870+-4.164] [ks=7.264]]\n",
      "82900 [D loss: 0.700884521008, acc.: 0.00%] [G loss: 0.716554760933] [mll=89.475+-4.515] [ks=7.119]\n",
      "83000 [D loss: 0.70726442337, acc.: 0.00%] [G loss: 0.708515584469] [mll=89.615+-4.224] [ks=7.860]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "83100 [D loss: 0.695149004459, acc.: 0.00%] [G loss: 0.712692677975] [mll=88.779+-4.700] [ks=8.006]\n",
      "83200 [D loss: 0.69878745079, acc.: 0.00%] [G loss: 0.715078115463] [mll=89.788+-4.871] [ks=8.513]]\n",
      "83300 [D loss: 0.703642129898, acc.: 0.00%] [G loss: 0.70794737339] [mll=91.217+-4.045] [ks=7.884]]\n",
      "83400 [D loss: 0.697911560535, acc.: 0.00%] [G loss: 0.703995585442] [mll=86.576+-4.238] [ks=8.362]\n",
      "83500 [D loss: 0.700465083122, acc.: 0.00%] [G loss: 0.706541895866] [mll=89.528+-4.305] [ks=8.110]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "83600 [D loss: 0.700590133667, acc.: 0.00%] [G loss: 0.704842209816] [mll=89.104+-4.313] [ks=7.753]\n",
      "83700 [D loss: 0.703360795975, acc.: 0.00%] [G loss: 0.704818665981] [mll=90.116+-4.209] [ks=7.497]\n",
      "83800 [D loss: 0.707738280296, acc.: 0.00%] [G loss: 0.703829348087] [mll=90.512+-4.411] [ks=7.785]\n",
      "83900 [D loss: 0.730814933777, acc.: 0.00%] [G loss: 0.702744364738] [mll=90.522+-4.031] [ks=7.951]\n",
      "84000 [D loss: 0.702170610428, acc.: 0.00%] [G loss: 0.704822778702] [mll=90.753+-4.289] [ks=7.837]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "84100 [D loss: 0.708560824394, acc.: 0.00%] [G loss: 0.707942485809] [mll=90.181+-4.519] [ks=7.603]\n",
      "84200 [D loss: 0.707877933979, acc.: 0.00%] [G loss: 0.706044912338] [mll=90.148+-4.300] [ks=7.798]\n",
      "84300 [D loss: 0.701398253441, acc.: 0.00%] [G loss: 0.698488771915] [mll=89.882+-4.419] [ks=7.900]\n",
      "84400 [D loss: 0.717576980591, acc.: 0.00%] [G loss: 0.701460599899] [mll=89.752+-4.139] [ks=8.290]\n",
      "84500 [D loss: 0.709035158157, acc.: 0.00%] [G loss: 0.70415019989] [mll=89.223+-3.957] [ks=8.107]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "84600 [D loss: 0.708299398422, acc.: 0.00%] [G loss: 0.706955313683] [mll=88.418+-4.204] [ks=7.969]\n",
      "84700 [D loss: 0.707243919373, acc.: 0.00%] [G loss: 0.704093396664] [mll=90.280+-4.328] [ks=7.590]\n",
      "84800 [D loss: 0.724268376827, acc.: 0.00%] [G loss: 0.707493245602] [mll=88.897+-4.320] [ks=7.840]\n",
      "84900 [D loss: 0.701189756393, acc.: 0.00%] [G loss: 0.715146005154] [mll=90.087+-4.563] [ks=7.466]\n",
      "85000 [D loss: 0.700018703938, acc.: 0.00%] [G loss: 0.706719338894] [mll=88.752+-3.786] [ks=7.780]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "85100 [D loss: 0.703099966049, acc.: 0.00%] [G loss: 0.703359127045] [mll=95.188+-8.802] [ks=7.942]\n",
      "85200 [D loss: 0.701537132263, acc.: 0.00%] [G loss: 0.708631575108] [mll=88.244+-4.266] [ks=8.202]\n",
      "85300 [D loss: 0.705458879471, acc.: 0.00%] [G loss: 0.710672497749] [mll=89.378+-4.270] [ks=7.884]\n",
      "85400 [D loss: 0.730845928192, acc.: 0.00%] [G loss: 0.704184055328] [mll=90.036+-4.033] [ks=8.050]\n",
      "85500 [D loss: 0.698074579239, acc.: 0.00%] [G loss: 0.704873502254] [mll=89.609+-3.938] [ks=7.741]\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "85600 [D loss: 0.708603978157, acc.: 0.00%] [G loss: 0.706153333187] [mll=88.241+-4.171] [ks=8.520]\n",
      "85700 [D loss: 0.704363465309, acc.: 0.00%] [G loss: 0.702057421207] [mll=89.787+-4.039] [ks=8.319]\n",
      "85800 [D loss: 0.700482368469, acc.: 0.00%] [G loss: 0.705368876457] [mll=90.250+-4.135] [ks=7.833]\n",
      "85900 [D loss: 0.700810849667, acc.: 0.00%] [G loss: 0.717766165733] [mll=90.162+-3.725] [ks=8.128]\n",
      "86000 [D loss: 0.703638195992, acc.: 0.00%] [G loss: 0.708353936672] [mll=87.391+-5.571] [ks=9.393]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "86100 [D loss: 0.700590193272, acc.: 0.00%] [G loss: 0.704960346222] [mll=89.412+-4.295] [ks=7.620]\n",
      "86200 [D loss: 0.708001077175, acc.: 0.00%] [G loss: 0.751672625542] [mll=90.415+-4.881] [ks=8.116]\n",
      "86300 [D loss: 0.702294230461, acc.: 0.00%] [G loss: 0.721556782722] [mll=91.413+-9.073] [ks=7.305]\n",
      "86400 [D loss: 0.702681839466, acc.: 0.00%] [G loss: 0.711655378342] [mll=89.637+-4.142] [ks=7.555]\n",
      "86500 [D loss: 0.703613162041, acc.: 0.00%] [G loss: 0.704276323318] [mll=89.306+-4.280] [ks=7.627]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "86600 [D loss: 0.700465202332, acc.: 0.00%] [G loss: 0.704042971134] [mll=90.173+-4.260] [ks=7.559]\n",
      "86700 [D loss: 0.703796207905, acc.: 0.00%] [G loss: 0.704772531986] [mll=89.499+-3.964] [ks=7.814]\n",
      "86800 [D loss: 0.70312076807, acc.: 0.00%] [G loss: 0.704639494419] [mll=89.458+-4.141] [ks=7.868]]\n",
      "86900 [D loss: 0.718008518219, acc.: 0.00%] [G loss: 0.707617819309] [mll=90.248+-4.598] [ks=7.837]\n",
      "87000 [D loss: 0.701326191425, acc.: 0.00%] [G loss: 0.704145550728] [mll=90.230+-4.389] [ks=7.462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 49us/step\n",
      "87100 [D loss: 0.701674342155, acc.: 0.00%] [G loss: 0.704911828041] [mll=89.466+-4.126] [ks=8.223]\n",
      "87200 [D loss: 0.711409807205, acc.: 0.00%] [G loss: 0.706970572472] [mll=89.933+-4.778] [ks=7.982]\n",
      "87300 [D loss: 0.700053393841, acc.: 0.00%] [G loss: 0.701713621616] [mll=89.273+-4.578] [ks=7.918]\n",
      "87400 [D loss: 0.699244976044, acc.: 0.00%] [G loss: 0.7052064538] [mll=89.461+-4.659] [ks=8.161]1]\n",
      "87500 [D loss: 0.724468111992, acc.: 0.00%] [G loss: 0.705771386623] [mll=90.201+-4.393] [ks=7.802]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "87600 [D loss: 0.706119596958, acc.: 0.00%] [G loss: 0.709461331367] [mll=89.966+-4.447] [ks=7.979]\n",
      "87700 [D loss: 0.714619278908, acc.: 0.00%] [G loss: 0.710584759712] [mll=89.959+-4.276] [ks=7.533]\n",
      "87800 [D loss: 0.702573657036, acc.: 0.00%] [G loss: 0.702879905701] [mll=89.372+-3.873] [ks=7.655]\n",
      "87900 [D loss: 0.717646062374, acc.: 0.00%] [G loss: 0.701784074306] [mll=89.196+-4.231] [ks=7.954]\n",
      "88000 [D loss: 0.704095721245, acc.: 0.00%] [G loss: 0.706195473671] [mll=89.900+-4.376] [ks=8.076]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "88100 [D loss: 0.706816911697, acc.: 0.00%] [G loss: 0.707610547543] [mll=89.614+-4.461] [ks=7.671]\n",
      "88200 [D loss: 0.703437268734, acc.: 0.00%] [G loss: 0.705621242523] [mll=89.771+-4.846] [ks=7.776]\n",
      "88300 [D loss: 0.705300569534, acc.: 0.00%] [G loss: 0.706647932529] [mll=89.010+-4.380] [ks=7.655]\n",
      "88400 [D loss: 0.700642466545, acc.: 0.00%] [G loss: 0.70731985569] [mll=89.433+-4.333] [ks=7.935]]\n",
      "88500 [D loss: 0.70204859972, acc.: 0.00%] [G loss: 0.708227217197] [mll=89.720+-4.472] [ks=7.610]]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "88600 [D loss: 0.697148442268, acc.: 0.00%] [G loss: 0.705531358719] [mll=88.790+-4.922] [ks=8.141]\n",
      "88700 [D loss: 0.707594871521, acc.: 0.00%] [G loss: 0.703814387321] [mll=90.615+-4.923] [ks=7.827]\n",
      "88800 [D loss: 0.718758642673, acc.: 0.00%] [G loss: 0.704500734806] [mll=89.352+-4.335] [ks=7.954]\n",
      "88900 [D loss: 0.723136603832, acc.: 0.00%] [G loss: 0.705601751804] [mll=89.231+-4.346] [ks=8.061]\n",
      "89000 [D loss: 0.700344026089, acc.: 0.00%] [G loss: 0.707325518131] [mll=90.120+-5.182] [ks=7.968]\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "89100 [D loss: 0.70211315155, acc.: 0.00%] [G loss: 0.705669462681] [mll=89.446+-4.364] [ks=8.203]]\n",
      "89200 [D loss: 0.702480792999, acc.: 0.00%] [G loss: 0.715872228146] [mll=90.582+-4.965] [ks=7.638]\n",
      "89300 [D loss: 0.702987670898, acc.: 0.00%] [G loss: 0.704706072807] [mll=89.312+-4.747] [ks=7.735]\n",
      "89400 [D loss: 0.699405431747, acc.: 0.00%] [G loss: 0.711199164391] [mll=89.306+-4.487] [ks=7.628]\n",
      "89500 [D loss: 0.700973391533, acc.: 0.00%] [G loss: 0.70906072855] [mll=89.624+-4.304] [ks=7.757]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "89600 [D loss: 0.704056978226, acc.: 0.00%] [G loss: 0.709847986698] [mll=89.590+-4.283] [ks=7.601]\n",
      "89700 [D loss: 0.701538443565, acc.: 0.00%] [G loss: 0.710876405239] [mll=90.360+-4.413] [ks=7.483]\n",
      "89800 [D loss: 0.703137040138, acc.: 0.00%] [G loss: 0.707801580429] [mll=90.061+-4.611] [ks=7.256]\n",
      "89900 [D loss: 0.710016846657, acc.: 0.00%] [G loss: 0.705850064754] [mll=89.272+-4.134] [ks=8.140]\n",
      "90000 [D loss: 0.704299271107, acc.: 0.00%] [G loss: 1.0204821825] [mll=89.218+-4.129] [ks=7.648]8]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "90100 [D loss: 0.701146304607, acc.: 0.00%] [G loss: 0.709450364113] [mll=84.913+-5.623] [ks=8.417]\n",
      "90200 [D loss: 0.70470893383, acc.: 0.00%] [G loss: 0.701569974422] [mll=89.006+-4.491] [ks=7.826]]\n",
      "90300 [D loss: 0.706020474434, acc.: 0.00%] [G loss: 0.708212375641] [mll=89.960+-4.385] [ks=7.558]\n",
      "90400 [D loss: 0.707456469536, acc.: 0.00%] [G loss: 0.710913598537] [mll=88.790+-5.138] [ks=7.871]\n",
      "90500 [D loss: 0.743196964264, acc.: 0.00%] [G loss: 1.30299055576] [mll=89.572+-4.290] [ks=8.072]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "90600 [D loss: 0.7042979002, acc.: 0.00%] [G loss: 0.714105069637] [mll=70.369+-8.011] [ks=9.804]4]\n",
      "90700 [D loss: 0.720710158348, acc.: 0.00%] [G loss: 0.727885186672] [mll=89.876+-4.485] [ks=7.880]\n",
      "90800 [D loss: 0.703329086304, acc.: 0.00%] [G loss: 0.710049211979] [mll=89.805+-5.665] [ks=8.252]\n",
      "90900 [D loss: 0.723165869713, acc.: 0.00%] [G loss: 0.704801142216] [mll=89.659+-4.199] [ks=7.564]\n",
      "91000 [D loss: 0.710784435272, acc.: 0.00%] [G loss: 0.705919384956] [mll=89.879+-4.516] [ks=7.521]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "91100 [D loss: 0.704052686691, acc.: 0.00%] [G loss: 0.706589281559] [mll=88.415+-4.650] [ks=7.849]\n",
      "91200 [D loss: 0.706453621387, acc.: 0.00%] [G loss: 0.70421653986] [mll=89.264+-4.535] [ks=7.808]]\n",
      "91300 [D loss: 0.703181028366, acc.: 0.00%] [G loss: 0.705988526344] [mll=90.102+-3.740] [ks=7.619]\n",
      "91400 [D loss: 0.701944828033, acc.: 0.00%] [G loss: 0.712142407894] [mll=90.292+-4.314] [ks=7.672]\n",
      "91500 [D loss: 0.70196390152, acc.: 0.00%] [G loss: 0.704638898373] [mll=90.156+-4.069] [ks=7.796]]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "91600 [D loss: 0.704320728779, acc.: 0.00%] [G loss: 0.70133548975] [mll=89.635+-4.133] [ks=7.292]]\n",
      "91700 [D loss: 0.70112746954, acc.: 0.00%] [G loss: 0.704535126686] [mll=89.582+-4.336] [ks=7.867]]\n",
      "91800 [D loss: 0.700720310211, acc.: 0.00%] [G loss: 0.705556631088] [mll=89.535+-4.479] [ks=7.508]\n",
      "91900 [D loss: 0.705939054489, acc.: 0.00%] [G loss: 0.703580498695] [mll=89.814+-4.398] [ks=7.670]\n",
      "92000 [D loss: 0.704188704491, acc.: 0.00%] [G loss: 0.704009115696] [mll=88.978+-4.061] [ks=7.448]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "92100 [D loss: 0.700188219547, acc.: 0.20%] [G loss: 0.707809388638] [mll=89.484+-4.303] [ks=7.547]\n",
      "92200 [D loss: 0.710038423538, acc.: 0.20%] [G loss: 0.724954664707] [mll=89.597+-4.154] [ks=7.744]\n",
      "92300 [D loss: 0.702243089676, acc.: 0.00%] [G loss: 0.711183488369] [mll=92.288+-12.698] [ks=7.758]\n",
      "92400 [D loss: 0.701217472553, acc.: 0.00%] [G loss: 0.706545591354] [mll=89.220+-4.936] [ks=7.562]\n",
      "92500 [D loss: 0.700169086456, acc.: 0.00%] [G loss: 0.714201033115] [mll=89.721+-5.692] [ks=8.016]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "92600 [D loss: 0.72846955061, acc.: 0.00%] [G loss: 0.782410562038] [mll=89.847+-4.106] [ks=7.493]]\n",
      "92700 [D loss: 0.702318429947, acc.: 0.00%] [G loss: 0.713370859623] [mll=77.859+-9.887] [ks=9.780]\n",
      "92800 [D loss: 0.702287077904, acc.: 0.00%] [G loss: 0.706466257572] [mll=89.346+-4.332] [ks=7.657]\n",
      "92900 [D loss: 0.701317369938, acc.: 0.00%] [G loss: 0.70538020134] [mll=89.779+-4.913] [ks=7.763]]\n",
      "93000 [D loss: 0.738179624081, acc.: 0.00%] [G loss: 0.706695616245] [mll=88.514+-4.803] [ks=8.568]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "93100 [D loss: 0.672829031944, acc.: 0.00%] [G loss: 0.706224799156] [mll=91.062+-4.098] [ks=7.396]\n",
      "93200 [D loss: 0.703478932381, acc.: 0.00%] [G loss: 0.714779913425] [mll=90.455+-5.148] [ks=8.435]\n",
      "93300 [D loss: 0.70104777813, acc.: 0.00%] [G loss: 0.710363805294] [mll=89.090+-4.923] [ks=7.618]]\n",
      "93400 [D loss: 0.726265966892, acc.: 0.00%] [G loss: 0.71485131979] [mll=89.847+-4.866] [ks=8.631]]\n",
      "93500 [D loss: 0.71418428421, acc.: 0.00%] [G loss: 0.707154691219] [mll=88.956+-5.384] [ks=7.640]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "93600 [D loss: 0.682597279549, acc.: 0.00%] [G loss: 0.749918401241] [mll=89.617+-4.474] [ks=7.783]\n",
      "93700 [D loss: 0.706804037094, acc.: 0.00%] [G loss: 0.71709895134] [mll=88.465+-5.319] [ks=8.420]]\n",
      "93800 [D loss: 0.703484892845, acc.: 0.00%] [G loss: 0.715456962585] [mll=89.288+-4.524] [ks=7.618]\n",
      "93900 [D loss: 0.727092981339, acc.: 0.00%] [G loss: 0.70919907093] [mll=89.739+-4.644] [ks=7.514]]\n",
      "94000 [D loss: 0.705764293671, acc.: 0.00%] [G loss: 0.706913113594] [mll=89.081+-4.684] [ks=7.634]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "94100 [D loss: 0.707990407944, acc.: 0.00%] [G loss: 0.709831297398] [mll=89.679+-4.538] [ks=7.628]\n",
      "94200 [D loss: 0.702834129333, acc.: 0.00%] [G loss: 0.707592427731] [mll=89.201+-4.985] [ks=8.539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94300 [D loss: 0.701837062836, acc.: 0.00%] [G loss: 0.701689004898] [mll=89.451+-3.861] [ks=7.527]\n",
      "94400 [D loss: 0.703336119652, acc.: 0.00%] [G loss: 0.705847680569] [mll=89.667+-4.959] [ks=7.811]\n",
      "94500 [D loss: 0.707735180855, acc.: 0.00%] [G loss: 0.708938717842] [mll=88.617+-4.809] [ks=7.814]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "94600 [D loss: 0.696179270744, acc.: 0.00%] [G loss: 0.711414694786] [mll=89.667+-4.599] [ks=8.187]\n",
      "94700 [D loss: 0.703978419304, acc.: 0.00%] [G loss: 0.710113584995] [mll=89.284+-4.406] [ks=8.896]\n",
      "94800 [D loss: 0.708265542984, acc.: 0.00%] [G loss: 0.712186455727] [mll=88.533+-4.812] [ks=7.696]\n",
      "94900 [D loss: 0.701207876205, acc.: 0.00%] [G loss: 0.706555604935] [mll=88.578+-5.910] [ks=7.989]\n",
      "95000 [D loss: 0.700340807438, acc.: 0.00%] [G loss: 0.706015646458] [mll=89.244+-4.502] [ks=7.935]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "95100 [D loss: 0.701407551765, acc.: 0.00%] [G loss: 0.719997346401] [mll=88.751+-4.816] [ks=7.669]\n",
      "95200 [D loss: 0.703043341637, acc.: 0.00%] [G loss: 0.721091508865] [mll=88.970+-4.591] [ks=7.803]\n",
      "95300 [D loss: 0.702318668365, acc.: 0.00%] [G loss: 0.706998288631] [mll=88.235+-5.085] [ks=8.400]\n",
      "95400 [D loss: 0.705226778984, acc.: 0.00%] [G loss: 0.700707435608] [mll=87.919+-5.095] [ks=8.150]\n",
      "95500 [D loss: 0.701272666454, acc.: 0.00%] [G loss: 0.703883588314] [mll=89.348+-4.200] [ks=8.058]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "95600 [D loss: 0.70447576046, acc.: 0.00%] [G loss: 0.714333415031] [mll=90.392+-4.338] [ks=7.689]]\n",
      "95700 [D loss: 0.702564001083, acc.: 0.00%] [G loss: 0.709958970547] [mll=89.599+-5.166] [ks=8.149]\n",
      "95800 [D loss: 0.789268434048, acc.: 0.00%] [G loss: 0.715350687504] [mll=88.676+-5.634] [ks=7.812]\n",
      "95900 [D loss: 0.70266443491, acc.: 0.00%] [G loss: 0.70793479681] [mll=88.091+-7.284] [ks=8.025]]]\n",
      "96000 [D loss: 0.704893708229, acc.: 0.00%] [G loss: 0.705598831177] [mll=88.816+-4.572] [ks=7.857]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "96100 [D loss: 0.699906349182, acc.: 0.00%] [G loss: 0.705324590206] [mll=86.921+-6.442] [ks=7.900]\n",
      "96200 [D loss: 0.702579975128, acc.: 0.00%] [G loss: 0.703961908817] [mll=89.321+-4.673] [ks=7.767]\n",
      "96300 [D loss: 0.703904092312, acc.: 0.00%] [G loss: 0.705022215843] [mll=89.911+-4.215] [ks=7.731]\n",
      "96400 [D loss: 0.699298799038, acc.: 0.00%] [G loss: 0.716542840004] [mll=89.574+-4.526] [ks=7.707]\n",
      "96500 [D loss: 0.700987458229, acc.: 0.00%] [G loss: 0.710334897041] [mll=90.071+-5.011] [ks=7.693]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "96600 [D loss: 0.701917111874, acc.: 0.00%] [G loss: 0.707785725594] [mll=91.309+-4.809] [ks=7.475]\n",
      "96700 [D loss: 0.709786057472, acc.: 0.00%] [G loss: 0.707503437996] [mll=89.781+-4.718] [ks=7.696]\n",
      "96800 [D loss: 0.708643317223, acc.: 0.00%] [G loss: 0.732664346695] [mll=89.698+-4.503] [ks=7.227]\n",
      "96900 [D loss: 0.702217578888, acc.: 0.00%] [G loss: 0.713891267776] [mll=89.421+-5.315] [ks=7.999]\n",
      "97000 [D loss: 0.699851989746, acc.: 0.00%] [G loss: 0.703657090664] [mll=89.593+-4.121] [ks=8.061]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "97100 [D loss: 0.703321814537, acc.: 0.00%] [G loss: 0.704426407814] [mll=89.123+-4.155] [ks=8.058]\n",
      "97200 [D loss: 0.700932979584, acc.: 0.00%] [G loss: 0.7092679739] [mll=88.956+-5.069] [ks=7.912]2]\n",
      "97300 [D loss: 0.702193856239, acc.: 0.00%] [G loss: 0.703315794468] [mll=90.242+-4.552] [ks=8.118]\n",
      "97400 [D loss: 0.701704621315, acc.: 0.00%] [G loss: 0.703432023525] [mll=89.158+-5.151] [ks=7.689]\n",
      "97500 [D loss: 0.703238427639, acc.: 0.00%] [G loss: 0.705970883369] [mll=89.817+-4.370] [ks=7.759]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "97600 [D loss: 0.704298913479, acc.: 0.00%] [G loss: 0.701909482479] [mll=89.351+-4.838] [ks=7.932]\n",
      "97700 [D loss: 0.699846923351, acc.: 0.00%] [G loss: 0.715711534023] [mll=89.012+-4.052] [ks=8.544]\n",
      "97800 [D loss: 0.705463409424, acc.: 0.00%] [G loss: 0.709439218044] [mll=89.611+-4.054] [ks=8.012]\n",
      "97900 [D loss: 0.702925562859, acc.: 0.00%] [G loss: 0.70511329174] [mll=89.161+-3.973] [ks=7.804]]\n",
      "98000 [D loss: 0.70483571291, acc.: 0.00%] [G loss: 0.704840242863] [mll=89.884+-3.792] [ks=8.152]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "98100 [D loss: 0.702990889549, acc.: 0.00%] [G loss: 0.705635070801] [mll=89.257+-4.024] [ks=7.677]\n",
      "98200 [D loss: 0.704416155815, acc.: 0.00%] [G loss: 0.722983300686] [mll=89.661+-5.039] [ks=8.090]]\n",
      "98300 [D loss: 0.702410101891, acc.: 0.00%] [G loss: 0.706430971622] [mll=87.674+-9.479] [ks=7.907]\n",
      "98400 [D loss: 0.706095695496, acc.: 0.00%] [G loss: 0.707611620426] [mll=89.207+-3.941] [ks=8.279]\n",
      "98500 [D loss: 0.701562285423, acc.: 0.00%] [G loss: 0.705348968506] [mll=89.944+-4.558] [ks=7.551]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "98600 [D loss: 0.263717979193, acc.: 0.59%] [G loss: 9.69934368134] [mll=89.569+-3.701] [ks=7.702]]\n",
      "98700 [D loss: 0.390492171049, acc.: 4.30%] [G loss: 11.0354957581] [mll=12.200+-8.769] [ks=11.357]]\n",
      "98800 [D loss: 0.215013831854, acc.: 0.00%] [G loss: 10.9022531509] [mll=26.652+-19.456] [ks=11.890]]\n",
      "98900 [D loss: 0.186019897461, acc.: 0.00%] [G loss: 7.34666919708] [mll=40.177+-20.550] [ks=11.398]\n",
      "99000 [D loss: 0.146059975028, acc.: 0.98%] [G loss: 13.1442117691] [mll=46.504+-20.611] [ks=11.595]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "99100 [D loss: 0.221245855093, acc.: 1.56%] [G loss: 12.3963785172] [mll=46.432+-19.399] [ks=10.894]\n",
      "99200 [D loss: 0.39937287569, acc.: 0.00%] [G loss: 1.56719326973] [mll=33.041+-17.201] [ks=11.155]]\n",
      "99300 [D loss: 0.588592231274, acc.: 0.00%] [G loss: 1.14389503002] [mll=99.312+-11.276] [ks=9.365]\n",
      "99400 [D loss: 0.68309211731, acc.: 0.00%] [G loss: 0.848236203194] [mll=94.480+-9.552] [ks=7.880]]\n",
      "99500 [D loss: 0.694547653198, acc.: 0.20%] [G loss: 0.807311594486] [mll=90.958+-7.834] [ks=7.965]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "99600 [D loss: 0.699937820435, acc.: 0.00%] [G loss: 0.757603704929] [mll=97.488+-11.960] [ks=8.165]\n",
      "99700 [D loss: 0.705980420113, acc.: 0.00%] [G loss: 0.730803847313] [mll=90.999+-6.631] [ks=7.882]\n",
      "99800 [D loss: 0.722766399384, acc.: 0.00%] [G loss: 0.760573506355] [mll=89.967+-5.128] [ks=7.820]\n",
      "99900 [D loss: 0.695880174637, acc.: 0.00%] [G loss: 0.715107798576] [mll=89.512+-13.000] [ks=7.431]\n",
      "100000 [D loss: 0.718198299408, acc.: 0.98%] [G loss: 0.742661058903] [mll=89.811+-4.734] [ks=7.766]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "Scaling jet pts\n",
      "Scaling lep isos\n",
      "Discriminator params: 161537\n",
      "Generator params: 340497\n",
      "scaling lepton isolations\n",
      "scaling jet pts\n",
      "100 [D loss: 0.486991912127, acc.: 0.00%] [G loss: 2.3635828495] [mll=-1.000+--1.000] [ks=999.000]]\n",
      "KS score improved from 999.00 to 15.18, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_100.weights\n",
      "200 [D loss: 0.465984880924, acc.: 50.00%] [G loss: 5.48796367645] [mll=22.580+-2.664] [ks=15.184]\n",
      "300 [D loss: 0.100466266274, acc.: 0.00%] [G loss: 4.89873075485] [mll=nan+-nan] [ks=15.452]]\n",
      "KS score improved from 15.18 to 14.59, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_300.weights\n",
      "400 [D loss: 0.195168241858, acc.: 0.00%] [G loss: 11.5460443497] [mll=63.447+-5.881] [ks=14.594]]\n",
      "500 [D loss: 0.104930557311, acc.: 0.00%] [G loss: 4.51197433472] [mll=32.334+-2.665] [ks=15.264]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "600 [D loss: 0.11232970655, acc.: 0.00%] [G loss: 5.85093641281] [mll=64.578+-4.554] [ks=14.741]1]\n",
      "700 [D loss: 0.13701146841, acc.: 0.00%] [G loss: 4.16341257095] [mll=46.520+-3.014] [ks=15.255]]]\n",
      "800 [D loss: 0.0810403823853, acc.: 0.00%] [G loss: 5.04670286179] [mll=56.890+-3.120] [ks=15.379]\n",
      "900 [D loss: 0.374679088593, acc.: 0.00%] [G loss: 5.36075973511] [mll=57.495+-2.869] [ks=14.733]]\n",
      "1000 [D loss: 0.144052088261, acc.: 0.00%] [G loss: 4.54741287231] [mll=35.287+-3.218] [ks=15.539]\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "KS score improved from 14.59 to 14.32, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_1000.weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 [D loss: 0.0629601851106, acc.: 0.00%] [G loss: 4.83400726318] [mll=46.962+-2.247] [ks=14.324]\n",
      "1200 [D loss: 0.0700435787439, acc.: 0.00%] [G loss: 4.40458059311] [mll=68.165+-3.805] [ks=14.845]\n",
      "KS score improved from 14.32 to 12.76, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_1200.weights\n",
      "1300 [D loss: 0.141455873847, acc.: 0.00%] [G loss: 7.61400318146] [mll=106.297+-11.029] [ks=12.755]]\n",
      "1400 [D loss: 0.462001651525, acc.: 0.00%] [G loss: 6.45111179352] [mll=50.650+-3.884] [ks=14.868]]\n",
      "1500 [D loss: 3.37149381638, acc.: 0.00%] [G loss: 7.25073194504] [mll=35.178+-1.963] [ks=14.672]]]\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "1600 [D loss: 0.301537424326, acc.: 0.00%] [G loss: 3.44302916527] [mll=39.478+-2.449] [ks=14.827]]\n",
      "1700 [D loss: 0.0818458050489, acc.: 0.00%] [G loss: 4.66565656662] [mll=27.906+-1.234] [ks=14.999]\n",
      "1800 [D loss: 0.158643841743, acc.: 0.00%] [G loss: 3.14773201942] [mll=71.264+-4.555] [ks=14.368]]\n",
      "KS score improved from 12.76 to 9.68, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_1800.weights\n",
      "1900 [D loss: 1.33277893066, acc.: 0.00%] [G loss: 3.41658592224] [mll=83.865+-12.631] [ks=9.677]]]\n",
      "2000 [D loss: 0.514273405075, acc.: 0.00%] [G loss: 3.99552679062] [mll=97.119+-9.875] [ks=11.230]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "2100 [D loss: 0.326095670462, acc.: 0.00%] [G loss: 2.17504882812] [mll=58.879+-9.779] [ks=12.777]\n",
      "KS score improved from 9.68 to 8.31, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_2100.weights\n",
      "2200 [D loss: 0.190492868423, acc.: 0.59%] [G loss: 2.72860503197] [mll=85.502+-11.512] [ks=8.313]]\n",
      "2300 [D loss: 0.169419616461, acc.: 0.00%] [G loss: 3.00276994705] [mll=70.845+-9.457] [ks=11.367]]\n",
      "2400 [D loss: 0.410507261753, acc.: 0.00%] [G loss: 2.92573022842] [mll=84.697+-7.150] [ks=9.859]]\n",
      "2500 [D loss: 0.215709209442, acc.: 0.00%] [G loss: 2.50951218605] [mll=78.078+-6.500] [ks=11.404]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "2600 [D loss: 0.280432403088, acc.: 0.00%] [G loss: 2.97487998009] [mll=86.969+-11.736] [ks=9.718]]\n",
      "2700 [D loss: 0.22239536047, acc.: 0.00%] [G loss: 2.09872937202] [mll=69.841+-14.571] [ks=9.844]]]\n",
      "2800 [D loss: 0.230239510536, acc.: 0.00%] [G loss: 2.0048353672] [mll=88.116+-6.975] [ks=8.532]]]\n",
      "2900 [D loss: 0.605995535851, acc.: 0.00%] [G loss: 1.94325852394] [mll=96.274+-6.675] [ks=9.618]\n",
      "3000 [D loss: 0.49483269453, acc.: 0.00%] [G loss: 1.69241607189] [mll=91.374+-9.731] [ks=8.519]]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "3100 [D loss: 0.561404764652, acc.: 0.00%] [G loss: 2.01182246208] [mll=68.721+-19.496] [ks=8.447]\n",
      "KS score improved from 8.31 to 7.58, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_3100.weights\n",
      "3200 [D loss: 0.444573938847, acc.: 0.00%] [G loss: 1.94348919392] [mll=89.246+-10.057] [ks=7.585]]\n",
      "3300 [D loss: 1.11950755119, acc.: 0.00%] [G loss: 1.73360943794] [mll=100.569+-14.462] [ks=8.118]]]\n",
      "3400 [D loss: 0.302387475967, acc.: 0.00%] [G loss: 1.73304772377] [mll=88.175+-7.467] [ks=7.617]\n",
      "3500 [D loss: 0.436778664589, acc.: 0.00%] [G loss: 1.80444121361] [mll=86.138+-7.197] [ks=7.726]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "KS score improved from 7.58 to 7.39, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_3500.weights\n",
      "3600 [D loss: 0.770707070827, acc.: 0.00%] [G loss: 1.50848889351] [mll=90.149+-7.043] [ks=7.390]\n",
      "3700 [D loss: 0.263318091631, acc.: 0.00%] [G loss: 1.97144782543] [mll=88.268+-9.603] [ks=7.520]]\n",
      "3800 [D loss: 0.849369347095, acc.: 0.00%] [G loss: 1.46370875835] [mll=93.315+-8.484] [ks=8.145]]\n",
      "3900 [D loss: 0.542373538017, acc.: 0.00%] [G loss: 1.4201823473] [mll=94.962+-8.225] [ks=9.172]]]\n",
      "KS score improved from 7.39 to 7.08, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_3900.weights\n",
      "4000 [D loss: 0.505668520927, acc.: 0.00%] [G loss: 1.27827346325] [mll=89.371+-10.188] [ks=7.078]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "KS score improved from 7.08 to 6.97, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_4000.weights\n",
      "4100 [D loss: 0.552898466587, acc.: 0.00%] [G loss: 1.48239505291] [mll=90.100+-7.525] [ks=6.974]\n",
      "4200 [D loss: 0.693115890026, acc.: 0.00%] [G loss: 1.26244974136] [mll=101.501+-8.344] [ks=8.155]\n",
      "4300 [D loss: 0.870945811272, acc.: 10.16%] [G loss: 1.44531357288] [mll=98.707+-14.752] [ks=7.975]\n",
      "KS score improved from 6.97 to 6.72, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_4300.weights\n",
      "4400 [D loss: 0.349984586239, acc.: 0.00%] [G loss: 1.35775923729] [mll=99.123+-27.241] [ks=6.720]\n",
      "4500 [D loss: 0.650599002838, acc.: 0.00%] [G loss: 1.20290005207] [mll=96.232+-9.232] [ks=7.269]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "4600 [D loss: 0.554443657398, acc.: 0.00%] [G loss: 1.15947926044] [mll=74.227+-18.432] [ks=6.874]]\n",
      "KS score improved from 6.72 to 6.56, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_4600.weights\n",
      "4700 [D loss: 0.688206315041, acc.: 0.20%] [G loss: 1.10682713985] [mll=90.620+-7.292] [ks=6.560]\n",
      "4800 [D loss: 0.606381654739, acc.: 0.00%] [G loss: 1.0652718544] [mll=97.934+-7.256] [ks=7.209]]]\n",
      "KS score improved from 6.56 to 5.62, saving models to progress/jetisoscale_mllwidth_flatNegNoise_2/gen_4800.weights\n",
      "4900 [D loss: 0.514267802238, acc.: 0.00%] [G loss: 1.05266368389] [mll=91.066+-6.488] [ks=5.619]]\n",
      "5000 [D loss: 0.635812699795, acc.: 0.00%] [G loss: 1.05089843273] [mll=90.390+-6.502] [ks=7.808]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "5100 [D loss: 0.682665228844, acc.: 0.00%] [G loss: 0.982597768307] [mll=89.562+-5.854] [ks=6.075]\n",
      "5200 [D loss: 0.667866230011, acc.: 0.00%] [G loss: 0.977953851223] [mll=93.686+-7.204] [ks=7.577]\n",
      "5300 [D loss: 0.57641094923, acc.: 0.00%] [G loss: 1.66311562061] [mll=87.910+-6.475] [ks=6.557]]]\n",
      "5400 [D loss: 0.418025493622, acc.: 24.22%] [G loss: 10.0145273209] [mll=36.687+-7.612] [ks=12.155]\n",
      "5500 [D loss: 0.291981935501, acc.: 0.00%] [G loss: 14.6887378693] [mll=2.976+-1.233] [ks=13.599]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "5600 [D loss: 0.150884345174, acc.: 0.00%] [G loss: 8.54479312897] [mll=12.493+-7.084] [ks=13.245]]\n",
      "5700 [D loss: 0.599297761917, acc.: 0.98%] [G loss: 8.964179039] [mll=43.774+-24.354] [ks=11.220]0]\n",
      "5800 [D loss: 0.44518533349, acc.: 0.00%] [G loss: 2.00650238991] [mll=35.959+-14.209] [ks=11.109]]]\n",
      "5900 [D loss: 0.230171903968, acc.: 0.00%] [G loss: 2.45571303368] [mll=73.384+-20.841] [ks=7.581]\n",
      "6000 [D loss: 0.35465836525, acc.: 0.00%] [G loss: 1.81702256203] [mll=88.765+-16.691] [ks=8.170]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "6100 [D loss: 0.423826962709, acc.: 0.00%] [G loss: 1.61345851421] [mll=86.577+-11.407] [ks=7.819]\n",
      "6200 [D loss: 0.567313075066, acc.: 0.00%] [G loss: 1.35081481934] [mll=93.929+-10.550] [ks=8.602]\n",
      "6300 [D loss: 0.529952287674, acc.: 0.00%] [G loss: 1.54740035534] [mll=82.827+-16.841] [ks=7.960]]\n",
      "6400 [D loss: 0.655380547047, acc.: 0.00%] [G loss: 1.32993018627] [mll=87.168+-8.779] [ks=6.857]\n",
      "6500 [D loss: 0.70239263773, acc.: 0.00%] [G loss: 1.15472686291] [mll=90.739+-7.412] [ks=7.743]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "6600 [D loss: 0.646800577641, acc.: 0.00%] [G loss: 1.15234076977] [mll=91.109+-7.731] [ks=6.336]\n",
      "6700 [D loss: 0.637677669525, acc.: 0.00%] [G loss: 1.13631117344] [mll=88.937+-7.142] [ks=6.280]\n",
      "6800 [D loss: 0.63938421011, acc.: 0.00%] [G loss: 1.01286804676] [mll=85.140+-14.454] [ks=6.967]]]\n",
      "6900 [D loss: 0.53770750761, acc.: 0.20%] [G loss: 1.11301755905] [mll=93.003+-7.225] [ks=6.892]]]\n",
      "7000 [D loss: 0.294632285833, acc.: 0.00%] [G loss: 5.85057878494] [mll=102.465+-12.719] [ks=6.240]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "7100 [D loss: 0.247713565826, acc.: 0.00%] [G loss: 9.01905536652] [mll=17.400+-5.714] [ks=13.798]]\n",
      "7200 [D loss: 0.3835247159, acc.: 0.00%] [G loss: 11.941078186] [mll=14.644+-6.805] [ks=13.205]05]]\n",
      "7300 [D loss: 0.117669500411, acc.: 0.00%] [G loss: 9.39908504486] [mll=49.342+-14.134] [ks=10.429]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7400 [D loss: 0.238420128822, acc.: 0.00%] [G loss: 6.94338703156] [mll=44.403+-18.166] [ks=9.001]]\n",
      "7500 [D loss: 0.255812287331, acc.: 0.20%] [G loss: 5.96951961517] [mll=56.738+-19.908] [ks=8.530]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "7600 [D loss: 0.247797220945, acc.: 0.78%] [G loss: 5.58653354645] [mll=66.814+-15.618] [ks=9.156]\n",
      "7700 [D loss: 0.333659827709, acc.: 0.00%] [G loss: 5.38031673431] [mll=69.079+-21.879] [ks=9.119]\n",
      "7800 [D loss: 0.428636401892, acc.: 0.00%] [G loss: 1.80515658855] [mll=72.401+-17.702] [ks=8.622]\n",
      "7900 [D loss: 0.440382480621, acc.: 0.00%] [G loss: 1.50491547585] [mll=93.055+-12.203] [ks=8.518]\n",
      "8000 [D loss: 0.74803096056, acc.: 0.00%] [G loss: 1.27375161648] [mll=90.203+-9.457] [ks=8.167]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "8100 [D loss: 0.753164887428, acc.: 0.00%] [G loss: 1.02821099758] [mll=95.786+-11.683] [ks=7.529]\n",
      "8200 [D loss: 0.680250287056, acc.: 0.00%] [G loss: 0.980701327324] [mll=94.402+-9.126] [ks=7.385]\n",
      "8300 [D loss: 0.734419941902, acc.: 0.00%] [G loss: 0.93258190155] [mll=91.620+-7.517] [ks=7.830]]\n",
      "8400 [D loss: 0.743394374847, acc.: 0.00%] [G loss: 0.919111788273] [mll=90.124+-11.124] [ks=7.293]\n",
      "8500 [D loss: 0.700796365738, acc.: 0.00%] [G loss: 0.825735628605] [mll=95.559+-8.765] [ks=7.559]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "8600 [D loss: 0.744198322296, acc.: 1.56%] [G loss: 0.840663075447] [mll=94.022+-6.140] [ks=7.390]\n",
      "8700 [D loss: 0.686395645142, acc.: 0.00%] [G loss: 0.764651238918] [mll=91.715+-28.924] [ks=7.256]\n",
      "8800 [D loss: 0.717137396336, acc.: 0.00%] [G loss: 0.770675778389] [mll=90.314+-6.369] [ks=7.295]\n",
      "8900 [D loss: 0.691465854645, acc.: 0.00%] [G loss: 0.746261954308] [mll=101.108+-26.197] [ks=7.735]\n",
      "9000 [D loss: 0.701603353024, acc.: 0.00%] [G loss: 0.732068657875] [mll=91.306+-5.834] [ks=7.691]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "9100 [D loss: 0.698655664921, acc.: 0.00%] [G loss: 0.729592263699] [mll=91.956+-5.706] [ks=7.344]\n",
      "9200 [D loss: 0.696447849274, acc.: 0.00%] [G loss: 0.725727140903] [mll=89.636+-5.065] [ks=7.394]\n",
      "9300 [D loss: 0.699186682701, acc.: 0.00%] [G loss: 0.726942956448] [mll=89.837+-6.453] [ks=7.210]\n",
      "9400 [D loss: 0.698984205723, acc.: 0.00%] [G loss: 0.732808053493] [mll=91.720+-5.029] [ks=6.746]\n",
      "9500 [D loss: 0.70857167244, acc.: 0.00%] [G loss: 0.733066797256] [mll=91.042+-5.327] [ks=7.125]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "9600 [D loss: 0.707472801208, acc.: 0.00%] [G loss: 0.722693562508] [mll=90.738+-5.501] [ks=6.956]\n",
      "9700 [D loss: 0.696099042892, acc.: 0.00%] [G loss: 0.720062196255] [mll=88.022+-5.558] [ks=6.850]\n",
      "9800 [D loss: 0.707765817642, acc.: 0.00%] [G loss: 0.717804551125] [mll=90.383+-5.281] [ks=7.502]\n",
      "9900 [D loss: 0.729582667351, acc.: 0.20%] [G loss: 0.792098939419] [mll=90.019+-4.961] [ks=7.533]\n",
      "10000 [D loss: 0.70220720768, acc.: 0.00%] [G loss: 0.715968370438] [mll=83.577+-21.849] [ks=7.614]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "10100 [D loss: 0.694911003113, acc.: 0.00%] [G loss: 0.719363212585] [mll=88.939+-4.631] [ks=7.627]\n",
      "10200 [D loss: 0.702705860138, acc.: 0.00%] [G loss: 0.711447000504] [mll=89.667+-5.334] [ks=7.732]\n",
      "10300 [D loss: 0.708258867264, acc.: 0.00%] [G loss: 0.715518534184] [mll=90.858+-5.021] [ks=7.455]\n",
      "10400 [D loss: 0.70215177536, acc.: 0.00%] [G loss: 0.71941703558] [mll=94.762+-7.673] [ks=7.410]0]\n",
      "10500 [D loss: 0.701532959938, acc.: 0.00%] [G loss: 0.716814100742] [mll=90.648+-5.093] [ks=7.198]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "10600 [D loss: 0.701178312302, acc.: 0.00%] [G loss: 0.717566251755] [mll=90.962+-4.536] [ks=6.860]\n",
      "10700 [D loss: 0.695412933826, acc.: 0.00%] [G loss: 0.717792570591] [mll=88.896+-4.743] [ks=7.356]\n",
      "10800 [D loss: 0.708014130592, acc.: 0.00%] [G loss: 0.741037964821] [mll=89.462+-4.495] [ks=7.621]\n",
      "10900 [D loss: 0.719738125801, acc.: 0.00%] [G loss: 0.75589376688] [mll=95.048+-9.166] [ks=8.478]]\n",
      "11000 [D loss: 0.698052227497, acc.: 0.00%] [G loss: 0.717596530914] [mll=87.234+-6.086] [ks=7.993]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "11100 [D loss: 0.701738357544, acc.: 0.00%] [G loss: 0.732383787632] [mll=92.617+-5.156] [ks=7.140]\n",
      "11200 [D loss: 0.715467333794, acc.: 0.00%] [G loss: 0.717870771885] [mll=92.419+-4.611] [ks=7.636]\n",
      "11300 [D loss: 0.694307208061, acc.: 0.00%] [G loss: 0.71470451355] [mll=89.581+-4.461] [ks=7.190]]\n",
      "11400 [D loss: 0.705955982208, acc.: 0.00%] [G loss: 0.729368746281] [mll=89.946+-5.083] [ks=7.487]\n",
      "11500 [D loss: 0.713783621788, acc.: 0.00%] [G loss: 0.726899206638] [mll=90.294+-4.607] [ks=7.352]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "11600 [D loss: 0.691549420357, acc.: 0.00%] [G loss: 0.736880421638] [mll=89.076+-5.076] [ks=7.795]\n",
      "11700 [D loss: 0.703062534332, acc.: 0.00%] [G loss: 0.728231668472] [mll=82.959+-10.438] [ks=7.832]\n",
      "11800 [D loss: 0.69071495533, acc.: 0.00%] [G loss: 0.905879020691] [mll=89.691+-4.330] [ks=7.055]]\n",
      "11900 [D loss: 0.70684081316, acc.: 0.00%] [G loss: 0.725900113583] [mll=88.657+-5.764] [ks=8.726]]\n",
      "12000 [D loss: 0.699753284454, acc.: 0.00%] [G loss: 0.722487390041] [mll=96.166+-6.625] [ks=7.563]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "12100 [D loss: 0.71214646101, acc.: 0.00%] [G loss: 0.716616630554] [mll=89.790+-4.719] [ks=7.546]]\n",
      "12200 [D loss: 0.695965588093, acc.: 0.00%] [G loss: 0.712265074253] [mll=90.615+-4.360] [ks=7.362]\n",
      "12300 [D loss: 0.699671506882, acc.: 0.00%] [G loss: 0.719298779964] [mll=89.242+-4.219] [ks=7.537]\n",
      "12400 [D loss: 0.704753160477, acc.: 0.00%] [G loss: 0.718789637089] [mll=91.260+-4.942] [ks=7.690]\n",
      "12500 [D loss: 0.715094089508, acc.: 0.00%] [G loss: 0.709854006767] [mll=89.826+-4.312] [ks=7.157]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "12600 [D loss: 0.713779687881, acc.: 0.00%] [G loss: 0.745827615261] [mll=88.649+-4.950] [ks=7.845]\n",
      "12700 [D loss: 0.702804386616, acc.: 0.00%] [G loss: 0.711267888546] [mll=75.855+-11.117] [ks=8.512]\n",
      "12800 [D loss: 0.699919462204, acc.: 0.00%] [G loss: 0.728743076324] [mll=88.721+-3.759] [ks=7.704]\n",
      "12900 [D loss: 0.731830120087, acc.: 0.20%] [G loss: 0.766805529594] [mll=90.981+-4.650] [ks=7.164]\n",
      "13000 [D loss: 0.692699432373, acc.: 0.00%] [G loss: 0.719266653061] [mll=96.090+-14.551] [ks=7.713]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "13100 [D loss: 0.717419743538, acc.: 0.78%] [G loss: 0.747017860413] [mll=90.492+-4.530] [ks=8.257]\n",
      "13200 [D loss: 0.699831366539, acc.: 0.00%] [G loss: 0.769923090935] [mll=88.148+-22.170] [ks=7.733]\n",
      "13300 [D loss: 0.709996581078, acc.: 0.00%] [G loss: 0.720269143581] [mll=91.497+-5.711] [ks=7.785]\n",
      "13400 [D loss: 0.707200050354, acc.: 0.00%] [G loss: 0.705232977867] [mll=89.638+-4.248] [ks=7.679]\n",
      "13500 [D loss: 0.694057941437, acc.: 0.00%] [G loss: 0.713212549686] [mll=88.063+-4.763] [ks=7.797]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "13600 [D loss: 0.69845533371, acc.: 0.00%] [G loss: 0.709577620029] [mll=89.783+-4.268] [ks=7.968]]\n",
      "13700 [D loss: 0.722491621971, acc.: 0.39%] [G loss: 0.759191870689] [mll=91.352+-4.385] [ks=7.516]\n",
      "13800 [D loss: 0.70172637701, acc.: 0.00%] [G loss: 0.719284117222] [mll=90.112+-19.526] [ks=8.076]]\n",
      "13900 [D loss: 0.706949234009, acc.: 0.00%] [G loss: 0.714583337307] [mll=89.207+-4.308] [ks=7.693]\n",
      "14000 [D loss: 0.708616435528, acc.: 0.00%] [G loss: 0.721898972988] [mll=89.544+-4.801] [ks=7.619]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "14100 [D loss: 0.700576066971, acc.: 0.00%] [G loss: 0.720234453678] [mll=89.638+-4.157] [ks=7.600]\n",
      "14200 [D loss: 0.700904846191, acc.: 0.00%] [G loss: 0.714750766754] [mll=89.151+-4.576] [ks=7.452]\n",
      "14300 [D loss: 0.698320508003, acc.: 0.00%] [G loss: 0.713942468166] [mll=89.327+-5.789] [ks=7.626]\n",
      "14400 [D loss: 0.701684355736, acc.: 0.00%] [G loss: 0.716296255589] [mll=89.123+-4.120] [ks=8.001]\n",
      "14500 [D loss: 0.704268693924, acc.: 0.00%] [G loss: 0.71835899353] [mll=90.370+-4.188] [ks=7.256]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "14600 [D loss: 0.697722613811, acc.: 0.00%] [G loss: 0.714372575283] [mll=89.582+-4.382] [ks=7.515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14700 [D loss: 0.709119200706, acc.: 0.00%] [G loss: 0.708915650845] [mll=89.301+-4.356] [ks=7.592]\n",
      "14800 [D loss: 0.704819202423, acc.: 0.00%] [G loss: 0.707920610905] [mll=89.946+-4.349] [ks=7.307]\n",
      "14900 [D loss: 0.709140300751, acc.: 0.00%] [G loss: 0.708937585354] [mll=95.292+-12.717] [ks=7.599]\n",
      "15000 [D loss: 0.712364256382, acc.: 0.20%] [G loss: 0.728445589542] [mll=91.275+-4.649] [ks=7.372]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "15100 [D loss: 0.698942542076, acc.: 0.00%] [G loss: 0.71359705925] [mll=101.607+-13.680] [ks=8.232]]\n",
      "15200 [D loss: 0.708714962006, acc.: 0.00%] [G loss: 0.71676003933] [mll=89.969+-4.377] [ks=7.629]]\n",
      "15300 [D loss: 0.697803676128, acc.: 0.00%] [G loss: 0.708289563656] [mll=90.026+-4.372] [ks=7.396]\n",
      "15400 [D loss: 0.696640253067, acc.: 0.00%] [G loss: 0.715725958347] [mll=90.097+-4.645] [ks=7.567]\n",
      "15500 [D loss: 0.700337648392, acc.: 0.00%] [G loss: 0.714132189751] [mll=89.190+-4.466] [ks=7.489]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "15600 [D loss: 0.680880904198, acc.: 0.00%] [G loss: 0.714341640472] [mll=89.213+-4.393] [ks=7.709]\n",
      "15700 [D loss: 0.701112985611, acc.: 0.00%] [G loss: 0.730352461338] [mll=88.587+-4.606] [ks=8.317]\n",
      "15800 [D loss: 0.702281475067, acc.: 0.00%] [G loss: 0.716475069523] [mll=90.212+-4.492] [ks=7.642]\n",
      "15900 [D loss: 0.688716888428, acc.: 0.00%] [G loss: 0.722156584263] [mll=90.278+-5.018] [ks=7.642]\n",
      "16000 [D loss: 0.770059585571, acc.: 0.00%] [G loss: 0.716955423355] [mll=90.331+-4.653] [ks=9.147]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "16100 [D loss: 0.706872880459, acc.: 0.00%] [G loss: 0.990462362766] [mll=90.278+-4.643] [ks=7.248]\n",
      "16200 [D loss: 0.703729867935, acc.: 0.00%] [G loss: 0.712173044682] [mll=97.787+-6.232] [ks=8.739]\n",
      "16300 [D loss: 0.718157052994, acc.: 0.00%] [G loss: 0.716339707375] [mll=88.604+-4.776] [ks=7.593]\n",
      "16400 [D loss: 0.707304775715, acc.: 0.00%] [G loss: 0.710543751717] [mll=90.755+-4.564] [ks=7.756]\n",
      "16500 [D loss: 0.709917843342, acc.: 0.00%] [G loss: 0.71329587698] [mll=90.534+-4.505] [ks=7.359]]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "16600 [D loss: 0.702626526356, acc.: 0.00%] [G loss: 0.715508103371] [mll=87.903+-4.848] [ks=7.716]\n",
      "16700 [D loss: 0.702685832977, acc.: 0.00%] [G loss: 0.711080014706] [mll=90.620+-4.369] [ks=7.621]\n",
      "16800 [D loss: 0.70189011097, acc.: 0.00%] [G loss: 0.719990193844] [mll=90.827+-4.337] [ks=7.291]]\n",
      "16900 [D loss: 0.702099204063, acc.: 0.00%] [G loss: 0.710129857063] [mll=89.180+-4.234] [ks=7.332]\n",
      "17000 [D loss: 0.69931781292, acc.: 0.00%] [G loss: 0.712375700474] [mll=89.740+-4.796] [ks=6.800]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "17100 [D loss: 0.702302753925, acc.: 0.00%] [G loss: 0.709584712982] [mll=94.656+-5.316] [ks=7.710]\n",
      "17200 [D loss: 0.700332403183, acc.: 0.00%] [G loss: 0.705854296684] [mll=88.944+-4.699] [ks=7.729]\n",
      "17300 [D loss: 0.699814558029, acc.: 0.00%] [G loss: 0.708652973175] [mll=89.956+-4.102] [ks=6.903]\n",
      "17400 [D loss: 0.697351813316, acc.: 0.00%] [G loss: 0.711512804031] [mll=90.228+-4.048] [ks=7.300]\n",
      "17500 [D loss: 0.702301800251, acc.: 0.00%] [G loss: 0.710758149624] [mll=88.595+-4.287] [ks=7.340]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "17600 [D loss: 0.704007863998, acc.: 0.00%] [G loss: 0.705434381962] [mll=94.712+-5.881] [ks=7.515]\n",
      "17700 [D loss: 0.699655532837, acc.: 0.00%] [G loss: 0.718570590019] [mll=91.458+-4.569] [ks=7.715]\n",
      "17800 [D loss: 0.701184391975, acc.: 0.00%] [G loss: 0.704500615597] [mll=92.873+-5.179] [ks=7.917]\n",
      "17900 [D loss: 0.704528272152, acc.: 0.00%] [G loss: 0.825548052788] [mll=89.521+-4.586] [ks=7.873]\n",
      "18000 [D loss: 0.729965090752, acc.: 0.00%] [G loss: 0.712296903133] [mll=88.811+-5.950] [ks=8.616]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "18100 [D loss: 0.702149569988, acc.: 0.00%] [G loss: 0.702203691006] [mll=90.032+-4.122] [ks=7.389]\n",
      "18200 [D loss: 0.706219673157, acc.: 0.00%] [G loss: 0.713619709015] [mll=90.076+-4.376] [ks=8.342]\n",
      "18300 [D loss: 0.699781060219, acc.: 0.00%] [G loss: 0.713288664818] [mll=90.125+-4.565] [ks=7.501]\n",
      "18400 [D loss: 0.700908720493, acc.: 0.00%] [G loss: 0.703630924225] [mll=89.534+-4.958] [ks=8.053]\n",
      "18500 [D loss: 0.699824988842, acc.: 0.00%] [G loss: 0.70779645443] [mll=89.444+-4.533] [ks=7.762]]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "18600 [D loss: 0.702347874641, acc.: 0.00%] [G loss: 0.704662263393] [mll=89.976+-4.214] [ks=7.830]\n",
      "18700 [D loss: 0.700432837009, acc.: 0.00%] [G loss: 0.705555558205] [mll=89.946+-4.454] [ks=8.072]\n",
      "18800 [D loss: 0.70590865612, acc.: 0.00%] [G loss: 0.707744181156] [mll=89.557+-4.559] [ks=7.949]]\n",
      "18900 [D loss: 0.700743198395, acc.: 0.00%] [G loss: 0.706730246544] [mll=88.792+-4.503] [ks=7.438]\n",
      "19000 [D loss: 0.700700759888, acc.: 0.00%] [G loss: 0.700790643692] [mll=85.998+-4.748] [ks=7.654]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "19100 [D loss: 0.695792198181, acc.: 0.00%] [G loss: 0.707478284836] [mll=89.079+-4.305] [ks=7.914]\n",
      "19200 [D loss: 0.707898855209, acc.: 0.00%] [G loss: 0.711097300053] [mll=89.156+-3.925] [ks=7.880]\n",
      "19300 [D loss: 0.702721118927, acc.: 0.00%] [G loss: 0.70829808712] [mll=89.288+-4.404] [ks=7.279]]\n",
      "19400 [D loss: 0.701208770275, acc.: 0.00%] [G loss: 0.706123888493] [mll=89.814+-4.238] [ks=7.230]\n",
      "19500 [D loss: 0.71074450016, acc.: 0.00%] [G loss: 0.709221124649] [mll=89.136+-4.520] [ks=7.260]]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "19600 [D loss: 0.702039480209, acc.: 0.00%] [G loss: 0.70917391777] [mll=89.681+-4.238] [ks=7.589]]\n",
      "19700 [D loss: 0.664435207844, acc.: 0.00%] [G loss: 0.727357387543] [mll=90.223+-4.097] [ks=7.520]\n",
      "19800 [D loss: 0.705242276192, acc.: 0.00%] [G loss: 0.716668725014] [mll=88.692+-5.001] [ks=8.312]\n",
      "19900 [D loss: 0.701684951782, acc.: 0.00%] [G loss: 0.710845887661] [mll=88.759+-4.576] [ks=7.354]\n",
      "20000 [D loss: 0.716887116432, acc.: 0.00%] [G loss: 0.727147042751] [mll=91.036+-4.487] [ks=7.873]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "20100 [D loss: 0.709635615349, acc.: 0.00%] [G loss: 0.705878853798] [mll=96.255+-13.725] [ks=7.677]\n",
      "20200 [D loss: 0.713388860226, acc.: 0.00%] [G loss: 0.707596719265] [mll=89.675+-4.310] [ks=7.603]\n",
      "20300 [D loss: 0.714937329292, acc.: 0.00%] [G loss: 0.725342392921] [mll=91.451+-4.819] [ks=7.343]\n",
      "20400 [D loss: 0.698096632957, acc.: 0.00%] [G loss: 0.707499146461] [mll=90.650+-8.287] [ks=8.037]\n",
      "20500 [D loss: 0.704209804535, acc.: 0.00%] [G loss: 0.707602739334] [mll=89.865+-4.303] [ks=7.813]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "20600 [D loss: 0.703243017197, acc.: 0.00%] [G loss: 0.705609083176] [mll=89.879+-3.870] [ks=8.115]\n",
      "20700 [D loss: 0.706093132496, acc.: 0.00%] [G loss: 0.703907549381] [mll=89.777+-4.452] [ks=7.555]\n",
      "20800 [D loss: 0.703520417213, acc.: 0.00%] [G loss: 0.706820070744] [mll=90.343+-4.285] [ks=7.978]\n",
      "20900 [D loss: 0.725967764854, acc.: 0.00%] [G loss: 0.705685377121] [mll=89.438+-3.940] [ks=7.251]\n",
      "21000 [D loss: 0.701442778111, acc.: 0.00%] [G loss: 0.705779314041] [mll=88.659+-3.940] [ks=7.794]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "21100 [D loss: 0.708758175373, acc.: 0.00%] [G loss: 0.707363367081] [mll=89.605+-4.921] [ks=7.938]\n",
      "21200 [D loss: 0.697514414787, acc.: 0.00%] [G loss: 0.705881536007] [mll=91.145+-4.592] [ks=7.242]\n",
      "21300 [D loss: 0.705121338367, acc.: 0.00%] [G loss: 0.705726206303] [mll=89.703+-4.287] [ks=7.025]\n",
      "21400 [D loss: 0.722028255463, acc.: 0.00%] [G loss: 0.728431105614] [mll=89.562+-4.031] [ks=7.572]\n",
      "21500 [D loss: 0.702578902245, acc.: 0.00%] [G loss: 0.707038640976] [mll=89.981+-4.410] [ks=8.712]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "21600 [D loss: 0.7018045187, acc.: 0.00%] [G loss: 0.705265939236] [mll=91.140+-4.928] [ks=7.011]1]\n",
      "21700 [D loss: 0.703114390373, acc.: 0.00%] [G loss: 0.708605706692] [mll=90.822+-4.670] [ks=6.983]\n",
      "21800 [D loss: 0.688674151897, acc.: 0.00%] [G loss: 0.763237714767] [mll=81.938+-8.969] [ks=7.971]\n",
      "21900 [D loss: 0.706283807755, acc.: 0.00%] [G loss: 0.726413011551] [mll=89.214+-6.499] [ks=8.983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000 [D loss: 0.704601407051, acc.: 0.00%] [G loss: 0.708145678043] [mll=89.912+-4.249] [ks=6.924]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "22100 [D loss: 0.735872149467, acc.: 0.00%] [G loss: 0.70829474926] [mll=89.881+-4.935] [ks=7.277]]\n",
      "22200 [D loss: 0.713406085968, acc.: 0.00%] [G loss: 0.704950332642] [mll=89.872+-4.848] [ks=7.772]\n",
      "22300 [D loss: 0.700298070908, acc.: 0.00%] [G loss: 0.707601189613] [mll=89.209+-4.275] [ks=7.419]\n",
      "22400 [D loss: 0.705749750137, acc.: 0.00%] [G loss: 0.707734584808] [mll=90.210+-6.847] [ks=7.842]\n",
      "22500 [D loss: 0.702431619167, acc.: 0.00%] [G loss: 0.707305014133] [mll=89.262+-4.336] [ks=7.097]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "22600 [D loss: 0.704711318016, acc.: 0.00%] [G loss: 0.707903921604] [mll=90.249+-4.276] [ks=7.085]\n",
      "22700 [D loss: 0.699060440063, acc.: 0.00%] [G loss: 0.706855714321] [mll=89.876+-4.193] [ks=7.963]\n",
      "22800 [D loss: 0.702698945999, acc.: 0.00%] [G loss: 0.704216241837] [mll=89.232+-4.419] [ks=7.635]\n",
      "22900 [D loss: 0.703030586243, acc.: 0.00%] [G loss: 0.705759942532] [mll=91.130+-4.006] [ks=7.844]\n",
      "23000 [D loss: 0.704434156418, acc.: 0.00%] [G loss: 0.712932229042] [mll=93.387+-5.242] [ks=7.694]\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "23100 [D loss: 0.699951171875, acc.: 0.00%] [G loss: 0.705856442451] [mll=98.273+-14.063] [ks=8.023]\n",
      "23200 [D loss: 0.704891681671, acc.: 0.00%] [G loss: 0.708568513393] [mll=88.675+-4.945] [ks=7.880]\n",
      "23300 [D loss: 0.701741337776, acc.: 0.00%] [G loss: 0.712787866592] [mll=90.598+-4.320] [ks=7.357]\n",
      "23400 [D loss: 0.701957345009, acc.: 0.00%] [G loss: 0.712661266327] [mll=89.627+-4.284] [ks=7.169]\n",
      "23500 [D loss: 0.702008128166, acc.: 0.00%] [G loss: 0.709455549717] [mll=89.699+-5.065] [ks=7.723]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "23600 [D loss: 0.700252175331, acc.: 0.00%] [G loss: 0.707312941551] [mll=90.405+-4.112] [ks=7.127]\n",
      "23700 [D loss: 0.744227647781, acc.: 0.00%] [G loss: 0.799235463142] [mll=89.313+-5.083] [ks=8.601]\n",
      "23800 [D loss: 0.697642087936, acc.: 0.00%] [G loss: 0.708628296852] [mll=83.138+-4.707] [ks=8.667]\n",
      "23900 [D loss: 0.701998472214, acc.: 0.00%] [G loss: 0.707061827183] [mll=90.396+-4.774] [ks=7.833]\n",
      "24000 [D loss: 0.699386715889, acc.: 0.00%] [G loss: 0.712860047817] [mll=90.090+-4.379] [ks=7.333]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "24100 [D loss: 0.716599464417, acc.: 0.00%] [G loss: 0.761013448238] [mll=90.239+-5.209] [ks=8.975]\n",
      "24200 [D loss: 0.709195315838, acc.: 0.00%] [G loss: 0.709119737148] [mll=84.667+-12.119] [ks=7.451]\n",
      "24300 [D loss: 0.69862473011, acc.: 0.00%] [G loss: 0.707046508789] [mll=89.813+-4.126] [ks=7.432]]\n",
      "24400 [D loss: 0.751836776733, acc.: 0.00%] [G loss: 0.716532588005] [mll=89.251+-4.669] [ks=8.115]\n",
      "24500 [D loss: 0.701251268387, acc.: 0.00%] [G loss: 0.704100072384] [mll=88.775+-5.252] [ks=7.528]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "24600 [D loss: 0.701623678207, acc.: 0.00%] [G loss: 0.705079495907] [mll=89.696+-3.938] [ks=7.447]\n",
      "24700 [D loss: 0.719308972359, acc.: 0.00%] [G loss: 0.731500685215] [mll=90.029+-4.555] [ks=7.265]\n",
      "24800 [D loss: 0.699927687645, acc.: 0.00%] [G loss: 0.703050553799] [mll=87.878+-6.083] [ks=7.813]\n",
      "24900 [D loss: 0.700906336308, acc.: 0.00%] [G loss: 0.706600666046] [mll=89.958+-4.412] [ks=6.522]\n",
      "25000 [D loss: 0.702737212181, acc.: 0.00%] [G loss: 0.704302072525] [mll=89.433+-4.180] [ks=6.555]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "25100 [D loss: 0.702135980129, acc.: 0.00%] [G loss: 0.705009043217] [mll=93.654+-6.209] [ks=7.784]\n",
      "25200 [D loss: 0.705970644951, acc.: 0.00%] [G loss: 0.70680898428] [mll=89.331+-4.871] [ks=7.384]]\n",
      "25300 [D loss: 0.699972212315, acc.: 0.00%] [G loss: 0.705940961838] [mll=89.065+-4.636] [ks=7.759]\n",
      "25400 [D loss: 0.746028780937, acc.: 0.00%] [G loss: 0.713618338108] [mll=90.234+-4.605] [ks=7.446]\n",
      "25500 [D loss: 0.707343459129, acc.: 0.00%] [G loss: 0.709316015244] [mll=87.202+-5.374] [ks=7.672]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "25600 [D loss: 0.710711300373, acc.: 0.00%] [G loss: 0.713117957115] [mll=89.442+-4.338] [ks=7.498]\n",
      "25700 [D loss: 0.702454388142, acc.: 0.00%] [G loss: 0.703987181187] [mll=90.375+-4.450] [ks=7.249]\n",
      "25800 [D loss: 0.704862475395, acc.: 0.00%] [G loss: 0.709531724453] [mll=89.827+-4.720] [ks=7.490]\n",
      "25900 [D loss: 0.699401736259, acc.: 0.00%] [G loss: 0.702671468258] [mll=87.551+-6.061] [ks=7.376]\n",
      "26000 [D loss: 0.702145218849, acc.: 0.00%] [G loss: 0.708531796932] [mll=89.637+-4.522] [ks=7.677]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "26100 [D loss: 0.711880922318, acc.: 0.00%] [G loss: 0.726132035255] [mll=89.398+-4.314] [ks=7.566]\n",
      "26200 [D loss: 0.700028777122, acc.: 0.00%] [G loss: 0.705885469913] [mll=94.536+-12.244] [ks=7.819]\n",
      "26300 [D loss: 0.703192532063, acc.: 0.00%] [G loss: 0.706102013588] [mll=89.628+-4.415] [ks=8.261]\n",
      "26400 [D loss: 0.714379429817, acc.: 0.00%] [G loss: 0.704281389713] [mll=88.721+-4.292] [ks=8.098]\n",
      "26500 [D loss: 0.703655719757, acc.: 0.00%] [G loss: 0.706944823265] [mll=89.997+-5.077] [ks=8.240]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "26600 [D loss: 0.700199842453, acc.: 0.00%] [G loss: 0.705828905106] [mll=90.135+-4.265] [ks=7.381]\n",
      "26700 [D loss: 0.703191280365, acc.: 0.00%] [G loss: 0.706873953342] [mll=88.356+-5.196] [ks=7.671]\n",
      "26800 [D loss: 0.700786709785, acc.: 0.00%] [G loss: 0.701225340366] [mll=90.431+-4.801] [ks=7.327]\n",
      "26900 [D loss: 0.705092191696, acc.: 0.00%] [G loss: 0.710360884666] [mll=89.799+-4.980] [ks=8.555]\n",
      "27000 [D loss: 0.710827112198, acc.: 0.20%] [G loss: 0.725964486599] [mll=90.262+-4.623] [ks=6.882]\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "27100 [D loss: 0.700558662415, acc.: 0.00%] [G loss: 0.763140261173] [mll=93.833+-14.999] [ks=7.149]\n",
      "27200 [D loss: 0.70327270031, acc.: 0.20%] [G loss: 0.707081735134] [mll=90.366+-5.347] [ks=7.274]]\n",
      "27300 [D loss: 0.705049157143, acc.: 0.00%] [G loss: 0.710995554924] [mll=89.119+-4.760] [ks=7.655]\n",
      "27400 [D loss: 0.761252403259, acc.: 0.00%] [G loss: 0.725973367691] [mll=90.058+-4.822] [ks=7.304]\n",
      "27500 [D loss: 0.705832242966, acc.: 0.00%] [G loss: 0.71100372076] [mll=102.510+-13.828] [ks=8.626]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "27600 [D loss: 0.698124527931, acc.: 0.00%] [G loss: 0.699424684048] [mll=90.123+-4.453] [ks=7.694]\n",
      "27700 [D loss: 0.703385233879, acc.: 0.00%] [G loss: 0.708727359772] [mll=89.088+-4.933] [ks=8.037]\n",
      "27800 [D loss: 0.712442398071, acc.: 0.00%] [G loss: 0.746718287468] [mll=89.465+-4.513] [ks=7.363]\n",
      "27900 [D loss: 0.705516695976, acc.: 0.00%] [G loss: 0.702196002007] [mll=90.688+-9.951] [ks=8.409]\n",
      "28000 [D loss: 0.705851018429, acc.: 0.00%] [G loss: 0.706460893154] [mll=90.066+-4.548] [ks=7.727]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "28100 [D loss: 0.698315143585, acc.: 0.00%] [G loss: 0.7194480896] [mll=89.772+-4.690] [ks=7.410]]]\n",
      "28200 [D loss: 0.701330542564, acc.: 0.00%] [G loss: 0.711113810539] [mll=89.368+-5.268] [ks=8.049]\n",
      "28300 [D loss: 0.714828431606, acc.: 0.00%] [G loss: 0.722752153873] [mll=89.627+-4.447] [ks=7.744]\n",
      "28400 [D loss: 0.700648009777, acc.: 0.00%] [G loss: 0.713093757629] [mll=87.823+-5.088] [ks=7.875]\n",
      "28500 [D loss: 0.724496126175, acc.: 0.39%] [G loss: 0.772707462311] [mll=89.896+-4.196] [ks=7.690]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "28600 [D loss: 0.711327433586, acc.: 0.00%] [G loss: 0.709785223007] [mll=95.113+-12.125] [ks=7.909]\n",
      "28700 [D loss: 0.713297963142, acc.: 0.39%] [G loss: 0.712527215481] [mll=89.833+-4.774] [ks=7.671]\n",
      "28800 [D loss: 0.70348238945, acc.: 0.00%] [G loss: 0.702879548073] [mll=89.436+-15.162] [ks=7.796]]\n",
      "28900 [D loss: 0.702734172344, acc.: 0.00%] [G loss: 0.71185708046] [mll=89.453+-5.124] [ks=7.425]]\n",
      "29000 [D loss: 0.687998771667, acc.: 0.00%] [G loss: 0.705302298069] [mll=90.436+-4.930] [ks=7.703]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "29100 [D loss: 0.700048327446, acc.: 0.00%] [G loss: 0.707293093204] [mll=90.066+-5.396] [ks=7.884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29200 [D loss: 0.702173411846, acc.: 0.00%] [G loss: 0.703473627567] [mll=89.818+-5.300] [ks=7.283]\n",
      "29300 [D loss: 0.705347776413, acc.: 0.00%] [G loss: 0.706410944462] [mll=88.401+-4.588] [ks=8.145]\n",
      "29400 [D loss: 0.701743960381, acc.: 0.00%] [G loss: 0.710956931114] [mll=89.227+-4.503] [ks=7.621]\n",
      "29500 [D loss: 0.724335670471, acc.: 0.00%] [G loss: 0.713122308254] [mll=89.743+-5.363] [ks=7.425]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "29600 [D loss: 0.732205569744, acc.: 0.00%] [G loss: 0.712452888489] [mll=89.783+-6.006] [ks=8.356]\n",
      "29700 [D loss: 0.703476190567, acc.: 0.00%] [G loss: 0.707730829716] [mll=87.677+-5.471] [ks=7.959]\n",
      "29800 [D loss: 0.712923705578, acc.: 0.00%] [G loss: 0.723198950291] [mll=89.039+-4.469] [ks=7.588]\n",
      "29900 [D loss: 0.704282641411, acc.: 0.00%] [G loss: 0.702691197395] [mll=88.813+-4.899] [ks=7.654]\n",
      "30000 [D loss: 0.701013624668, acc.: 0.00%] [G loss: 0.704352617264] [mll=89.611+-4.609] [ks=7.196]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "30100 [D loss: 0.704124391079, acc.: 0.00%] [G loss: 0.707893252373] [mll=88.985+-4.552] [ks=7.617]\n",
      "30200 [D loss: 0.706984519958, acc.: 0.00%] [G loss: 0.710145831108] [mll=90.384+-4.975] [ks=7.964]\n",
      "30300 [D loss: 0.706912398338, acc.: 0.00%] [G loss: 0.707897722721] [mll=88.861+-4.919] [ks=7.506]\n",
      "30400 [D loss: 0.697693943977, acc.: 0.00%] [G loss: 0.705939352512] [mll=91.717+-6.451] [ks=7.473]\n",
      "30500 [D loss: 0.717394709587, acc.: 0.00%] [G loss: 0.707556664944] [mll=88.567+-5.122] [ks=7.804]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "30600 [D loss: 0.701103806496, acc.: 0.00%] [G loss: 0.7062754035] [mll=89.509+-4.442] [ks=7.859]9]\n",
      "30700 [D loss: 0.72097325325, acc.: 0.00%] [G loss: 0.706303656101] [mll=89.360+-4.996] [ks=8.501]]\n",
      "30800 [D loss: 0.7054926157, acc.: 0.00%] [G loss: 0.707363665104] [mll=89.457+-4.681] [ks=7.471]1]\n",
      "30900 [D loss: 0.704861521721, acc.: 0.00%] [G loss: 0.715095579624] [mll=88.913+-5.013] [ks=7.817]\n",
      "31000 [D loss: 0.707269906998, acc.: 0.20%] [G loss: 0.72684442997] [mll=87.071+-7.044] [ks=7.817]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "31100 [D loss: 0.708319544792, acc.: 0.00%] [G loss: 0.708600401878] [mll=95.852+-19.460] [ks=7.648]\n",
      "31200 [D loss: 0.696069121361, acc.: 0.00%] [G loss: 0.706772744656] [mll=89.539+-5.090] [ks=7.518]\n",
      "31300 [D loss: 0.702555418015, acc.: 0.00%] [G loss: 0.711269915104] [mll=89.187+-5.375] [ks=7.678]\n",
      "31400 [D loss: 0.703250408173, acc.: 0.00%] [G loss: 0.706920027733] [mll=89.659+-4.609] [ks=7.830]\n",
      "31500 [D loss: 0.700069248676, acc.: 0.00%] [G loss: 0.70404535532] [mll=89.421+-4.663] [ks=7.854]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "31600 [D loss: 0.707051753998, acc.: 0.00%] [G loss: 0.706860482693] [mll=87.899+-4.426] [ks=8.498]\n",
      "31700 [D loss: 0.700257122517, acc.: 0.00%] [G loss: 0.712048411369] [mll=89.598+-5.338] [ks=7.822]\n",
      "31800 [D loss: 0.705723285675, acc.: 0.00%] [G loss: 0.706464707851] [mll=89.755+-5.825] [ks=7.727]\n",
      "31900 [D loss: 0.686272025108, acc.: 0.00%] [G loss: 0.705157339573] [mll=89.270+-4.327] [ks=7.807]\n",
      "32000 [D loss: 0.705295324326, acc.: 0.00%] [G loss: 0.703971922398] [mll=89.216+-4.828] [ks=7.465]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "32100 [D loss: 0.706647157669, acc.: 0.00%] [G loss: 0.706984400749] [mll=88.477+-5.019] [ks=7.480]\n",
      "32200 [D loss: 0.702734827995, acc.: 0.00%] [G loss: 0.707647442818] [mll=88.770+-4.962] [ks=7.719]\n",
      "32300 [D loss: 0.702218413353, acc.: 0.00%] [G loss: 0.712626218796] [mll=89.958+-5.185] [ks=7.391]\n",
      "32400 [D loss: 0.764786481857, acc.: 0.00%] [G loss: 0.709509789944] [mll=89.767+-4.660] [ks=7.232]\n",
      "32500 [D loss: 0.756558895111, acc.: 0.00%] [G loss: 0.709200322628] [mll=89.676+-4.682] [ks=8.958]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "32600 [D loss: 0.702229499817, acc.: 0.00%] [G loss: 0.709306955338] [mll=89.375+-4.592] [ks=7.464]\n",
      "32700 [D loss: 0.708945274353, acc.: 0.00%] [G loss: 0.70715212822] [mll=89.086+-4.888] [ks=7.494]]\n",
      "32800 [D loss: 0.701990783215, acc.: 0.00%] [G loss: 0.714453935623] [mll=89.440+-4.557] [ks=7.827]\n",
      "32900 [D loss: 0.70749437809, acc.: 0.00%] [G loss: 0.705240666866] [mll=89.165+-4.373] [ks=7.740]]\n",
      "33000 [D loss: 0.705837368965, acc.: 0.00%] [G loss: 0.70665115118] [mll=88.298+-5.128] [ks=8.159]]\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "33100 [D loss: 0.727649569511, acc.: 0.00%] [G loss: 0.709202766418] [mll=89.078+-5.199] [ks=7.422]\n",
      "33200 [D loss: 0.704783320427, acc.: 0.00%] [G loss: 0.713174104691] [mll=88.910+-4.101] [ks=7.753]\n",
      "33300 [D loss: 0.704952299595, acc.: 0.00%] [G loss: 0.710684835911] [mll=89.638+-4.923] [ks=7.515]\n",
      "33400 [D loss: 0.712357521057, acc.: 0.00%] [G loss: 0.706315100193] [mll=85.028+-7.443] [ks=8.550]\n",
      "33500 [D loss: 0.709277629852, acc.: 0.00%] [G loss: 0.709222555161] [mll=88.402+-4.870] [ks=7.854]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "33600 [D loss: 0.701157093048, acc.: 0.00%] [G loss: 0.707597970963] [mll=88.242+-5.008] [ks=7.626]\n",
      "33700 [D loss: 0.703867793083, acc.: 0.00%] [G loss: 0.707359850407] [mll=89.458+-4.860] [ks=7.893]\n",
      "33800 [D loss: 0.706537306309, acc.: 0.39%] [G loss: 0.719891309738] [mll=88.595+-4.958] [ks=7.832]\n",
      "33900 [D loss: 0.704971075058, acc.: 0.00%] [G loss: 0.703271329403] [mll=94.256+-6.553] [ks=8.958]\n",
      "34000 [D loss: 0.709035873413, acc.: 0.00%] [G loss: 0.71033769846] [mll=89.199+-5.290] [ks=7.760]]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "34100 [D loss: 0.733364999294, acc.: 0.20%] [G loss: 0.745019853115] [mll=88.602+-5.168] [ks=7.790]\n",
      "34200 [D loss: 0.701916992664, acc.: 0.00%] [G loss: 0.711822450161] [mll=95.285+-12.400] [ks=7.659]\n",
      "34300 [D loss: 0.699607133865, acc.: 0.00%] [G loss: 0.729212224483] [mll=89.066+-4.816] [ks=7.499]\n",
      "34400 [D loss: 0.694391846657, acc.: 0.00%] [G loss: 0.712784707546] [mll=90.364+-4.442] [ks=8.367]\n",
      "34500 [D loss: 0.699929833412, acc.: 0.00%] [G loss: 0.708204507828] [mll=86.805+-5.015] [ks=8.703]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "34600 [D loss: 0.706035137177, acc.: 0.00%] [G loss: 0.71355342865] [mll=90.384+-5.081] [ks=7.590]]\n",
      "34700 [D loss: 0.704587578773, acc.: 0.00%] [G loss: 0.711548388004] [mll=89.213+-4.276] [ks=7.739]\n",
      "34800 [D loss: 0.71127974987, acc.: 0.00%] [G loss: 0.710893571377] [mll=88.441+-4.506] [ks=7.782]]\n",
      "34900 [D loss: 0.693097710609, acc.: 0.00%] [G loss: 0.694880723953] [mll=89.698+-4.949] [ks=7.772]\n",
      "35000 [D loss: 0.703892588615, acc.: 0.00%] [G loss: 0.715605318546] [mll=90.133+-4.793] [ks=8.312]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "35100 [D loss: 0.706223845482, acc.: 0.00%] [G loss: 0.714507520199] [mll=89.717+-4.656] [ks=7.617]\n",
      "35200 [D loss: 0.703254640102, acc.: 0.00%] [G loss: 0.712976694107] [mll=89.718+-4.814] [ks=7.549]\n",
      "35300 [D loss: 0.703945875168, acc.: 0.00%] [G loss: 0.711749494076] [mll=88.635+-5.489] [ks=7.726]\n",
      "35400 [D loss: 0.703840136528, acc.: 0.00%] [G loss: 0.704643666744] [mll=94.317+-9.747] [ks=7.675]\n",
      "35500 [D loss: 0.70202088356, acc.: 0.00%] [G loss: 0.706067919731] [mll=89.644+-4.560] [ks=7.757]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "35600 [D loss: 0.717071890831, acc.: 0.00%] [G loss: 0.710770845413] [mll=88.264+-5.373] [ks=7.727]\n",
      "35700 [D loss: 0.711327552795, acc.: 0.00%] [G loss: 0.709364891052] [mll=89.689+-4.503] [ks=7.286]\n",
      "35800 [D loss: 0.723870038986, acc.: 0.00%] [G loss: 0.70659506321] [mll=89.274+-4.757] [ks=8.110]]\n",
      "35900 [D loss: 0.711000978947, acc.: 0.00%] [G loss: 0.709637105465] [mll=89.570+-4.700] [ks=8.113]\n",
      "36000 [D loss: 0.701994299889, acc.: 0.00%] [G loss: 0.707300186157] [mll=88.710+-5.371] [ks=8.426]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "36100 [D loss: 0.706588506699, acc.: 0.00%] [G loss: 0.707786202431] [mll=89.398+-4.628] [ks=7.479]\n",
      "36200 [D loss: 0.704453825951, acc.: 0.00%] [G loss: 0.706430315971] [mll=91.002+-5.248] [ks=7.465]\n",
      "36300 [D loss: 0.684785306454, acc.: 0.00%] [G loss: 0.704129338264] [mll=88.057+-5.257] [ks=7.505]\n",
      "36400 [D loss: 0.708750486374, acc.: 0.00%] [G loss: 0.709385931492] [mll=89.572+-4.639] [ks=8.337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36500 [D loss: 0.705522060394, acc.: 0.00%] [G loss: 0.712812066078] [mll=88.836+-5.334] [ks=7.720]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "36600 [D loss: 0.708122253418, acc.: 0.00%] [G loss: 0.707584857941] [mll=92.432+-7.241] [ks=7.572]\n",
      "36700 [D loss: 0.721576094627, acc.: 0.00%] [G loss: 0.716993331909] [mll=89.301+-5.154] [ks=7.466]\n",
      "36800 [D loss: 0.712229371071, acc.: 0.00%] [G loss: 0.710731565952] [mll=86.146+-7.901] [ks=7.640]\n",
      "36900 [D loss: 0.716271400452, acc.: 0.00%] [G loss: 0.713203370571] [mll=89.602+-4.928] [ks=7.409]\n",
      "37000 [D loss: 0.699379444122, acc.: 0.00%] [G loss: 0.882535099983] [mll=92.052+-11.154] [ks=7.715]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "37100 [D loss: 0.703875541687, acc.: 0.00%] [G loss: 0.713394224644] [mll=88.512+-5.901] [ks=8.695]\n",
      "37200 [D loss: 0.713873505592, acc.: 0.00%] [G loss: 0.710299432278] [mll=88.069+-4.426] [ks=8.030]\n",
      "37300 [D loss: 0.702547252178, acc.: 0.00%] [G loss: 0.710894167423] [mll=90.619+-5.179] [ks=7.601]\n",
      "37400 [D loss: 0.701507210732, acc.: 0.00%] [G loss: 0.714081823826] [mll=89.485+-5.299] [ks=7.496]\n",
      "37500 [D loss: 0.69133067131, acc.: 0.00%] [G loss: 0.709133565426] [mll=89.027+-5.221] [ks=7.980]]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "37600 [D loss: 0.719224452972, acc.: 0.00%] [G loss: 0.709392666817] [mll=89.389+-4.841] [ks=8.197]\n",
      "37700 [D loss: 0.703711152077, acc.: 0.00%] [G loss: 0.713724732399] [mll=89.949+-4.793] [ks=7.243]\n",
      "37800 [D loss: 0.701157271862, acc.: 0.00%] [G loss: 0.710692763329] [mll=83.224+-10.050] [ks=8.648]\n",
      "37900 [D loss: 0.688983678818, acc.: 0.00%] [G loss: 0.712508738041] [mll=89.417+-4.306] [ks=7.464]\n",
      "38000 [D loss: 0.708992600441, acc.: 0.00%] [G loss: 0.708924233913] [mll=90.023+-4.676] [ks=7.989]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "38100 [D loss: 0.7145357728, acc.: 0.00%] [G loss: 0.729870259762] [mll=89.452+-4.719] [ks=7.469]9]\n",
      "38200 [D loss: 0.705279588699, acc.: 0.00%] [G loss: 0.71435302496] [mll=90.514+-5.393] [ks=7.435]]\n",
      "38300 [D loss: 0.711388468742, acc.: 0.00%] [G loss: 0.725302755833] [mll=90.037+-5.240] [ks=7.563]\n",
      "38400 [D loss: 0.703477442265, acc.: 0.00%] [G loss: 0.712942838669] [mll=88.557+-5.082] [ks=7.721]\n",
      "38500 [D loss: 0.701589345932, acc.: 0.00%] [G loss: 0.715257108212] [mll=87.723+-5.043] [ks=8.145]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "38600 [D loss: 0.704003572464, acc.: 0.00%] [G loss: 0.712816178799] [mll=89.229+-4.354] [ks=7.647]\n",
      "38700 [D loss: 0.704094171524, acc.: 0.00%] [G loss: 0.710822939873] [mll=88.848+-5.114] [ks=7.850]\n",
      "38800 [D loss: 0.706284701824, acc.: 0.00%] [G loss: 0.709960997105] [mll=90.079+-5.399] [ks=7.738]\n",
      "38900 [D loss: 0.698968529701, acc.: 0.00%] [G loss: 0.710062146187] [mll=89.312+-4.603] [ks=7.653]\n",
      "39000 [D loss: 0.77398276329, acc.: 0.00%] [G loss: 1.67228806019] [mll=89.649+-4.546] [ks=8.039]]]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "39100 [D loss: 0.705573499203, acc.: 0.00%] [G loss: 0.716140627861] [mll=73.721+-10.811] [ks=9.099]\n",
      "39200 [D loss: 0.705117583275, acc.: 0.00%] [G loss: 0.707184791565] [mll=89.155+-5.208] [ks=7.279]\n",
      "39300 [D loss: 0.702657341957, acc.: 0.00%] [G loss: 0.706841051579] [mll=89.084+-4.685] [ks=7.876]\n",
      "39400 [D loss: 0.726020753384, acc.: 0.00%] [G loss: 0.711998045444] [mll=90.033+-4.178] [ks=7.553]\n",
      "39500 [D loss: 0.702713787556, acc.: 0.00%] [G loss: 0.86836630106] [mll=82.805+-9.689] [ks=8.397]]\n",
      "10000/10000 [==============================] - 0s 29us/step\n",
      "39600 [D loss: 0.703518509865, acc.: 0.00%] [G loss: 0.715487480164] [mll=90.378+-4.643] [ks=7.544]\n",
      "39700 [D loss: 0.703800201416, acc.: 0.00%] [G loss: 0.702520787716] [mll=89.024+-4.227] [ks=7.506]\n",
      "39800 [D loss: 0.708959341049, acc.: 0.00%] [G loss: 0.703211069107] [mll=90.192+-3.874] [ks=7.555]\n",
      "39900 [D loss: 0.706861019135, acc.: 0.00%] [G loss: 0.70931237936] [mll=89.576+-3.989] [ks=7.246]]\n",
      "40000 [D loss: 0.648109674454, acc.: 0.00%] [G loss: 0.72912466526] [mll=89.619+-4.309] [ks=7.181]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "40100 [D loss: 0.817033648491, acc.: 0.00%] [G loss: 0.713569700718] [mll=90.092+-4.325] [ks=8.844]\n",
      "40200 [D loss: 0.707570672035, acc.: 0.00%] [G loss: 0.721496045589] [mll=88.958+-4.166] [ks=7.396]\n",
      "40300 [D loss: 0.702459871769, acc.: 0.00%] [G loss: 0.708072304726] [mll=93.198+-7.666] [ks=7.812]\n",
      "40400 [D loss: 0.703928828239, acc.: 0.00%] [G loss: 0.710413217545] [mll=89.636+-5.150] [ks=8.338]\n",
      "40500 [D loss: 0.701942741871, acc.: 0.00%] [G loss: 0.708112001419] [mll=89.264+-4.206] [ks=7.642]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "40600 [D loss: 0.706634044647, acc.: 0.00%] [G loss: 0.708225250244] [mll=89.754+-4.533] [ks=7.680]\n",
      "40700 [D loss: 0.680338740349, acc.: 0.00%] [G loss: 0.703446149826] [mll=89.157+-4.676] [ks=7.383]\n",
      "40800 [D loss: 0.70509314537, acc.: 0.00%] [G loss: 0.718726634979] [mll=89.343+-4.527] [ks=8.639]]\n",
      "40900 [D loss: 0.705144584179, acc.: 0.00%] [G loss: 0.721526861191] [mll=88.302+-5.060] [ks=7.700]\n",
      "41000 [D loss: 0.666600346565, acc.: 0.00%] [G loss: 0.817695081234] [mll=88.929+-5.744] [ks=7.542]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "41100 [D loss: 0.71805781126, acc.: 0.00%] [G loss: 0.733194231987] [mll=79.085+-9.613] [ks=9.519]]\n",
      "41200 [D loss: 0.706954836845, acc.: 0.00%] [G loss: 0.724976599216] [mll=89.031+-4.702] [ks=7.732]\n",
      "41300 [D loss: 0.720339298248, acc.: 0.00%] [G loss: 0.71083521843] [mll=88.833+-5.463] [ks=7.347]]\n",
      "41400 [D loss: 0.722404360771, acc.: 0.00%] [G loss: 0.715879499912] [mll=88.990+-3.993] [ks=7.597]\n",
      "41500 [D loss: 0.701485276222, acc.: 0.00%] [G loss: 0.725398600101] [mll=88.366+-5.079] [ks=7.723]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "41600 [D loss: 0.706056118011, acc.: 0.00%] [G loss: 0.722383081913] [mll=89.198+-4.969] [ks=7.618]\n",
      "41700 [D loss: 0.639634728432, acc.: 0.00%] [G loss: 0.734765052795] [mll=88.004+-5.211] [ks=7.942]\n",
      "41800 [D loss: 0.706054270267, acc.: 0.00%] [G loss: 0.72627723217] [mll=89.359+-4.661] [ks=8.831]]\n",
      "41900 [D loss: 0.706131398678, acc.: 0.00%] [G loss: 0.726276159286] [mll=89.026+-4.946] [ks=7.352]\n",
      "42000 [D loss: 0.732475042343, acc.: 0.00%] [G loss: 0.706424832344] [mll=89.140+-4.880] [ks=7.545]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "42100 [D loss: 0.705157279968, acc.: 0.00%] [G loss: 0.713542819023] [mll=89.808+-4.254] [ks=8.092]\n",
      "42200 [D loss: 0.702015399933, acc.: 0.00%] [G loss: 0.732565462589] [mll=90.792+-5.437] [ks=7.617]\n",
      "42300 [D loss: 0.698718249798, acc.: 0.00%] [G loss: 0.744698762894] [mll=88.433+-4.707] [ks=7.591]\n",
      "42400 [D loss: 0.701794147491, acc.: 0.00%] [G loss: 0.714874207973] [mll=88.607+-5.209] [ks=8.030]\n",
      "42500 [D loss: 0.698140621185, acc.: 0.00%] [G loss: 0.717746853828] [mll=88.238+-5.183] [ks=8.064]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "42600 [D loss: 0.697277486324, acc.: 0.00%] [G loss: 0.725233018398] [mll=89.616+-4.571] [ks=7.675]\n",
      "42700 [D loss: 0.708233833313, acc.: 0.00%] [G loss: 0.71466255188] [mll=88.911+-4.888] [ks=8.355]]\n",
      "42800 [D loss: 0.703530550003, acc.: 0.00%] [G loss: 0.721544742584] [mll=89.202+-4.483] [ks=7.721]\n",
      "42900 [D loss: 0.704767823219, acc.: 0.00%] [G loss: 0.733113348484] [mll=88.478+-4.705] [ks=7.489]\n",
      "43000 [D loss: 0.705541491508, acc.: 0.00%] [G loss: 0.71436214447] [mll=90.546+-5.557] [ks=8.333]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "43100 [D loss: 0.702637910843, acc.: 0.00%] [G loss: 0.716343402863] [mll=89.613+-4.585] [ks=7.544]\n",
      "43200 [D loss: 0.694018721581, acc.: 0.00%] [G loss: 0.710411131382] [mll=89.457+-4.336] [ks=7.548]\n",
      "43300 [D loss: 0.698461592197, acc.: 0.00%] [G loss: 0.72366720438] [mll=89.201+-4.806] [ks=8.770]]\n",
      "43400 [D loss: 0.704781293869, acc.: 0.00%] [G loss: 0.714963793755] [mll=82.373+-8.200] [ks=9.364]\n",
      "43500 [D loss: 0.714638352394, acc.: 0.00%] [G loss: 0.703275203705] [mll=89.467+-4.133] [ks=7.507]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "43600 [D loss: 0.699223041534, acc.: 0.00%] [G loss: 0.709556937218] [mll=89.188+-4.736] [ks=8.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43700 [D loss: 0.705519318581, acc.: 0.00%] [G loss: 0.713390767574] [mll=88.997+-4.798] [ks=8.188]\n",
      "43800 [D loss: 0.698737800121, acc.: 0.00%] [G loss: 0.704501211643] [mll=89.266+-4.967] [ks=7.411]\n",
      "43900 [D loss: 0.703848719597, acc.: 0.00%] [G loss: 0.711601316929] [mll=87.895+-6.054] [ks=8.863]\n",
      "44000 [D loss: 0.703992366791, acc.: 0.00%] [G loss: 0.71176725626] [mll=86.763+-5.650] [ks=7.759]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "44100 [D loss: 0.704346179962, acc.: 0.00%] [G loss: 0.721140861511] [mll=89.405+-4.586] [ks=7.827]\n",
      "44200 [D loss: 0.698237895966, acc.: 0.00%] [G loss: 0.712518751621] [mll=95.130+-9.943] [ks=8.358]\n",
      "44300 [D loss: 0.729729712009, acc.: 0.00%] [G loss: 0.707991063595] [mll=90.158+-4.732] [ks=8.146]\n",
      "44400 [D loss: 0.753131508827, acc.: 0.00%] [G loss: 0.71178394556] [mll=89.864+-4.397] [ks=7.662]]\n",
      "44500 [D loss: 0.70460575819, acc.: 0.00%] [G loss: 0.708055496216] [mll=89.025+-4.653] [ks=7.672]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "44600 [D loss: 0.709273934364, acc.: 0.00%] [G loss: 0.712517976761] [mll=89.141+-4.387] [ks=7.356]\n",
      "44700 [D loss: 0.702498555183, acc.: 0.00%] [G loss: 0.709065020084] [mll=89.233+-4.681] [ks=7.057]\n",
      "44800 [D loss: 0.709979116917, acc.: 0.00%] [G loss: 0.709048688412] [mll=89.420+-3.972] [ks=7.720]\n",
      "44900 [D loss: 0.708261549473, acc.: 0.00%] [G loss: 0.704830229282] [mll=90.880+-6.006] [ks=7.878]\n",
      "45000 [D loss: 0.704607248306, acc.: 0.00%] [G loss: 0.71130412817] [mll=89.796+-3.902] [ks=7.878]]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "45100 [D loss: 0.704650223255, acc.: 0.00%] [G loss: 0.712122678757] [mll=89.182+-3.988] [ks=7.725]\n",
      "45200 [D loss: 0.702084302902, acc.: 0.00%] [G loss: 0.707016468048] [mll=89.279+-4.668] [ks=7.608]\n",
      "45300 [D loss: 0.663610339165, acc.: 0.00%] [G loss: 0.730598390102] [mll=89.802+-4.638] [ks=7.827]\n",
      "45400 [D loss: 0.703830599785, acc.: 0.00%] [G loss: 0.708980023861] [mll=88.905+-4.511] [ks=9.104]\n",
      "45500 [D loss: 0.685710847378, acc.: 0.00%] [G loss: 0.705767154694] [mll=90.080+-4.647] [ks=7.764]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "45600 [D loss: 0.705948591232, acc.: 0.00%] [G loss: 0.70878636837] [mll=89.649+-5.401] [ks=8.392]]\n",
      "45700 [D loss: 0.705794930458, acc.: 0.00%] [G loss: 0.712084412575] [mll=88.692+-5.447] [ks=7.635]\n",
      "45800 [D loss: 0.703899025917, acc.: 0.00%] [G loss: 0.709158837795] [mll=90.699+-5.697] [ks=7.769]\n",
      "45900 [D loss: 0.791731953621, acc.: 0.00%] [G loss: 0.710125565529] [mll=86.743+-6.389] [ks=7.704]\n",
      "46000 [D loss: 0.692628264427, acc.: 0.00%] [G loss: 0.726290166378] [mll=89.173+-4.499] [ks=7.436]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "46100 [D loss: 0.634572863579, acc.: 0.00%] [G loss: 0.741892337799] [mll=89.898+-5.252] [ks=7.908]\n",
      "46200 [D loss: 0.714086532593, acc.: 0.00%] [G loss: 0.710584700108] [mll=86.869+-6.472] [ks=8.064]\n",
      "46300 [D loss: 0.687035560608, acc.: 0.00%] [G loss: 0.724556028843] [mll=90.072+-4.010] [ks=7.283]\n",
      "46400 [D loss: 0.709194481373, acc.: 0.00%] [G loss: 0.724378526211] [mll=89.976+-4.563] [ks=7.574]\n",
      "46500 [D loss: 0.705055892467, acc.: 0.00%] [G loss: 0.712545335293] [mll=89.473+-4.745] [ks=7.512]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "46600 [D loss: 0.724738359451, acc.: 0.00%] [G loss: 0.706783294678] [mll=91.962+-7.791] [ks=7.565]\n",
      "46700 [D loss: 0.861845195293, acc.: 0.00%] [G loss: 0.727444410324] [mll=89.817+-5.017] [ks=7.527]\n",
      "46800 [D loss: 0.709694027901, acc.: 0.00%] [G loss: 0.706556558609] [mll=86.856+-10.634] [ks=7.330]\n",
      "46900 [D loss: 0.705531597137, acc.: 0.00%] [G loss: 0.70971429348] [mll=89.460+-5.068] [ks=7.393]]\n",
      "47000 [D loss: 0.705172538757, acc.: 0.00%] [G loss: 0.708702623844] [mll=86.101+-7.185] [ks=7.765]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "47100 [D loss: 0.703290104866, acc.: 0.00%] [G loss: 0.708803117275] [mll=90.582+-5.190] [ks=7.278]\n",
      "47200 [D loss: 0.690791249275, acc.: 0.00%] [G loss: 0.70454031229] [mll=88.810+-5.045] [ks=7.923]]\n",
      "47300 [D loss: 0.701826632023, acc.: 0.00%] [G loss: 0.717148900032] [mll=90.295+-4.702] [ks=8.382]\n",
      "47400 [D loss: 0.712089896202, acc.: 0.00%] [G loss: 0.711591303349] [mll=88.999+-4.505] [ks=7.484]\n",
      "47500 [D loss: 0.702834486961, acc.: 0.00%] [G loss: 0.703578948975] [mll=88.260+-5.096] [ks=7.699]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "47600 [D loss: 0.695866107941, acc.: 0.00%] [G loss: 0.701901435852] [mll=90.299+-4.552] [ks=7.521]\n",
      "47700 [D loss: 0.709189593792, acc.: 0.00%] [G loss: 0.705254018307] [mll=89.105+-4.958] [ks=7.882]\n",
      "47800 [D loss: 0.703973472118, acc.: 0.00%] [G loss: 0.707788527012] [mll=89.173+-5.853] [ks=7.823]\n",
      "47900 [D loss: 0.730094671249, acc.: 0.00%] [G loss: 0.70766556263] [mll=88.997+-5.350] [ks=7.946]]\n",
      "48000 [D loss: 0.720726013184, acc.: 0.98%] [G loss: 0.73983424902] [mll=89.115+-5.063] [ks=8.107]]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "48100 [D loss: 0.208225950599, acc.: 0.20%] [G loss: 12.1813983917] [mll=94.941+-15.153] [ks=7.619]]\n",
      "48200 [D loss: 0.166778996587, acc.: 0.39%] [G loss: 8.84929561615] [mll=34.728+-12.045] [ks=13.001]\n",
      "48300 [D loss: 0.17115278542, acc.: 0.39%] [G loss: 6.98073911667] [mll=45.853+-15.109] [ks=11.707]]]\n",
      "48400 [D loss: 0.224295288324, acc.: 0.20%] [G loss: 4.34685850143] [mll=56.378+-16.787] [ks=10.681]]\n",
      "48500 [D loss: 0.260436058044, acc.: 0.20%] [G loss: 9.57701396942] [mll=59.607+-15.419] [ks=10.548]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "48600 [D loss: 0.205834746361, acc.: 0.00%] [G loss: 6.19991779327] [mll=55.809+-15.731] [ks=9.879]\n",
      "48700 [D loss: 0.306528538465, acc.: 0.39%] [G loss: 5.06850862503] [mll=68.450+-20.173] [ks=9.745]\n",
      "48800 [D loss: 0.556865930557, acc.: 0.00%] [G loss: 1.33362698555] [mll=60.793+-21.223] [ks=10.099]\n",
      "48900 [D loss: 0.610390663147, acc.: 0.00%] [G loss: 1.00739228725] [mll=95.832+-17.683] [ks=9.133]]\n",
      "49000 [D loss: 0.631156802177, acc.: 0.00%] [G loss: 0.894347667694] [mll=91.244+-8.633] [ks=8.574]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "49100 [D loss: 0.689613997936, acc.: 0.00%] [G loss: 0.833387315273] [mll=82.736+-9.511] [ks=8.865]\n",
      "49200 [D loss: 0.701028466225, acc.: 0.00%] [G loss: 0.872137963772] [mll=90.568+-6.496] [ks=7.782]\n",
      "49300 [D loss: 0.70659840107, acc.: 0.00%] [G loss: 0.7829028368] [mll=90.527+-8.779] [ks=7.868]68]\n",
      "49400 [D loss: 0.699764728546, acc.: 0.00%] [G loss: 1.00855624676] [mll=90.376+-5.739] [ks=7.347]]\n",
      "49500 [D loss: 0.163913846016, acc.: 0.00%] [G loss: 5.64171648026] [mll=88.857+-6.209] [ks=8.194]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "49600 [D loss: 0.161869883537, acc.: 0.20%] [G loss: 11.0524349213] [mll=56.262+-11.467] [ks=11.692]\n",
      "49700 [D loss: 0.138532489538, acc.: 0.00%] [G loss: 11.1173248291] [mll=61.585+-17.034] [ks=10.290]\n",
      "49800 [D loss: 0.223298221827, acc.: 0.78%] [G loss: 7.59404850006] [mll=59.769+-16.924] [ks=10.528]\n",
      "49900 [D loss: 0.238806545734, acc.: 0.00%] [G loss: 9.72192764282] [mll=52.820+-19.042] [ks=10.862]\n",
      "50000 [D loss: 0.156949341297, acc.: 0.59%] [G loss: 7.80145215988] [mll=63.491+-19.813] [ks=10.395]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "50100 [D loss: 0.258982300758, acc.: 0.20%] [G loss: 6.58203840256] [mll=56.861+-23.349] [ks=10.519]\n",
      "50200 [D loss: 0.367560833693, acc.: 0.39%] [G loss: 5.90391206741] [mll=65.352+-16.785] [ks=10.276]\n",
      "50300 [D loss: 0.546524822712, acc.: 0.00%] [G loss: 1.04820811749] [mll=80.870+-17.951] [ks=9.127]\n",
      "50400 [D loss: 0.661818027496, acc.: 0.00%] [G loss: 0.900250017643] [mll=97.145+-9.151] [ks=9.035]\n",
      "50500 [D loss: 0.649336397648, acc.: 0.00%] [G loss: 0.874628424644] [mll=91.812+-8.256] [ks=8.089]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "50600 [D loss: 0.692476272583, acc.: 0.00%] [G loss: 0.815479159355] [mll=90.916+-7.790] [ks=8.010]\n",
      "50700 [D loss: 0.662801742554, acc.: 0.20%] [G loss: 2.77315139771] [mll=90.985+-5.890] [ks=7.893]]\n",
      "50800 [D loss: 0.71238052845, acc.: 0.00%] [G loss: 0.801840245724] [mll=92.545+-9.559] [ks=9.053]]\n",
      "50900 [D loss: 0.580454647541, acc.: 0.00%] [G loss: 0.891316354275] [mll=91.365+-7.626] [ks=7.784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000 [D loss: 0.705635786057, acc.: 0.00%] [G loss: 0.793285429478] [mll=87.140+-7.399] [ks=8.974]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "51100 [D loss: 0.703171908855, acc.: 0.00%] [G loss: 0.761603415012] [mll=89.817+-6.224] [ks=7.790]\n",
      "51200 [D loss: 0.715342521667, acc.: 0.00%] [G loss: 0.777666032314] [mll=89.928+-5.862] [ks=7.629]\n",
      "51300 [D loss: 0.703590154648, acc.: 0.00%] [G loss: 0.736074447632] [mll=93.345+-17.120] [ks=7.783]\n",
      "51400 [D loss: 0.694479286671, acc.: 0.00%] [G loss: 0.739475786686] [mll=89.543+-5.207] [ks=7.918]\n",
      "51500 [D loss: 0.703764557838, acc.: 0.00%] [G loss: 0.739971041679] [mll=89.947+-5.749] [ks=7.806]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "51600 [D loss: 0.702567756176, acc.: 0.00%] [G loss: 0.729645967484] [mll=92.100+-9.791] [ks=7.543]\n",
      "51700 [D loss: 0.69961309433, acc.: 0.00%] [G loss: 0.745355367661] [mll=88.948+-6.045] [ks=8.008]]\n",
      "51800 [D loss: 0.708131551743, acc.: 0.00%] [G loss: 0.727123200893] [mll=89.899+-6.362] [ks=7.784]\n",
      "51900 [D loss: 0.868329048157, acc.: 0.00%] [G loss: 0.785324513912] [mll=88.678+-5.478] [ks=7.980]\n",
      "52000 [D loss: 0.706553459167, acc.: 0.00%] [G loss: 0.725942671299] [mll=84.729+-6.593] [ks=9.166]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "52100 [D loss: 0.657395422459, acc.: 0.00%] [G loss: 0.77836316824] [mll=89.472+-5.388] [ks=7.882]]\n",
      "52200 [D loss: 0.692995369434, acc.: 0.00%] [G loss: 0.723768591881] [mll=88.687+-6.563] [ks=8.544]\n",
      "52300 [D loss: 0.687523841858, acc.: 0.20%] [G loss: 0.73384386301] [mll=89.021+-5.835] [ks=7.623]]\n",
      "52400 [D loss: 0.703050971031, acc.: 0.00%] [G loss: 0.718168199062] [mll=90.699+-5.335] [ks=7.994]\n",
      "52500 [D loss: 0.702302753925, acc.: 0.00%] [G loss: 0.724058032036] [mll=89.678+-5.825] [ks=8.240]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "52600 [D loss: 0.710945010185, acc.: 0.00%] [G loss: 0.716757535934] [mll=89.483+-5.209] [ks=7.858]\n",
      "52700 [D loss: 0.700903773308, acc.: 0.00%] [G loss: 0.715650498867] [mll=89.886+-5.301] [ks=7.713]\n",
      "52800 [D loss: 0.701186418533, acc.: 0.00%] [G loss: 0.728908121586] [mll=90.016+-5.292] [ks=7.630]\n",
      "52900 [D loss: 0.699869632721, acc.: 0.00%] [G loss: 0.7187038064] [mll=89.937+-5.707] [ks=7.914]4]\n",
      "53000 [D loss: 0.705827355385, acc.: 0.00%] [G loss: 0.727169454098] [mll=89.155+-5.744] [ks=7.702]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "53100 [D loss: 0.716490507126, acc.: 0.00%] [G loss: 0.719345450401] [mll=90.967+-6.802] [ks=7.701]\n",
      "53200 [D loss: 0.698651731014, acc.: 0.00%] [G loss: 0.712801933289] [mll=89.697+-5.282] [ks=7.656]\n",
      "53300 [D loss: 0.711388289928, acc.: 0.00%] [G loss: 0.704627752304] [mll=89.670+-5.644] [ks=7.660]\n",
      "53400 [D loss: 0.707779526711, acc.: 0.00%] [G loss: 0.718339979649] [mll=89.710+-5.758] [ks=8.185]\n",
      "53500 [D loss: 0.701721429825, acc.: 0.00%] [G loss: 0.715593457222] [mll=89.035+-4.685] [ks=8.028]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "53600 [D loss: 0.708760738373, acc.: 0.00%] [G loss: 0.71821886301] [mll=89.540+-5.276] [ks=7.642]]\n",
      "53700 [D loss: 0.690187692642, acc.: 0.00%] [G loss: 0.720539033413] [mll=89.647+-5.729] [ks=7.805]\n",
      "53800 [D loss: 0.701380968094, acc.: 0.00%] [G loss: 0.71943706274] [mll=89.990+-5.305] [ks=8.075]]\n",
      "53900 [D loss: 0.702536702156, acc.: 0.00%] [G loss: 0.712487697601] [mll=89.989+-5.105] [ks=7.749]\n",
      "54000 [D loss: 0.698064088821, acc.: 0.00%] [G loss: 0.711401343346] [mll=89.639+-4.656] [ks=7.656]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "54100 [D loss: 0.724558949471, acc.: 0.00%] [G loss: 0.712252140045] [mll=89.021+-5.340] [ks=8.231]\n",
      "54200 [D loss: 0.704186439514, acc.: 0.00%] [G loss: 0.710969388485] [mll=89.572+-5.066] [ks=7.751]\n",
      "54300 [D loss: 0.70222645998, acc.: 0.00%] [G loss: 1.19407975674] [mll=89.591+-5.213] [ks=7.703]]]\n",
      "54400 [D loss: 0.686662137508, acc.: 0.00%] [G loss: 1.0101017952] [mll=90.596+-7.629] [ks=7.778]]]\n",
      "54500 [D loss: 0.696860492229, acc.: 0.00%] [G loss: 0.712859511375] [mll=88.380+-5.188] [ks=8.392]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "54600 [D loss: 0.702343702316, acc.: 0.00%] [G loss: 0.71135365963] [mll=89.494+-5.160] [ks=7.704]]\n",
      "54700 [D loss: 0.712490081787, acc.: 0.00%] [G loss: 0.715168893337] [mll=89.387+-4.969] [ks=7.821]\n",
      "54800 [D loss: 0.695196509361, acc.: 0.00%] [G loss: 0.72089856863] [mll=89.755+-5.200] [ks=7.920]]\n",
      "54900 [D loss: 0.701831042767, acc.: 0.00%] [G loss: 0.715981245041] [mll=90.050+-5.703] [ks=7.622]\n",
      "55000 [D loss: 0.701218724251, acc.: 0.00%] [G loss: 0.718985021114] [mll=89.813+-4.744] [ks=7.713]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "55100 [D loss: 0.693300843239, acc.: 0.00%] [G loss: 0.711502492428] [mll=88.492+-5.263] [ks=7.745]\n",
      "55200 [D loss: 0.701010584831, acc.: 0.00%] [G loss: 0.721694529057] [mll=89.400+-4.705] [ks=8.031]\n",
      "55300 [D loss: 0.69773375988, acc.: 0.00%] [G loss: 0.707738518715] [mll=86.414+-10.546] [ks=7.784]]\n",
      "55400 [D loss: 0.700226187706, acc.: 0.00%] [G loss: 0.713475167751] [mll=89.179+-5.086] [ks=7.736]\n",
      "55500 [D loss: 0.701647698879, acc.: 0.00%] [G loss: 0.713028550148] [mll=89.618+-5.203] [ks=7.786]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "55600 [D loss: 0.70912027359, acc.: 0.39%] [G loss: 0.730687081814] [mll=89.434+-5.134] [ks=7.695]]\n",
      "55700 [D loss: 0.702801465988, acc.: 0.00%] [G loss: 0.718698561192] [mll=92.874+-12.814] [ks=7.637]\n",
      "55800 [D loss: 0.702429294586, acc.: 0.00%] [G loss: 0.712088942528] [mll=88.660+-5.618] [ks=8.147]\n",
      "55900 [D loss: 0.699120521545, acc.: 0.00%] [G loss: 0.706094205379] [mll=89.803+-4.626] [ks=7.634]\n",
      "56000 [D loss: 0.702129006386, acc.: 0.00%] [G loss: 0.70806157589] [mll=89.641+-4.556] [ks=8.136]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "56100 [D loss: 0.70935434103, acc.: 0.20%] [G loss: 0.717790186405] [mll=89.292+-4.805] [ks=7.702]]\n",
      "56200 [D loss: 0.685684800148, acc.: 0.00%] [G loss: 0.69862985611] [mll=91.592+-12.315] [ks=7.747]]\n",
      "56300 [D loss: 0.702180504799, acc.: 0.00%] [G loss: 0.715349078178] [mll=89.283+-4.974] [ks=8.389]\n",
      "56400 [D loss: 0.707742631435, acc.: 0.00%] [G loss: 0.712516069412] [mll=89.259+-4.991] [ks=7.633]\n",
      "56500 [D loss: 0.697033703327, acc.: 0.20%] [G loss: 0.702465772629] [mll=90.132+-5.248] [ks=7.774]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "56600 [D loss: 0.709955573082, acc.: 0.00%] [G loss: 0.712621688843] [mll=89.485+-4.766] [ks=8.158]\n",
      "56700 [D loss: 0.696700751781, acc.: 0.00%] [G loss: 0.708792090416] [mll=89.089+-4.672] [ks=7.798]\n",
      "56800 [D loss: 0.69943857193, acc.: 0.00%] [G loss: 0.724089562893] [mll=89.780+-5.559] [ks=7.926]]\n",
      "56900 [D loss: 0.715898871422, acc.: 0.00%] [G loss: 0.710299730301] [mll=89.817+-6.341] [ks=8.157]\n",
      "57000 [D loss: 0.677192032337, acc.: 0.00%] [G loss: 0.71820473671] [mll=89.581+-4.892] [ks=7.906]]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "57100 [D loss: 0.710798084736, acc.: 0.20%] [G loss: 0.712209641933] [mll=89.258+-6.083] [ks=8.347]\n",
      "57200 [D loss: 0.698359966278, acc.: 0.00%] [G loss: 0.710648417473] [mll=90.028+-5.386] [ks=7.586]\n",
      "57300 [D loss: 0.709143877029, acc.: 0.00%] [G loss: 0.708455145359] [mll=89.588+-4.672] [ks=7.732]\n",
      "57400 [D loss: 0.693709611893, acc.: 0.00%] [G loss: 0.703787267208] [mll=89.710+-4.509] [ks=7.740]\n",
      "57500 [D loss: 0.716082572937, acc.: 0.00%] [G loss: 0.709362447262] [mll=90.384+-4.539] [ks=8.198]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "57600 [D loss: 0.697558045387, acc.: 0.00%] [G loss: 0.709317922592] [mll=88.520+-5.024] [ks=8.017]\n",
      "57700 [D loss: 0.708573758602, acc.: 0.00%] [G loss: 0.713470578194] [mll=89.103+-5.631] [ks=8.353]\n",
      "57800 [D loss: 0.697559118271, acc.: 0.00%] [G loss: 0.707021176815] [mll=89.872+-4.882] [ks=7.497]\n",
      "57900 [D loss: 0.689338803291, acc.: 0.00%] [G loss: 0.70778799057] [mll=89.478+-4.432] [ks=7.537]]\n",
      "58000 [D loss: 0.703444182873, acc.: 0.00%] [G loss: 0.70888364315] [mll=90.353+-4.866] [ks=8.026]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "58100 [D loss: 0.693093657494, acc.: 0.00%] [G loss: 0.703014433384] [mll=89.400+-4.772] [ks=7.631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58200 [D loss: 0.70197725296, acc.: 0.00%] [G loss: 0.718428015709] [mll=89.854+-5.489] [ks=8.239]]\n",
      "58300 [D loss: 0.708971738815, acc.: 0.00%] [G loss: 0.720229685307] [mll=89.599+-4.848] [ks=7.760]\n",
      "58400 [D loss: 0.70149987936, acc.: 0.00%] [G loss: 0.710673689842] [mll=89.726+-4.748] [ks=7.727]]\n",
      "58500 [D loss: 0.702012717724, acc.: 0.00%] [G loss: 0.705800652504] [mll=91.282+-6.112] [ks=7.694]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "58600 [D loss: 0.708502411842, acc.: 0.00%] [G loss: 0.736524343491] [mll=89.272+-4.798] [ks=7.781]\n",
      "58700 [D loss: 0.707588016987, acc.: 0.00%] [G loss: 0.700138688087] [mll=91.908+-11.898] [ks=7.783]\n",
      "58800 [D loss: 0.708185732365, acc.: 0.00%] [G loss: 0.70997852087] [mll=89.591+-4.562] [ks=8.092]]\n",
      "58900 [D loss: 0.71688836813, acc.: 0.00%] [G loss: 0.708864629269] [mll=89.383+-4.854] [ks=7.696]]\n",
      "59000 [D loss: 0.721492052078, acc.: 0.00%] [G loss: 0.704332888126] [mll=89.800+-5.028] [ks=7.595]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "59100 [D loss: 0.703366756439, acc.: 0.00%] [G loss: 0.712556242943] [mll=89.431+-4.919] [ks=7.570]\n",
      "59200 [D loss: 0.77921795845, acc.: 0.00%] [G loss: 0.709033966064] [mll=87.831+-5.802] [ks=8.275]]\n",
      "59300 [D loss: 0.703852713108, acc.: 0.00%] [G loss: 0.708426356316] [mll=89.571+-5.173] [ks=7.592]\n",
      "59400 [D loss: 0.700220584869, acc.: 0.00%] [G loss: 0.709329664707] [mll=89.497+-4.775] [ks=7.789]\n",
      "59500 [D loss: 0.709038496017, acc.: 0.00%] [G loss: 0.706974089146] [mll=89.516+-4.755] [ks=7.791]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "59600 [D loss: 0.701637029648, acc.: 0.00%] [G loss: 0.704196989536] [mll=91.184+-5.761] [ks=7.709]\n",
      "59700 [D loss: 0.70228099823, acc.: 0.00%] [G loss: 0.709637403488] [mll=89.386+-5.011] [ks=7.806]]\n",
      "59800 [D loss: 0.84768807888, acc.: 0.00%] [G loss: 0.711998403072] [mll=88.924+-5.834] [ks=7.900]]\n",
      "59900 [D loss: 0.702907204628, acc.: 0.00%] [G loss: 0.70993667841] [mll=89.625+-4.872] [ks=8.505]]\n",
      "60000 [D loss: 0.701238036156, acc.: 0.00%] [G loss: 0.708551347256] [mll=89.549+-4.894] [ks=7.633]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "60100 [D loss: 0.708914279938, acc.: 0.00%] [G loss: 0.723523378372] [mll=90.088+-4.998] [ks=7.750]\n",
      "60200 [D loss: 0.705972790718, acc.: 0.00%] [G loss: 0.714224338531] [mll=89.159+-5.662] [ks=8.347]\n",
      "60300 [D loss: 0.694844484329, acc.: 0.00%] [G loss: 0.776293754578] [mll=89.784+-4.749] [ks=7.629]\n",
      "60400 [D loss: 0.702254295349, acc.: 0.00%] [G loss: 0.73180192709] [mll=89.668+-5.382] [ks=7.853]]\n",
      "60500 [D loss: 0.722681283951, acc.: 0.00%] [G loss: 0.713754415512] [mll=90.484+-5.657] [ks=7.902]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "60600 [D loss: 0.738078415394, acc.: 0.00%] [G loss: 4.63264083862] [mll=88.862+-5.201] [ks=7.805]]\n",
      "60700 [D loss: 0.709451436996, acc.: 0.00%] [G loss: 0.715795099735] [mll=68.600+-11.453] [ks=10.502]\n",
      "60800 [D loss: 0.703010320663, acc.: 0.00%] [G loss: 0.70951551199] [mll=89.665+-5.329] [ks=7.626]]\n",
      "60900 [D loss: 0.705645680428, acc.: 0.00%] [G loss: 0.709341585636] [mll=89.533+-4.745] [ks=7.928]\n",
      "61000 [D loss: 0.810996770859, acc.: 0.00%] [G loss: 0.708593249321] [mll=89.240+-5.066] [ks=7.509]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "61100 [D loss: 0.697678864002, acc.: 0.00%] [G loss: 0.7051410079] [mll=89.562+-4.896] [ks=7.786]6]\n",
      "61200 [D loss: 0.707151770592, acc.: 0.00%] [G loss: 0.7125172019] [mll=88.844+-5.088] [ks=8.589]9]\n",
      "61300 [D loss: 0.702321946621, acc.: 0.00%] [G loss: 0.722939550877] [mll=89.353+-5.534] [ks=7.743]\n",
      "61400 [D loss: 0.703486084938, acc.: 0.00%] [G loss: 0.793547153473] [mll=89.220+-5.355] [ks=7.675]\n",
      "61500 [D loss: 0.708067536354, acc.: 0.00%] [G loss: 0.716828763485] [mll=87.289+-5.988] [ks=8.914]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "61600 [D loss: 0.671694934368, acc.: 0.00%] [G loss: 0.770856320858] [mll=89.142+-5.771] [ks=7.785]\n",
      "61700 [D loss: 0.70935434103, acc.: 0.00%] [G loss: 0.718265116215] [mll=88.407+-6.885] [ks=9.237]]\n",
      "61800 [D loss: 0.700518548489, acc.: 0.00%] [G loss: 0.705586373806] [mll=89.627+-5.022] [ks=7.650]\n",
      "61900 [D loss: 0.700694620609, acc.: 0.00%] [G loss: 0.703112959862] [mll=89.757+-4.419] [ks=7.733]\n",
      "62000 [D loss: 0.707445025444, acc.: 0.00%] [G loss: 0.709716320038] [mll=89.697+-4.979] [ks=7.631]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "62100 [D loss: 0.718278050423, acc.: 0.00%] [G loss: 0.710258066654] [mll=89.164+-5.135] [ks=7.727]\n",
      "62200 [D loss: 0.70295882225, acc.: 0.00%] [G loss: 0.709747314453] [mll=90.522+-5.777] [ks=7.992]]\n",
      "62300 [D loss: 0.707583427429, acc.: 0.00%] [G loss: 0.708021104336] [mll=88.977+-5.013] [ks=7.796]\n",
      "62400 [D loss: 0.698705673218, acc.: 0.00%] [G loss: 0.71155923605] [mll=89.416+-4.910] [ks=7.773]]\n",
      "62500 [D loss: 0.6998052001, acc.: 0.00%] [G loss: 0.706701159477] [mll=89.351+-5.698] [ks=7.955]5]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "62600 [D loss: 0.703919768333, acc.: 0.00%] [G loss: 0.720321893692] [mll=89.257+-4.967] [ks=7.707]\n",
      "62700 [D loss: 0.702890098095, acc.: 0.00%] [G loss: 0.706076562405] [mll=91.302+-6.523] [ks=7.566]\n",
      "62800 [D loss: 0.700654327869, acc.: 0.00%] [G loss: 0.710391104221] [mll=89.344+-5.132] [ks=7.562]\n",
      "62900 [D loss: 0.702726244926, acc.: 0.00%] [G loss: 0.707207620144] [mll=90.432+-4.994] [ks=7.701]\n",
      "63000 [D loss: 0.703769922256, acc.: 0.00%] [G loss: 0.70430713892] [mll=89.156+-4.930] [ks=7.790]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "63100 [D loss: 0.71480345726, acc.: 0.00%] [G loss: 0.741843223572] [mll=89.036+-5.125] [ks=7.582]]\n",
      "63200 [D loss: 0.704664766788, acc.: 0.00%] [G loss: 0.706131398678] [mll=88.847+-5.172] [ks=8.180]\n",
      "63300 [D loss: 0.7037307024, acc.: 0.00%] [G loss: 0.721416950226] [mll=90.102+-4.219] [ks=7.657]7]\n",
      "63400 [D loss: 0.706320285797, acc.: 0.00%] [G loss: 0.710833609104] [mll=89.718+-4.890] [ks=7.822]\n",
      "63500 [D loss: 0.719316482544, acc.: 0.00%] [G loss: 0.709548711777] [mll=89.346+-5.285] [ks=8.083]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "63600 [D loss: 0.701942801476, acc.: 0.00%] [G loss: 0.707760930061] [mll=89.776+-4.671] [ks=7.769]\n",
      "63700 [D loss: 0.70029425621, acc.: 0.00%] [G loss: 0.714244484901] [mll=89.670+-5.327] [ks=7.889]]\n",
      "63800 [D loss: 0.701827585697, acc.: 0.00%] [G loss: 0.708267152309] [mll=90.161+-5.489] [ks=7.658]\n",
      "63900 [D loss: 0.737106025219, acc.: 0.00%] [G loss: 0.706115663052] [mll=89.676+-4.442] [ks=7.776]\n",
      "64000 [D loss: 0.704027414322, acc.: 0.00%] [G loss: 0.727560579777] [mll=89.427+-5.531] [ks=7.604]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "64100 [D loss: 0.703848958015, acc.: 0.00%] [G loss: 0.724485397339] [mll=80.552+-8.265] [ks=9.692]\n",
      "64200 [D loss: 0.69261610508, acc.: 0.00%] [G loss: 0.89012992382] [mll=89.331+-5.703] [ks=7.648]8]\n",
      "64300 [D loss: 0.717712104321, acc.: 0.98%] [G loss: 0.733020424843] [mll=86.516+-5.500] [ks=8.306]\n",
      "64400 [D loss: 0.707457244396, acc.: 0.00%] [G loss: 0.709791243076] [mll=96.248+-13.453] [ks=8.491]\n",
      "64500 [D loss: 0.706377744675, acc.: 0.00%] [G loss: 0.709306299686] [mll=90.157+-5.833] [ks=7.717]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "64600 [D loss: 0.701515257359, acc.: 0.00%] [G loss: 0.705241441727] [mll=89.367+-5.570] [ks=7.744]\n",
      "64700 [D loss: 0.699273586273, acc.: 0.00%] [G loss: 0.70616209507] [mll=90.334+-4.970] [ks=7.676]]\n",
      "64800 [D loss: 0.701820492744, acc.: 0.00%] [G loss: 0.708614289761] [mll=90.362+-4.986] [ks=7.929]\n",
      "64900 [D loss: 0.699766159058, acc.: 0.00%] [G loss: 0.708843946457] [mll=89.384+-4.729] [ks=8.118]\n",
      "65000 [D loss: 0.704736709595, acc.: 0.20%] [G loss: 0.710481107235] [mll=88.956+-5.299] [ks=7.641]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "65100 [D loss: 0.72292226553, acc.: 0.00%] [G loss: 0.70748758316] [mll=90.823+-5.771] [ks=7.735]5]\n",
      "65200 [D loss: 0.658217787743, acc.: 0.00%] [G loss: 0.781585097313] [mll=89.620+-4.886] [ks=7.653]\n",
      "65300 [D loss: 0.700229525566, acc.: 0.00%] [G loss: 0.72110915184] [mll=89.308+-5.537] [ks=8.660]]\n",
      "65400 [D loss: 0.673244476318, acc.: 0.00%] [G loss: 0.722020089626] [mll=90.748+-5.163] [ks=7.920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65500 [D loss: 0.751438081264, acc.: 0.00%] [G loss: 0.713940620422] [mll=89.035+-5.189] [ks=8.600]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "65600 [D loss: 0.700940847397, acc.: 0.00%] [G loss: 0.707967817783] [mll=89.905+-4.894] [ks=7.804]\n",
      "65700 [D loss: 0.701370835304, acc.: 0.00%] [G loss: 0.703168869019] [mll=89.630+-5.340] [ks=7.514]\n",
      "65800 [D loss: 0.704057872295, acc.: 0.00%] [G loss: 0.707572102547] [mll=89.098+-5.021] [ks=7.609]\n",
      "65900 [D loss: 0.705821633339, acc.: 0.00%] [G loss: 0.711233496666] [mll=89.957+-4.975] [ks=7.600]\n",
      "66000 [D loss: 0.703531503677, acc.: 0.00%] [G loss: 0.710221171379] [mll=89.188+-5.033] [ks=7.898]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "66100 [D loss: 0.703510761261, acc.: 0.00%] [G loss: 0.707515120506] [mll=90.311+-5.478] [ks=7.551]\n",
      "66200 [D loss: 0.70751273632, acc.: 0.00%] [G loss: 0.714492201805] [mll=88.863+-7.776] [ks=7.789]]\n",
      "66300 [D loss: 0.704874992371, acc.: 0.00%] [G loss: 0.725037813187] [mll=91.011+-7.822] [ks=7.692]\n",
      "66400 [D loss: 0.700586616993, acc.: 0.00%] [G loss: 0.721008419991] [mll=89.525+-9.801] [ks=7.655]\n",
      "66500 [D loss: 0.710381984711, acc.: 0.00%] [G loss: 0.711317658424] [mll=88.746+-5.782] [ks=7.904]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "66600 [D loss: 0.706754386425, acc.: 0.00%] [G loss: 0.71664083004] [mll=89.728+-5.195] [ks=7.728]]\n",
      "66700 [D loss: 0.703594565392, acc.: 0.00%] [G loss: 0.712278842926] [mll=89.599+-6.690] [ks=8.043]\n",
      "66800 [D loss: 0.701267242432, acc.: 0.00%] [G loss: 0.708266675472] [mll=91.300+-5.916] [ks=7.916]\n",
      "66900 [D loss: 0.705021977425, acc.: 0.00%] [G loss: 0.707765102386] [mll=89.600+-5.117] [ks=7.791]\n",
      "67000 [D loss: 0.696658849716, acc.: 0.00%] [G loss: 0.717252016068] [mll=89.603+-5.098] [ks=7.755]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "67100 [D loss: 0.701463937759, acc.: 0.00%] [G loss: 0.710407316685] [mll=89.562+-5.636] [ks=8.222]\n",
      "67200 [D loss: 0.706263363361, acc.: 0.00%] [G loss: 0.707142412663] [mll=89.425+-5.146] [ks=7.559]\n",
      "67300 [D loss: 0.714433908463, acc.: 0.00%] [G loss: 0.725224018097] [mll=89.557+-5.205] [ks=7.833]\n",
      "67400 [D loss: 0.699080467224, acc.: 0.00%] [G loss: 0.713919758797] [mll=89.510+-5.354] [ks=7.599]\n",
      "67500 [D loss: 0.701273679733, acc.: 0.00%] [G loss: 0.710806310177] [mll=88.246+-5.535] [ks=8.396]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "67600 [D loss: 0.75076520443, acc.: 0.00%] [G loss: 0.744481444359] [mll=90.493+-4.755] [ks=7.737]]\n",
      "67700 [D loss: 0.703826129436, acc.: 0.00%] [G loss: 0.710749566555] [mll=94.922+-12.354] [ks=7.751]\n",
      "67800 [D loss: 0.706674575806, acc.: 0.00%] [G loss: 0.715063631535] [mll=91.179+-5.925] [ks=7.635]\n",
      "67900 [D loss: 0.699023246765, acc.: 0.00%] [G loss: 0.708438813686] [mll=90.278+-6.424] [ks=7.806]\n",
      "68000 [D loss: 0.704875230789, acc.: 0.00%] [G loss: 0.714749753475] [mll=89.808+-4.821] [ks=7.824]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "68100 [D loss: 0.701012849808, acc.: 0.00%] [G loss: 0.707213938236] [mll=87.221+-8.275] [ks=8.114]\n",
      "68200 [D loss: 0.703039288521, acc.: 0.00%] [G loss: 0.706071317196] [mll=89.350+-4.948] [ks=7.681]\n",
      "68300 [D loss: 0.707814097404, acc.: 0.00%] [G loss: 0.708688318729] [mll=89.168+-5.843] [ks=7.982]\n",
      "68400 [D loss: 0.706802845001, acc.: 0.00%] [G loss: 0.707917153835] [mll=89.391+-4.665] [ks=8.036]\n",
      "68500 [D loss: 0.702706694603, acc.: 0.00%] [G loss: 0.710141897202] [mll=89.088+-5.024] [ks=7.998]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "68600 [D loss: 0.703961968422, acc.: 0.00%] [G loss: 0.709171652794] [mll=89.155+-4.863] [ks=7.891]\n",
      "68700 [D loss: 0.699953556061, acc.: 0.00%] [G loss: 0.715757787228] [mll=89.420+-4.848] [ks=7.842]\n",
      "68800 [D loss: 0.701997041702, acc.: 0.00%] [G loss: 0.711893677711] [mll=89.114+-5.360] [ks=7.726]\n",
      "68900 [D loss: 0.703967690468, acc.: 0.00%] [G loss: 0.716761350632] [mll=89.209+-5.604] [ks=7.676]\n",
      "69000 [D loss: 0.73998105526, acc.: 0.00%] [G loss: 0.720516562462] [mll=88.968+-5.271] [ks=8.009]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "69100 [D loss: 0.70351755619, acc.: 0.00%] [G loss: 0.707593798637] [mll=87.756+-5.931] [ks=8.846]]\n",
      "69200 [D loss: 0.698249936104, acc.: 0.00%] [G loss: 0.722473144531] [mll=88.892+-5.416] [ks=8.008]\n",
      "69300 [D loss: 0.700950622559, acc.: 0.00%] [G loss: 0.712992608547] [mll=89.495+-4.313] [ks=8.232]\n",
      "69400 [D loss: 0.701853871346, acc.: 0.00%] [G loss: 0.752545773983] [mll=89.517+-4.910] [ks=7.987]\n",
      "69500 [D loss: 0.701728820801, acc.: 0.00%] [G loss: 0.704524934292] [mll=88.054+-6.008] [ks=8.351]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "69600 [D loss: 0.703675031662, acc.: 0.00%] [G loss: 0.709998190403] [mll=88.281+-5.571] [ks=7.762]\n",
      "69700 [D loss: 0.692880034447, acc.: 0.00%] [G loss: 0.720293104649] [mll=85.800+-10.617] [ks=8.132]\n",
      "69800 [D loss: 0.702182650566, acc.: 0.00%] [G loss: 0.712724745274] [mll=88.950+-5.880] [ks=8.211]\n",
      "69900 [D loss: 0.701691746712, acc.: 0.00%] [G loss: 0.711730897427] [mll=89.011+-5.577] [ks=7.794]\n",
      "70000 [D loss: 0.702351331711, acc.: 0.00%] [G loss: 0.710487246513] [mll=89.446+-5.647] [ks=7.709]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "70100 [D loss: 0.705357432365, acc.: 0.00%] [G loss: 0.708603739738] [mll=89.518+-4.973] [ks=7.788]\n",
      "70200 [D loss: 0.656306624413, acc.: 0.00%] [G loss: 0.745081305504] [mll=89.132+-5.274] [ks=7.731]\n",
      "70300 [D loss: 0.700710773468, acc.: 0.00%] [G loss: 0.712319791317] [mll=88.799+-5.194] [ks=8.721]\n",
      "70400 [D loss: 0.707722306252, acc.: 0.00%] [G loss: 0.716506123543] [mll=89.375+-5.750] [ks=7.656]\n",
      "70500 [D loss: 0.691936373711, acc.: 0.00%] [G loss: 0.713676512241] [mll=90.086+-5.251] [ks=7.844]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "70600 [D loss: 0.688611209393, acc.: 0.00%] [G loss: 0.719104647636] [mll=90.475+-5.644] [ks=8.213]\n",
      "70700 [D loss: 0.701498746872, acc.: 0.00%] [G loss: 0.714138865471] [mll=87.232+-6.236] [ks=9.164]\n",
      "70800 [D loss: 0.704223871231, acc.: 0.00%] [G loss: 0.703981816769] [mll=89.418+-4.893] [ks=7.749]\n",
      "70900 [D loss: 0.706525683403, acc.: 0.00%] [G loss: 0.721685349941] [mll=89.191+-4.885] [ks=7.877]\n",
      "71000 [D loss: 0.703042507172, acc.: 0.00%] [G loss: 0.710035681725] [mll=89.290+-5.659] [ks=8.081]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "71100 [D loss: 0.702147126198, acc.: 0.00%] [G loss: 0.733519077301] [mll=90.151+-4.911] [ks=7.686]\n",
      "71200 [D loss: 0.702086806297, acc.: 0.00%] [G loss: 0.712113261223] [mll=88.809+-5.117] [ks=8.397]\n",
      "71300 [D loss: 0.710402846336, acc.: 0.00%] [G loss: 0.707776606083] [mll=89.325+-4.640] [ks=8.069]\n",
      "71400 [D loss: 0.707559704781, acc.: 0.00%] [G loss: 0.715478003025] [mll=89.741+-4.438] [ks=7.713]\n",
      "71500 [D loss: 0.709147036076, acc.: 0.00%] [G loss: 0.707494318485] [mll=89.100+-5.112] [ks=7.697]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "71600 [D loss: 0.703895807266, acc.: 0.00%] [G loss: 0.723565042019] [mll=88.974+-5.459] [ks=7.752]\n",
      "71700 [D loss: 0.704107880592, acc.: 0.00%] [G loss: 0.709724009037] [mll=89.079+-5.679] [ks=7.758]\n",
      "71800 [D loss: 0.716454029083, acc.: 0.00%] [G loss: 0.732868254185] [mll=89.875+-5.212] [ks=7.802]\n",
      "71900 [D loss: 0.705545306206, acc.: 0.00%] [G loss: 0.715630471706] [mll=89.867+-5.492] [ks=7.677]\n",
      "72000 [D loss: 0.706298351288, acc.: 0.00%] [G loss: 0.711391866207] [mll=89.434+-5.802] [ks=7.776]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "72100 [D loss: 0.701997280121, acc.: 0.00%] [G loss: 0.708989560604] [mll=89.837+-6.000] [ks=7.609]\n",
      "72200 [D loss: 0.703994989395, acc.: 0.00%] [G loss: 0.712951242924] [mll=89.021+-5.252] [ks=7.744]\n",
      "72300 [D loss: 0.702563166618, acc.: 0.00%] [G loss: 0.708590447903] [mll=88.949+-5.068] [ks=7.656]\n",
      "72400 [D loss: 0.710113167763, acc.: 0.00%] [G loss: 0.72800219059] [mll=89.460+-5.457] [ks=7.962]]\n",
      "72500 [D loss: 0.70228511095, acc.: 0.00%] [G loss: 0.712178826332] [mll=89.147+-4.574] [ks=8.122]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "72600 [D loss: 0.681241035461, acc.: 0.00%] [G loss: 0.719500124454] [mll=89.559+-5.403] [ks=7.666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72700 [D loss: 0.704243004322, acc.: 0.00%] [G loss: 0.712108254433] [mll=90.323+-5.457] [ks=8.556]\n",
      "72800 [D loss: 0.70247733593, acc.: 0.00%] [G loss: 0.707532465458] [mll=89.606+-5.236] [ks=7.937]]\n",
      "72900 [D loss: 0.702480316162, acc.: 0.00%] [G loss: 0.712733864784] [mll=89.049+-5.750] [ks=7.794]\n",
      "73000 [D loss: 0.250903576612, acc.: 0.00%] [G loss: 9.88554477692] [mll=89.050+-5.651] [ks=8.000]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "73100 [D loss: 0.168765172362, acc.: 0.20%] [G loss: 9.03270816803] [mll=51.332+-20.729] [ks=11.780]\n",
      "73200 [D loss: 0.247175902128, acc.: 0.78%] [G loss: 12.2832784653] [mll=55.435+-27.817] [ks=10.166]]\n",
      "73300 [D loss: 0.204022735357, acc.: 0.59%] [G loss: 11.269156456] [mll=49.532+-27.090] [ks=10.477]]]\n",
      "73400 [D loss: 0.234982460737, acc.: 0.00%] [G loss: 11.2191305161] [mll=46.419+-21.044] [ks=11.480]]\n",
      "73500 [D loss: 0.389150738716, acc.: 0.00%] [G loss: 6.17132377625] [mll=73.886+-23.038] [ks=9.920]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "73600 [D loss: 0.329301416874, acc.: 0.39%] [G loss: 5.82255220413] [mll=64.791+-20.879] [ks=10.133]\n",
      "73700 [D loss: 0.160894498229, acc.: 0.78%] [G loss: 9.22633743286] [mll=62.975+-20.689] [ks=10.387]\n",
      "73800 [D loss: 0.313303619623, acc.: 0.00%] [G loss: 5.24355268478] [mll=56.795+-20.432] [ks=10.594]]\n",
      "73900 [D loss: 0.56501185894, acc.: 1.17%] [G loss: 3.66266036034] [mll=75.658+-25.400] [ks=9.353]]\n",
      "74000 [D loss: 0.172516688704, acc.: 0.00%] [G loss: 8.80350208282] [mll=66.796+-21.542] [ks=9.988]]\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "74100 [D loss: 0.615306854248, acc.: 0.00%] [G loss: 0.998325943947] [mll=63.024+-23.493] [ks=10.030]\n",
      "74200 [D loss: 0.700166225433, acc.: 0.39%] [G loss: 0.848610818386] [mll=93.282+-9.742] [ks=8.317]\n",
      "74300 [D loss: 0.737179875374, acc.: 0.39%] [G loss: 0.854085087776] [mll=90.447+-11.127] [ks=7.930]\n",
      "74400 [D loss: 0.693169414997, acc.: 0.00%] [G loss: 0.770411908627] [mll=93.439+-16.310] [ks=7.882]\n",
      "74500 [D loss: 0.696772813797, acc.: 0.00%] [G loss: 0.754206299782] [mll=90.941+-7.684] [ks=8.179]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "74600 [D loss: 0.72353053093, acc.: 0.59%] [G loss: 0.848090052605] [mll=89.853+-6.146] [ks=7.954]]\n",
      "74700 [D loss: 0.699105858803, acc.: 0.00%] [G loss: 0.751872122288] [mll=99.111+-18.054] [ks=8.144]\n",
      "74800 [D loss: 0.706966400146, acc.: 0.00%] [G loss: 0.738258957863] [mll=89.538+-6.525] [ks=7.903]\n",
      "74900 [D loss: 0.704947173595, acc.: 0.00%] [G loss: 0.745535314083] [mll=89.770+-6.529] [ks=7.980]\n",
      "75000 [D loss: 0.701338291168, acc.: 0.00%] [G loss: 0.725812911987] [mll=90.653+-8.477] [ks=7.794]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "75100 [D loss: 0.716595113277, acc.: 0.00%] [G loss: 0.76081931591] [mll=89.333+-6.561] [ks=7.727]]\n",
      "75200 [D loss: 0.702652812004, acc.: 0.00%] [G loss: 0.726491570473] [mll=89.745+-7.789] [ks=8.691]\n",
      "75300 [D loss: 0.700714111328, acc.: 0.00%] [G loss: 0.721371233463] [mll=89.822+-5.610] [ks=7.659]\n",
      "75400 [D loss: 0.769871234894, acc.: 0.00%] [G loss: 0.724511563778] [mll=89.876+-5.434] [ks=7.615]\n",
      "75500 [D loss: 0.711230158806, acc.: 0.00%] [G loss: 0.768210947514] [mll=87.313+-6.687] [ks=8.282]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "75600 [D loss: 0.701235294342, acc.: 0.00%] [G loss: 0.719437599182] [mll=87.548+-6.644] [ks=8.308]\n",
      "75700 [D loss: 0.705442786217, acc.: 0.00%] [G loss: 0.712776303291] [mll=89.977+-5.488] [ks=7.690]\n",
      "75800 [D loss: 0.775451242924, acc.: 0.00%] [G loss: 0.716048955917] [mll=89.415+-5.362] [ks=7.707]\n",
      "75900 [D loss: 0.708103060722, acc.: 0.00%] [G loss: 0.711830556393] [mll=89.486+-5.636] [ks=7.699]\n",
      "76000 [D loss: 0.717418193817, acc.: 0.00%] [G loss: 0.718081057072] [mll=89.702+-5.539] [ks=7.686]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "76100 [D loss: 0.721652746201, acc.: 0.00%] [G loss: 0.718340754509] [mll=90.292+-5.934] [ks=7.852]\n",
      "76200 [D loss: 0.709214091301, acc.: 0.00%] [G loss: 0.710446238518] [mll=88.046+-5.471] [ks=8.444]\n",
      "76300 [D loss: 0.692846655846, acc.: 0.00%] [G loss: 0.723562777042] [mll=89.069+-5.354] [ks=7.965]\n",
      "76400 [D loss: 0.703166723251, acc.: 0.00%] [G loss: 0.716597497463] [mll=89.304+-5.541] [ks=8.363]\n",
      "76500 [D loss: 0.7094835639, acc.: 0.00%] [G loss: 0.716387331486] [mll=89.956+-5.649] [ks=7.685]5]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "76600 [D loss: 0.695168673992, acc.: 0.00%] [G loss: 0.720761835575] [mll=89.387+-6.252] [ks=7.614]\n",
      "76700 [D loss: 0.638918757439, acc.: 0.00%] [G loss: 0.748241424561] [mll=88.821+-5.328] [ks=7.833]\n",
      "76800 [D loss: 0.702762782574, acc.: 0.00%] [G loss: 0.717207789421] [mll=86.949+-7.289] [ks=9.279]\n",
      "76900 [D loss: 0.702457904816, acc.: 0.00%] [G loss: 0.720814228058] [mll=89.447+-5.548] [ks=7.681]\n",
      "77000 [D loss: 0.693708896637, acc.: 0.00%] [G loss: 0.714078187943] [mll=89.751+-5.579] [ks=7.821]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "77100 [D loss: 0.760308921337, acc.: 0.00%] [G loss: 0.713516771793] [mll=90.150+-5.365] [ks=7.911]\n",
      "77200 [D loss: 0.699802160263, acc.: 0.00%] [G loss: 0.720371127129] [mll=90.164+-5.932] [ks=7.735]\n",
      "77300 [D loss: 0.698045134544, acc.: 0.00%] [G loss: 0.709379255772] [mll=89.407+-6.061] [ks=8.073]\n",
      "77400 [D loss: 0.7021920681, acc.: 0.00%] [G loss: 0.712293744087] [mll=88.275+-5.969] [ks=7.803]3]\n",
      "77500 [D loss: 0.699651002884, acc.: 0.00%] [G loss: 0.709257483482] [mll=89.811+-5.260] [ks=7.710]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "77600 [D loss: 0.679091334343, acc.: 0.00%] [G loss: 0.719058454037] [mll=88.762+-5.415] [ks=7.904]\n",
      "77700 [D loss: 0.699149549007, acc.: 0.00%] [G loss: 0.712988913059] [mll=88.687+-5.067] [ks=8.561]\n",
      "77800 [D loss: 0.669781804085, acc.: 0.00%] [G loss: 0.713144898415] [mll=89.592+-5.237] [ks=7.669]\n",
      "77900 [D loss: 0.710846066475, acc.: 0.00%] [G loss: 0.730584740639] [mll=88.534+-5.873] [ks=8.305]\n",
      "78000 [D loss: 0.697525441647, acc.: 0.00%] [G loss: 0.723836421967] [mll=92.318+-9.488] [ks=7.876]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "78100 [D loss: 0.702985882759, acc.: 0.00%] [G loss: 0.707971811295] [mll=88.697+-6.244] [ks=7.793]\n",
      "78200 [D loss: 0.702800869942, acc.: 0.00%] [G loss: 0.709668755531] [mll=90.280+-6.370] [ks=7.793]\n",
      "78300 [D loss: 0.67586928606, acc.: 0.00%] [G loss: 0.722386598587] [mll=89.371+-4.938] [ks=7.681]]\n",
      "78400 [D loss: 0.698897242546, acc.: 0.00%] [G loss: 0.717498242855] [mll=88.509+-6.584] [ks=8.491]\n",
      "78500 [D loss: 0.690537154675, acc.: 0.00%] [G loss: 0.69914907217] [mll=89.359+-6.336] [ks=7.540]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "78600 [D loss: 0.70851868391, acc.: 0.00%] [G loss: 0.714720785618] [mll=90.068+-5.440] [ks=7.973]]\n",
      "78700 [D loss: 0.698917388916, acc.: 0.00%] [G loss: 0.726051688194] [mll=89.095+-6.159] [ks=7.708]\n",
      "78800 [D loss: 0.702391028404, acc.: 0.00%] [G loss: 0.714137494564] [mll=89.130+-5.759] [ks=8.140]\n",
      "78900 [D loss: 0.694419741631, acc.: 0.00%] [G loss: 0.710494875908] [mll=89.146+-5.921] [ks=7.735]\n",
      "79000 [D loss: 0.697597563267, acc.: 0.00%] [G loss: 0.733119904995] [mll=89.991+-5.912] [ks=7.775]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "79100 [D loss: 0.707151830196, acc.: 0.00%] [G loss: 0.720372080803] [mll=88.950+-6.532] [ks=7.807]\n",
      "79200 [D loss: 0.704373478889, acc.: 0.00%] [G loss: 0.7074021101] [mll=89.785+-5.489] [ks=7.864]]]\n",
      "79300 [D loss: 0.719858646393, acc.: 0.00%] [G loss: 0.749862253666] [mll=89.127+-6.038] [ks=8.024]\n",
      "79400 [D loss: 0.70164167881, acc.: 0.00%] [G loss: 0.711271226406] [mll=82.818+-8.910] [ks=8.675]]\n",
      "79500 [D loss: 0.704563140869, acc.: 0.00%] [G loss: 0.708258092403] [mll=89.451+-5.154] [ks=7.719]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "79600 [D loss: 0.705575704575, acc.: 0.00%] [G loss: 0.706119298935] [mll=89.675+-5.442] [ks=7.624]\n",
      "79700 [D loss: 0.702332019806, acc.: 0.00%] [G loss: 0.729450643063] [mll=89.211+-6.005] [ks=7.646]\n",
      "79800 [D loss: 0.703098058701, acc.: 0.00%] [G loss: 0.715947270393] [mll=88.537+-7.100] [ks=8.158]\n",
      "79900 [D loss: 0.706711053848, acc.: 0.00%] [G loss: 0.709201395512] [mll=88.736+-7.633] [ks=7.658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 [D loss: 0.697426795959, acc.: 0.00%] [G loss: 0.711190104485] [mll=88.582+-5.771] [ks=8.255]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "80100 [D loss: 0.691951155663, acc.: 0.00%] [G loss: 0.732413172722] [mll=89.337+-5.262] [ks=7.712]\n",
      "80200 [D loss: 0.708259642124, acc.: 0.00%] [G loss: 0.708947181702] [mll=88.021+-6.085] [ks=8.797]\n",
      "80300 [D loss: 0.704938292503, acc.: 0.00%] [G loss: 0.705104887486] [mll=89.252+-6.079] [ks=7.795]\n",
      "80400 [D loss: 0.701068401337, acc.: 0.00%] [G loss: 0.72085249424] [mll=88.590+-5.715] [ks=7.891]]\n",
      "80500 [D loss: 0.702781617641, acc.: 0.00%] [G loss: 0.710227429867] [mll=89.924+-6.302] [ks=7.593]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "80600 [D loss: 0.700994729996, acc.: 0.00%] [G loss: 0.708141386509] [mll=89.956+-5.549] [ks=7.667]\n",
      "80700 [D loss: 0.715293526649, acc.: 0.00%] [G loss: 0.708096981049] [mll=89.873+-5.746] [ks=7.605]\n",
      "80800 [D loss: 0.702805161476, acc.: 0.00%] [G loss: 0.713018834591] [mll=89.596+-5.125] [ks=7.765]\n",
      "80900 [D loss: 0.674700438976, acc.: 0.00%] [G loss: 0.713790953159] [mll=89.692+-5.070] [ks=7.850]\n",
      "81000 [D loss: 0.699271798134, acc.: 0.00%] [G loss: 0.711352229118] [mll=88.373+-5.160] [ks=8.525]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "81100 [D loss: 0.706849575043, acc.: 0.00%] [G loss: 0.713586211205] [mll=89.545+-5.814] [ks=7.671]\n",
      "81200 [D loss: 0.700465857983, acc.: 0.00%] [G loss: 0.714568078518] [mll=90.164+-5.311] [ks=7.802]\n",
      "81300 [D loss: 0.703020334244, acc.: 0.00%] [G loss: 0.706718027592] [mll=89.328+-6.453] [ks=7.889]\n",
      "81400 [D loss: 0.702116966248, acc.: 0.00%] [G loss: 0.713060319424] [mll=89.156+-5.831] [ks=7.740]\n",
      "81500 [D loss: 0.701323986053, acc.: 0.00%] [G loss: 0.710510671139] [mll=89.974+-6.408] [ks=7.770]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "81600 [D loss: 0.703344523907, acc.: 0.00%] [G loss: 0.717030405998] [mll=89.240+-5.583] [ks=7.768]\n",
      "81700 [D loss: 0.697997808456, acc.: 0.00%] [G loss: 0.725852429867] [mll=90.028+-5.691] [ks=7.725]\n",
      "81800 [D loss: 0.701415777206, acc.: 0.00%] [G loss: 0.709256410599] [mll=88.868+-5.083] [ks=8.280]\n",
      "81900 [D loss: 0.696582376957, acc.: 0.00%] [G loss: 0.76338917017] [mll=89.978+-5.582] [ks=7.677]]\n",
      "82000 [D loss: 0.701913893223, acc.: 0.00%] [G loss: 0.743175566196] [mll=80.821+-7.869] [ks=10.404]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "82100 [D loss: 0.705042004585, acc.: 0.00%] [G loss: 0.717344641685] [mll=89.951+-5.889] [ks=7.675]\n",
      "82200 [D loss: 0.705188810825, acc.: 0.00%] [G loss: 0.713262319565] [mll=89.989+-5.364] [ks=7.822]\n",
      "82300 [D loss: 0.702481031418, acc.: 0.00%] [G loss: 0.713173806667] [mll=88.539+-5.820] [ks=7.934]\n",
      "82400 [D loss: 0.696657061577, acc.: 0.00%] [G loss: 0.710637688637] [mll=89.296+-5.991] [ks=7.867]\n",
      "82500 [D loss: 0.702976703644, acc.: 0.00%] [G loss: 0.70701110363] [mll=89.225+-6.112] [ks=7.611]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "82600 [D loss: 0.701898694038, acc.: 0.00%] [G loss: 0.711316525936] [mll=88.665+-6.462] [ks=8.119]\n",
      "82700 [D loss: 0.711652874947, acc.: 0.00%] [G loss: 0.70578199625] [mll=89.568+-5.659] [ks=7.779]]\n",
      "82800 [D loss: 0.762632548809, acc.: 0.00%] [G loss: 0.702640771866] [mll=88.873+-6.097] [ks=7.693]\n",
      "82900 [D loss: 0.70140004158, acc.: 0.00%] [G loss: 0.712087571621] [mll=89.386+-5.250] [ks=8.043]]\n",
      "83000 [D loss: 0.702367603779, acc.: 0.00%] [G loss: 0.708531141281] [mll=89.518+-4.740] [ks=7.864]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "83100 [D loss: 0.699023604393, acc.: 0.00%] [G loss: 0.705438554287] [mll=89.286+-5.107] [ks=7.796]\n",
      "83200 [D loss: 0.701694250107, acc.: 0.00%] [G loss: 0.714136362076] [mll=89.408+-5.317] [ks=7.684]\n",
      "83300 [D loss: 0.696323156357, acc.: 0.00%] [G loss: 0.720581412315] [mll=89.700+-6.068] [ks=7.691]\n",
      "83400 [D loss: 0.701713085175, acc.: 0.00%] [G loss: 0.710102200508] [mll=90.042+-9.183] [ks=8.783]\n",
      "83500 [D loss: 0.706253170967, acc.: 0.00%] [G loss: 0.707950055599] [mll=89.801+-4.608] [ks=7.930]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "83600 [D loss: 0.714134693146, acc.: 0.00%] [G loss: 0.724654555321] [mll=89.917+-4.608] [ks=7.811]\n",
      "83700 [D loss: 0.701131165028, acc.: 0.00%] [G loss: 0.713304579258] [mll=88.908+-5.796] [ks=8.141]\n",
      "83800 [D loss: 0.734670758247, acc.: 0.00%] [G loss: 0.727388739586] [mll=89.011+-5.279] [ks=7.926]\n",
      "83900 [D loss: 0.701934397221, acc.: 0.00%] [G loss: 0.711094617844] [mll=88.838+-5.615] [ks=8.229]\n",
      "84000 [D loss: 0.700777471066, acc.: 0.00%] [G loss: 0.708347558975] [mll=89.426+-4.926] [ks=7.752]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "84100 [D loss: 0.703070998192, acc.: 0.00%] [G loss: 0.715029597282] [mll=89.308+-5.442] [ks=7.863]\n",
      "84200 [D loss: 0.701320767403, acc.: 0.00%] [G loss: 0.71013635397] [mll=89.711+-5.344] [ks=7.690]]\n",
      "84300 [D loss: 0.702245533466, acc.: 0.00%] [G loss: 0.712675571442] [mll=89.117+-5.966] [ks=7.823]\n",
      "84400 [D loss: 0.702266573906, acc.: 0.00%] [G loss: 0.713209092617] [mll=89.171+-5.325] [ks=7.853]\n",
      "84500 [D loss: 0.700931489468, acc.: 0.00%] [G loss: 0.709723472595] [mll=89.749+-5.563] [ks=7.705]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "84600 [D loss: 0.701661109924, acc.: 0.00%] [G loss: 0.706865251064] [mll=89.691+-5.299] [ks=7.767]\n",
      "84700 [D loss: 0.706705451012, acc.: 0.00%] [G loss: 0.703236997128] [mll=89.453+-5.597] [ks=7.650]\n",
      "84800 [D loss: 0.703322172165, acc.: 0.00%] [G loss: 0.705874085426] [mll=89.796+-5.121] [ks=7.830]\n",
      "84900 [D loss: 0.701053917408, acc.: 0.00%] [G loss: 0.715354442596] [mll=89.533+-6.354] [ks=7.754]\n",
      "85000 [D loss: 0.701516270638, acc.: 0.00%] [G loss: 0.711112558842] [mll=89.203+-6.607] [ks=7.880]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "85100 [D loss: 0.705258905888, acc.: 0.00%] [G loss: 0.71601241827] [mll=90.049+-5.235] [ks=7.617]]\n",
      "85200 [D loss: 0.702864170074, acc.: 0.00%] [G loss: 0.705903112888] [mll=88.991+-5.571] [ks=7.667]\n",
      "85300 [D loss: 0.701038956642, acc.: 0.00%] [G loss: 0.706446111202] [mll=89.331+-6.139] [ks=7.700]\n",
      "85400 [D loss: 0.702173352242, acc.: 0.00%] [G loss: 0.704724371433] [mll=90.151+-5.571] [ks=7.976]\n",
      "85500 [D loss: 0.703544020653, acc.: 0.00%] [G loss: 0.704475998878] [mll=89.263+-5.007] [ks=7.717]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "85600 [D loss: 0.701728403568, acc.: 0.00%] [G loss: 0.709180295467] [mll=89.252+-5.768] [ks=7.792]\n",
      "85700 [D loss: 0.701251029968, acc.: 0.00%] [G loss: 0.708184838295] [mll=91.374+-7.293] [ks=7.682]\n",
      "85800 [D loss: 0.701588988304, acc.: 0.00%] [G loss: 0.720221042633] [mll=89.744+-4.904] [ks=7.762]\n",
      "85900 [D loss: 0.703851938248, acc.: 0.00%] [G loss: 0.708087980747] [mll=89.444+-5.332] [ks=7.995]\n",
      "86000 [D loss: 0.680584669113, acc.: 0.00%] [G loss: 0.71487814188] [mll=90.744+-5.267] [ks=7.844]]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "86100 [D loss: 0.689827144146, acc.: 0.00%] [G loss: 0.747672617435] [mll=90.183+-5.896] [ks=8.311]\n",
      "86200 [D loss: 0.702024459839, acc.: 0.00%] [G loss: 0.716030538082] [mll=87.446+-7.519] [ks=9.128]\n",
      "86300 [D loss: 0.700651049614, acc.: 0.00%] [G loss: 0.703824102879] [mll=88.988+-5.879] [ks=7.627]\n",
      "86400 [D loss: 0.700773119926, acc.: 0.00%] [G loss: 0.707289099693] [mll=89.513+-4.935] [ks=7.596]\n",
      "86500 [D loss: 0.704316973686, acc.: 0.00%] [G loss: 0.710896253586] [mll=89.377+-5.245] [ks=7.861]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "86600 [D loss: 0.70489859581, acc.: 0.00%] [G loss: 0.711961627007] [mll=89.314+-5.180] [ks=7.779]]\n",
      "86700 [D loss: 0.745916545391, acc.: 0.00%] [G loss: 0.709953188896] [mll=90.073+-6.627] [ks=7.751]\n",
      "86800 [D loss: 0.694305539131, acc.: 0.00%] [G loss: 0.719039022923] [mll=87.963+-5.323] [ks=7.938]\n",
      "86900 [D loss: 0.701477944851, acc.: 0.00%] [G loss: 0.710795998573] [mll=88.816+-4.836] [ks=8.680]\n",
      "87000 [D loss: 0.701997220516, acc.: 0.00%] [G loss: 0.70811265707] [mll=89.324+-5.865] [ks=7.878]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "87100 [D loss: 0.692070245743, acc.: 0.00%] [G loss: 0.74626326561] [mll=89.081+-5.073] [ks=7.825]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87200 [D loss: 0.705232858658, acc.: 0.00%] [G loss: 0.712939679623] [mll=87.255+-5.993] [ks=8.251]\n",
      "87300 [D loss: 0.703021526337, acc.: 0.00%] [G loss: 0.712714076042] [mll=89.299+-5.260] [ks=7.761]\n",
      "87400 [D loss: 0.686623871326, acc.: 0.00%] [G loss: 0.718481481075] [mll=89.557+-5.821] [ks=7.743]\n",
      "87500 [D loss: 0.700491905212, acc.: 0.00%] [G loss: 0.718110561371] [mll=88.538+-5.433] [ks=8.338]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "87600 [D loss: 0.709492683411, acc.: 0.00%] [G loss: 0.727856576443] [mll=87.610+-6.424] [ks=8.097]\n",
      "87700 [D loss: 0.703225553036, acc.: 0.00%] [G loss: 0.716152608395] [mll=90.939+-5.625] [ks=7.961]\n",
      "87800 [D loss: 0.703035593033, acc.: 0.00%] [G loss: 0.714034557343] [mll=89.410+-5.067] [ks=7.615]\n",
      "87900 [D loss: 0.699833512306, acc.: 0.00%] [G loss: 0.710735678673] [mll=89.070+-5.222] [ks=7.854]\n",
      "88000 [D loss: 0.677470862865, acc.: 0.00%] [G loss: 0.732268750668] [mll=89.528+-5.945] [ks=7.717]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "88100 [D loss: 0.711413502693, acc.: 0.00%] [G loss: 0.711625635624] [mll=84.698+-6.542] [ks=9.495]\n",
      "88200 [D loss: 0.702296197414, acc.: 0.00%] [G loss: 0.784731328487] [mll=89.878+-5.867] [ks=7.673]\n",
      "88300 [D loss: 0.698976159096, acc.: 0.00%] [G loss: 0.706369817257] [mll=91.192+-5.354] [ks=8.190]\n",
      "88400 [D loss: 0.711063742638, acc.: 0.00%] [G loss: 0.707272648811] [mll=89.269+-5.278] [ks=7.974]\n",
      "88500 [D loss: 0.701459884644, acc.: 0.00%] [G loss: 0.707713544369] [mll=89.274+-5.405] [ks=7.979]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "88600 [D loss: 0.713386535645, acc.: 0.39%] [G loss: 0.71833884716] [mll=89.088+-5.670] [ks=7.957]]\n",
      "88700 [D loss: 0.714139819145, acc.: 0.00%] [G loss: 0.708938658237] [mll=92.785+-11.125] [ks=7.944]\n",
      "88800 [D loss: 0.700749158859, acc.: 0.00%] [G loss: 0.714678645134] [mll=89.774+-5.076] [ks=7.955]\n",
      "88900 [D loss: 0.702881217003, acc.: 0.00%] [G loss: 0.707995951176] [mll=89.828+-5.928] [ks=7.735]\n",
      "89000 [D loss: 0.707081794739, acc.: 0.00%] [G loss: 0.715329766273] [mll=89.382+-5.672] [ks=7.978]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "89100 [D loss: 0.704220533371, acc.: 0.00%] [G loss: 0.706208348274] [mll=90.413+-5.798] [ks=7.962]\n",
      "89200 [D loss: 0.674354791641, acc.: 0.00%] [G loss: 0.728304326534] [mll=89.581+-4.902] [ks=7.750]\n",
      "89300 [D loss: 0.704264163971, acc.: 0.00%] [G loss: 0.70991396904] [mll=89.501+-5.246] [ks=8.344]]\n",
      "89400 [D loss: 0.706181764603, acc.: 0.00%] [G loss: 0.724912881851] [mll=89.313+-5.709] [ks=7.637]\n",
      "89500 [D loss: 0.700055897236, acc.: 0.00%] [G loss: 0.712441205978] [mll=89.296+-5.988] [ks=8.010]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "89600 [D loss: 0.700467824936, acc.: 0.00%] [G loss: 0.711862027645] [mll=89.518+-5.607] [ks=7.738]\n",
      "89700 [D loss: 0.710177540779, acc.: 0.00%] [G loss: 0.749026715755] [mll=89.379+-5.274] [ks=7.914]\n",
      "89800 [D loss: 0.701046347618, acc.: 0.00%] [G loss: 0.716339528561] [mll=89.270+-5.504] [ks=7.905]\n",
      "89900 [D loss: 0.705308377743, acc.: 0.00%] [G loss: 0.72728073597] [mll=89.621+-5.268] [ks=7.869]]\n",
      "90000 [D loss: 0.705435752869, acc.: 0.00%] [G loss: 0.715414047241] [mll=90.199+-5.362] [ks=8.156]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "90100 [D loss: 0.704772114754, acc.: 0.00%] [G loss: 0.710590779781] [mll=89.381+-5.137] [ks=7.775]\n",
      "90200 [D loss: 0.702661752701, acc.: 0.00%] [G loss: 0.716201901436] [mll=88.856+-5.909] [ks=7.693]\n",
      "90300 [D loss: 0.707371354103, acc.: 0.00%] [G loss: 0.711280822754] [mll=89.902+-5.102] [ks=8.003]\n",
      "90400 [D loss: 0.699023246765, acc.: 0.00%] [G loss: 0.712600290775] [mll=89.119+-4.535] [ks=7.860]\n",
      "90500 [D loss: 0.710848927498, acc.: 0.00%] [G loss: 0.7087277174] [mll=89.831+-4.942] [ks=8.455]5]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "90600 [D loss: 0.704858481884, acc.: 0.00%] [G loss: 0.706111490726] [mll=89.683+-5.459] [ks=7.553]\n",
      "90700 [D loss: 0.702721476555, acc.: 0.00%] [G loss: 0.705966055393] [mll=89.196+-4.944] [ks=7.664]\n",
      "90800 [D loss: 0.702072024345, acc.: 0.00%] [G loss: 0.714223146439] [mll=89.157+-4.869] [ks=8.056]\n",
      "90900 [D loss: 0.704321920872, acc.: 0.00%] [G loss: 0.704739630222] [mll=89.276+-4.857] [ks=7.825]\n",
      "91000 [D loss: 0.708977222443, acc.: 0.00%] [G loss: 0.713554024696] [mll=89.035+-4.497] [ks=7.993]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "91100 [D loss: 0.70223146677, acc.: 0.00%] [G loss: 0.707512915134] [mll=89.765+-4.557] [ks=7.934]]\n",
      "91200 [D loss: 0.703942060471, acc.: 0.00%] [G loss: 0.727448046207] [mll=88.895+-5.495] [ks=7.893]\n",
      "91300 [D loss: 0.702292382717, acc.: 0.00%] [G loss: 0.709915220737] [mll=89.512+-5.816] [ks=7.762]\n",
      "91400 [D loss: 0.699640572071, acc.: 0.00%] [G loss: 0.702497363091] [mll=89.252+-4.980] [ks=7.884]\n",
      "91500 [D loss: 0.703137874603, acc.: 0.00%] [G loss: 0.70530217886] [mll=89.155+-5.688] [ks=8.057]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "91600 [D loss: 0.70528870821, acc.: 0.00%] [G loss: 0.704149782658] [mll=89.788+-5.011] [ks=7.609]]\n",
      "91700 [D loss: 0.702300906181, acc.: 0.00%] [G loss: 0.705983102322] [mll=88.988+-5.132] [ks=8.157]\n",
      "91800 [D loss: 0.7006701231, acc.: 0.00%] [G loss: 0.711941838264] [mll=89.200+-5.641] [ks=8.039]9]\n",
      "91900 [D loss: 0.702667415142, acc.: 0.00%] [G loss: 0.710169374943] [mll=90.251+-5.366] [ks=7.781]\n",
      "92000 [D loss: 0.73078751564, acc.: 0.00%] [G loss: 0.755003869534] [mll=90.648+-8.781] [ks=8.363]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "92100 [D loss: 0.717297613621, acc.: 0.00%] [G loss: 0.707559168339] [mll=89.421+-5.378] [ks=8.039]\n",
      "92200 [D loss: 0.702351689339, acc.: 0.00%] [G loss: 0.705663263798] [mll=88.937+-6.067] [ks=8.167]\n",
      "92300 [D loss: 0.704748272896, acc.: 0.00%] [G loss: 0.712473511696] [mll=89.222+-5.044] [ks=7.950]\n",
      "92400 [D loss: 0.709609627724, acc.: 0.00%] [G loss: 0.726870775223] [mll=89.180+-4.955] [ks=7.668]\n",
      "92500 [D loss: 0.702379703522, acc.: 0.00%] [G loss: 0.713111281395] [mll=88.964+-5.565] [ks=8.500]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "92600 [D loss: 1.42504119873, acc.: 0.00%] [G loss: 2.21251893044] [mll=89.463+-4.927] [ks=7.805]]]\n",
      "92700 [D loss: 0.703571617603, acc.: 0.00%] [G loss: 0.714402616024] [mll=72.888+-10.380] [ks=10.521]\n",
      "92800 [D loss: 0.715901434422, acc.: 0.00%] [G loss: 0.70710515976] [mll=91.423+-8.149] [ks=7.738]]\n",
      "92900 [D loss: 0.702236711979, acc.: 0.00%] [G loss: 0.711595654488] [mll=90.467+-7.280] [ks=7.776]\n",
      "93000 [D loss: 0.708646178246, acc.: 0.00%] [G loss: 0.727985441685] [mll=89.132+-5.356] [ks=7.835]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "93100 [D loss: 0.71164047718, acc.: 0.00%] [G loss: 0.706888258457] [mll=89.963+-7.152] [ks=7.976]]\n",
      "93200 [D loss: 0.670926094055, acc.: 0.00%] [G loss: 0.713828027248] [mll=88.704+-5.801] [ks=7.864]\n",
      "93300 [D loss: 0.703680038452, acc.: 0.00%] [G loss: 0.717764854431] [mll=89.643+-6.869] [ks=8.934]\n",
      "93400 [D loss: 0.713036060333, acc.: 0.00%] [G loss: 0.712048470974] [mll=89.491+-5.617] [ks=7.696]\n",
      "93500 [D loss: 0.685888290405, acc.: 0.00%] [G loss: 0.76739782095] [mll=89.379+-5.799] [ks=7.816]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "93600 [D loss: 0.704079151154, acc.: 0.00%] [G loss: 0.717657446861] [mll=84.490+-5.523] [ks=9.633]\n",
      "93700 [D loss: 0.700226068497, acc.: 0.00%] [G loss: 0.717651128769] [mll=89.110+-5.857] [ks=7.873]\n",
      "93800 [D loss: 0.7045327425, acc.: 0.00%] [G loss: 0.70758920908] [mll=89.419+-7.128] [ks=8.533]33]\n",
      "93900 [D loss: 0.703746080399, acc.: 0.00%] [G loss: 0.716747224331] [mll=89.056+-5.801] [ks=7.628]\n",
      "94000 [D loss: 0.701207756996, acc.: 0.00%] [G loss: 0.708377897739] [mll=89.489+-5.437] [ks=7.835]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "94100 [D loss: 0.702244818211, acc.: 0.00%] [G loss: 0.708967149258] [mll=89.137+-5.527] [ks=7.849]\n",
      "94200 [D loss: 0.704462766647, acc.: 0.00%] [G loss: 0.707801699638] [mll=89.351+-6.189] [ks=7.566]\n",
      "94300 [D loss: 0.701764762402, acc.: 0.00%] [G loss: 0.70710504055] [mll=93.742+-9.238] [ks=8.207]]\n",
      "94400 [D loss: 0.702193439007, acc.: 0.00%] [G loss: 0.709151268005] [mll=89.153+-4.988] [ks=7.894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94500 [D loss: 0.723951876163, acc.: 0.00%] [G loss: 0.707277834415] [mll=89.455+-5.860] [ks=8.031]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "94600 [D loss: 0.701559305191, acc.: 0.00%] [G loss: 0.707330167294] [mll=87.903+-5.437] [ks=8.073]\n",
      "94700 [D loss: 0.716291904449, acc.: 0.00%] [G loss: 0.705641627312] [mll=89.734+-4.948] [ks=8.074]\n",
      "94800 [D loss: 0.701224148273, acc.: 0.00%] [G loss: 0.704590380192] [mll=90.653+-5.745] [ks=7.934]\n",
      "94900 [D loss: 0.706151247025, acc.: 0.00%] [G loss: 0.716583371162] [mll=89.139+-4.534] [ks=8.037]\n",
      "95000 [D loss: 0.705153226852, acc.: 0.00%] [G loss: 0.708305418491] [mll=87.025+-5.830] [ks=8.643]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "95100 [D loss: 0.703454256058, acc.: 0.00%] [G loss: 0.704390406609] [mll=89.340+-5.475] [ks=7.581]\n",
      "95200 [D loss: 0.703149795532, acc.: 0.00%] [G loss: 0.707818031311] [mll=91.120+-7.321] [ks=7.834]\n",
      "95300 [D loss: 0.72847878933, acc.: 0.00%] [G loss: 0.704388082027] [mll=89.795+-4.105] [ks=7.921]]\n",
      "95400 [D loss: 0.700123310089, acc.: 0.00%] [G loss: 0.705383658409] [mll=89.744+-4.410] [ks=7.897]\n",
      "95500 [D loss: 0.701717972755, acc.: 0.00%] [G loss: 0.709553956985] [mll=88.935+-5.008] [ks=8.746]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "95600 [D loss: 0.706172227859, acc.: 0.00%] [G loss: 0.711578905582] [mll=89.629+-5.181] [ks=7.773]\n",
      "95700 [D loss: 0.688004672527, acc.: 0.00%] [G loss: 0.722736418247] [mll=90.252+-5.176] [ks=7.807]\n",
      "95800 [D loss: 0.706563830376, acc.: 0.00%] [G loss: 0.714129924774] [mll=91.370+-8.433] [ks=8.641]\n",
      "95900 [D loss: 0.704398036003, acc.: 0.00%] [G loss: 0.71439909935] [mll=89.621+-5.719] [ks=7.639]]\n",
      "96000 [D loss: 0.703725814819, acc.: 0.00%] [G loss: 0.709231436253] [mll=89.676+-5.363] [ks=7.919]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "96100 [D loss: 0.706892073154, acc.: 0.00%] [G loss: 0.709279000759] [mll=89.062+-5.453] [ks=8.123]\n",
      "96200 [D loss: 0.70354372263, acc.: 0.00%] [G loss: 0.705902159214] [mll=89.818+-5.741] [ks=7.689]]\n",
      "96300 [D loss: 0.713076710701, acc.: 0.00%] [G loss: 0.754165768623] [mll=88.644+-5.950] [ks=8.150]\n",
      "96400 [D loss: 0.71081417799, acc.: 0.00%] [G loss: 0.711200833321] [mll=84.295+-6.229] [ks=9.171]]\n",
      "96500 [D loss: 0.707521140575, acc.: 0.00%] [G loss: 0.711511671543] [mll=89.353+-5.318] [ks=7.763]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "96600 [D loss: 0.707404732704, acc.: 0.00%] [G loss: 0.711248636246] [mll=88.832+-5.614] [ks=8.085]\n",
      "96700 [D loss: 0.706485688686, acc.: 0.00%] [G loss: 0.707382559776] [mll=89.456+-5.269] [ks=7.723]\n",
      "96800 [D loss: 0.70300579071, acc.: 0.00%] [G loss: 0.721557855606] [mll=89.327+-5.262] [ks=8.026]]\n",
      "96900 [D loss: 0.705496191978, acc.: 0.00%] [G loss: 0.713549375534] [mll=88.576+-6.216] [ks=8.154]\n",
      "97000 [D loss: 0.665184736252, acc.: 0.00%] [G loss: 0.728891313076] [mll=89.550+-5.258] [ks=7.728]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "97100 [D loss: 0.705149292946, acc.: 0.00%] [G loss: 0.711714208126] [mll=89.684+-5.083] [ks=8.530]\n",
      "97200 [D loss: 0.699939608574, acc.: 0.00%] [G loss: 0.706303119659] [mll=89.922+-4.867] [ks=7.930]\n",
      "97300 [D loss: 0.719786465168, acc.: 0.00%] [G loss: 0.707744657993] [mll=89.766+-5.555] [ks=8.213]\n",
      "97400 [D loss: 0.706230640411, acc.: 0.00%] [G loss: 0.716686308384] [mll=88.300+-5.354] [ks=8.084]\n",
      "97500 [D loss: 0.703042566776, acc.: 0.00%] [G loss: 0.709255635738] [mll=88.797+-6.090] [ks=8.051]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "97600 [D loss: 0.702798783779, acc.: 0.00%] [G loss: 0.700814783573] [mll=89.295+-4.990] [ks=8.135]\n",
      "97700 [D loss: 0.706486463547, acc.: 0.00%] [G loss: 0.723471283913] [mll=88.997+-5.324] [ks=8.602]\n",
      "97800 [D loss: 0.702768802643, acc.: 0.00%] [G loss: 0.711793363094] [mll=90.127+-4.680] [ks=7.901]\n",
      "97900 [D loss: 0.712752938271, acc.: 0.00%] [G loss: 0.704185724258] [mll=89.768+-4.594] [ks=7.714]\n",
      "98000 [D loss: 0.707011461258, acc.: 0.00%] [G loss: 0.704661786556] [mll=88.385+-5.916] [ks=8.018]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "98100 [D loss: 0.697531342506, acc.: 0.00%] [G loss: 0.731278419495] [mll=89.545+-4.192] [ks=7.782]\n",
      "98200 [D loss: 0.703299224377, acc.: 0.00%] [G loss: 0.713317453861] [mll=89.352+-6.261] [ks=8.150]\n",
      "98300 [D loss: 0.704359173775, acc.: 0.00%] [G loss: 0.704657077789] [mll=92.802+-10.300] [ks=7.754]\n",
      "98400 [D loss: 0.700168907642, acc.: 0.00%] [G loss: 0.707671880722] [mll=90.394+-5.196] [ks=8.088]\n",
      "98500 [D loss: 0.687424302101, acc.: 0.00%] [G loss: 0.784655213356] [mll=89.387+-4.546] [ks=8.243]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "98600 [D loss: 0.702754259109, acc.: 0.00%] [G loss: 0.721348404884] [mll=86.357+-6.259] [ks=8.986]\n",
      "98700 [D loss: 0.704182386398, acc.: 0.00%] [G loss: 0.708230853081] [mll=89.543+-6.089] [ks=7.739]\n",
      "98800 [D loss: 0.709358692169, acc.: 0.00%] [G loss: 0.713621377945] [mll=89.282+-4.539] [ks=7.850]\n",
      "98900 [D loss: 0.700340032578, acc.: 0.00%] [G loss: 0.710512876511] [mll=89.428+-5.614] [ks=7.862]\n",
      "99000 [D loss: 0.708104491234, acc.: 0.00%] [G loss: 0.705357789993] [mll=89.711+-4.666] [ks=7.664]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "99100 [D loss: 0.706285893917, acc.: 0.00%] [G loss: 0.706581056118] [mll=90.082+-5.071] [ks=8.098]\n",
      "99200 [D loss: 0.706069231033, acc.: 0.00%] [G loss: 0.711763799191] [mll=88.716+-5.368] [ks=8.150]\n",
      "99300 [D loss: 0.705842196941, acc.: 0.00%] [G loss: 0.710315585136] [mll=90.577+-11.520] [ks=7.925]\n",
      "99400 [D loss: 0.722069740295, acc.: 0.00%] [G loss: 0.70739543438] [mll=86.988+-7.315] [ks=8.065]]\n",
      "99500 [D loss: 0.649256229401, acc.: 0.00%] [G loss: 0.770820558071] [mll=88.070+-5.990] [ks=7.859]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "99600 [D loss: 0.877758264542, acc.: 0.00%] [G loss: 0.727513313293] [mll=88.893+-5.295] [ks=8.531]\n",
      "99700 [D loss: 0.719608545303, acc.: 0.00%] [G loss: 0.723282754421] [mll=88.993+-5.030] [ks=8.070]\n",
      "99800 [D loss: 0.705915927887, acc.: 0.00%] [G loss: 0.707946777344] [mll=88.974+-4.889] [ks=8.130]\n",
      "99900 [D loss: 0.706222057343, acc.: 0.00%] [G loss: 0.714674890041] [mll=86.796+-7.322] [ks=7.993]\n",
      "100000 [D loss: 0.703503668308, acc.: 0.00%] [G loss: 0.707549214363] [mll=96.565+-11.834] [ks=8.360]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "Scaling jet pts\n",
      "Scaling lep isos\n",
      "Discriminator params: 161537\n",
      "Generator params: 340497\n",
      "scaling lepton isolations\n",
      "scaling jet pts\n",
      "100 [D loss: 0.42129445076, acc.: 0.00%] [G loss: 3.31208181381] [mll=-1.000+--1.000] [ks=999.000]]\n",
      "KS score improved from 999.00 to 15.48, saving models to progress/jetisoscale_mllwidth_flatNegNoise_3/gen_100.weights\n",
      "200 [D loss: 0.261315524578, acc.: 0.00%] [G loss: 4.65033912659] [mll=7.434+-0.813] [ks=15.475]\n",
      "300 [D loss: 0.290753781796, acc.: 0.00%] [G loss: 8.38613033295] [mll=28.488+-3.172] [ks=15.500]]\n",
      "KS score improved from 15.48 to 14.59, saving models to progress/jetisoscale_mllwidth_flatNegNoise_3/gen_300.weights\n",
      "400 [D loss: 0.0704249367118, acc.: 0.00%] [G loss: 5.58054924011] [mll=46.737+-4.922] [ks=14.588]\n",
      "KS score improved from 14.59 to 14.40, saving models to progress/jetisoscale_mllwidth_flatNegNoise_3/gen_400.weights\n",
      "500 [D loss: 0.121441364288, acc.: 0.00%] [G loss: 5.59239959717] [mll=64.708+-6.516] [ks=14.403]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "KS score improved from 14.40 to 14.21, saving models to progress/jetisoscale_mllwidth_flatNegNoise_3/gen_500.weights\n",
      "600 [D loss: 0.145675271749, acc.: 0.00%] [G loss: 2.97129297256] [mll=55.720+-5.455] [ks=14.209]]\n",
      "KS score improved from 14.21 to 14.03, saving models to progress/jetisoscale_mllwidth_flatNegNoise_3/gen_600.weights\n",
      "700 [D loss: 0.246285527945, acc.: 0.00%] [G loss: 4.19943666458] [mll=73.818+-6.786] [ks=14.029]]\n",
      "800 [D loss: 0.366760343313, acc.: 0.00%] [G loss: 4.50546121597] [mll=44.776+-3.588] [ks=15.003]]\n",
      "KS score improved from 14.03 to 12.98, saving models to progress/jetisoscale_mllwidth_flatNegNoise_3/gen_800.weights\n",
      "900 [D loss: 0.0765544101596, acc.: 0.00%] [G loss: 4.43025922775] [mll=78.067+-6.563] [ks=12.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [D loss: 0.0466299168766, acc.: 0.00%] [G loss: 5.43813276291] [mll=60.238+-3.869] [ks=13.564]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "1100 [D loss: 0.112516887486, acc.: 0.00%] [G loss: 4.86867713928] [mll=82.828+-7.618] [ks=14.030]]\n",
      "1200 [D loss: 0.162538260221, acc.: 0.00%] [G loss: 5.07642793655] [mll=64.503+-4.781] [ks=14.815]]\n",
      "1300 [D loss: 0.129095375538, acc.: 0.00%] [G loss: 4.35857439041] [mll=50.397+-3.208] [ks=15.125]]\n",
      "1400 [D loss: 0.18922111392, acc.: 0.00%] [G loss: 3.71271562576] [mll=97.091+-10.031] [ks=14.998]]]\n",
      "1500 [D loss: 1.03896737099, acc.: 41.41%] [G loss: 4.1997179985] [mll=52.515+-2.985] [ks=15.275]5]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "1600 [D loss: 0.0936832129955, acc.: 0.00%] [G loss: 4.15477323532] [mll=4.875+-1.979] [ks=14.427]\n",
      "1700 [D loss: 0.127380892634, acc.: 0.00%] [G loss: 7.45177745819] [mll=83.831+-7.047] [ks=14.694]]\n",
      "1800 [D loss: 7.97737932205, acc.: 0.00%] [G loss: 0.00377620919608] [mll=54.065+-3.610] [ks=15.347]\n",
      "1900 [D loss: 7.98095655441, acc.: 0.00%] [G loss: 0.0100350258872] [mll=89.158+-5.963] [ks=13.875]]\n",
      "2000 [D loss: 7.98641252518, acc.: 0.00%] [G loss: 0.00701362965629] [mll=96.546+-5.383] [ks=14.280]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "2100 [D loss: 7.98440551758, acc.: 0.00%] [G loss: 0.0052740201354] [mll=95.563+-4.511] [ks=14.265]]\n",
      "2200 [D loss: 7.97864866257, acc.: 0.00%] [G loss: 0.00578168593347] [mll=93.854+-4.029] [ks=14.108]\n",
      "2300 [D loss: 7.98966836929, acc.: 0.00%] [G loss: 0.00534407002851] [mll=94.607+-3.980] [ks=14.127]\n",
      "2400 [D loss: 7.98221826553, acc.: 0.00%] [G loss: 0.00505400635302] [mll=94.039+-3.946] [ks=14.037]\n",
      "2500 [D loss: 7.97994232178, acc.: 0.00%] [G loss: 0.00478797825053] [mll=93.549+-3.939] [ks=13.982]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "2600 [D loss: 7.98257493973, acc.: 0.00%] [G loss: 0.00349931465462] [mll=93.324+-3.954] [ks=13.945]\n",
      "2700 [D loss: 7.9797000885, acc.: 0.00%] [G loss: 0.00338578573428] [mll=91.719+-3.913] [ks=13.796]]\n",
      "2800 [D loss: 8.05947113037, acc.: 0.00%] [G loss: 0.00454830331728] [mll=91.938+-4.008] [ks=13.804]\n",
      "2900 [D loss: 7.97925758362, acc.: 0.00%] [G loss: 0.00425819121301] [mll=93.292+-4.013] [ks=13.917]\n",
      "3000 [D loss: 7.976313591, acc.: 0.00%] [G loss: 0.00401275185868] [mll=85.880+-3.576] [ks=14.157]]]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "3100 [D loss: 7.97795772552, acc.: 0.00%] [G loss: 0.00300122960471] [mll=86.393+-3.606] [ks=14.113]\n",
      "3200 [D loss: 7.97578239441, acc.: 0.00%] [G loss: 0.00336552434601] [mll=89.835+-3.857] [ks=13.761]\n",
      "3300 [D loss: 7.97817182541, acc.: 0.00%] [G loss: 0.00327382958494] [mll=88.073+-3.738] [ks=13.949]\n",
      "3400 [D loss: 7.97671079636, acc.: 0.00%] [G loss: 0.0029925769195] [mll=87.751+-3.730] [ks=13.979]]\n",
      "3500 [D loss: 7.97524738312, acc.: 0.00%] [G loss: 0.00306597887538] [mll=89.409+-3.843] [ks=13.803]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "3600 [D loss: 7.98996400833, acc.: 0.00%] [G loss: 0.00313118821941] [mll=88.603+-3.844] [ks=13.891]\n",
      "3700 [D loss: 7.97757434845, acc.: 0.00%] [G loss: 0.00312379095703] [mll=88.625+-3.786] [ks=13.895]\n",
      "3800 [D loss: 7.98048591614, acc.: 0.00%] [G loss: 0.00326197175309] [mll=88.372+-3.771] [ks=13.926]\n",
      "3900 [D loss: 7.97807264328, acc.: 0.00%] [G loss: 0.00305851269513] [mll=87.978+-3.771] [ks=13.959]\n",
      "4000 [D loss: 7.97480297089, acc.: 0.00%] [G loss: 0.00314715295099] [mll=88.747+-3.775] [ks=13.883]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "4100 [D loss: 7.99309110641, acc.: 0.00%] [G loss: 0.0032202298753] [mll=87.987+-3.771] [ks=13.955]]\n",
      "4200 [D loss: 7.97710132599, acc.: 0.00%] [G loss: 0.00364826666191] [mll=91.211+-3.949] [ks=13.726]\n",
      "4300 [D loss: 7.97946596146, acc.: 0.00%] [G loss: 0.00316789001226] [mll=86.935+-3.668] [ks=14.057]\n",
      "4400 [D loss: 7.97674751282, acc.: 0.00%] [G loss: 0.00298993429169] [mll=88.075+-3.760] [ks=13.947]\n",
      "4500 [D loss: 7.97614097595, acc.: 0.00%] [G loss: 0.0030770804733] [mll=89.284+-3.770] [ks=13.832]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "4600 [D loss: 7.98244333267, acc.: 0.00%] [G loss: 0.00317185698077] [mll=88.557+-3.777] [ks=13.894]\n",
      "4700 [D loss: 7.97563838959, acc.: 0.00%] [G loss: 0.00301221292466] [mll=88.312+-3.796] [ks=13.916]\n",
      "4800 [D loss: 7.97747802734, acc.: 0.00%] [G loss: 0.00316173932515] [mll=90.209+-3.942] [ks=13.725]\n",
      "4900 [D loss: 7.97923803329, acc.: 0.00%] [G loss: 0.00309981568716] [mll=90.588+-3.869] [ks=13.724]\n",
      "5000 [D loss: 7.97631597519, acc.: 0.00%] [G loss: 0.00313542573713] [mll=88.324+-3.763] [ks=13.920]\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "5100 [D loss: 7.98121786118, acc.: 0.00%] [G loss: 0.00319558405317] [mll=88.223+-3.723] [ks=13.934]\n",
      "5200 [D loss: 8.00302791595, acc.: 0.00%] [G loss: 0.00331327109598] [mll=91.208+-3.945] [ks=13.724]\n",
      "5300 [D loss: 7.98028039932, acc.: 0.00%] [G loss: 0.00309353414923] [mll=87.987+-3.673] [ks=13.960]\n",
      "5400 [D loss: 7.97914552689, acc.: 0.00%] [G loss: 0.00325176492333] [mll=88.848+-3.860] [ks=13.861]\n",
      "5500 [D loss: 7.97947502136, acc.: 0.00%] [G loss: 0.00314061203972] [mll=90.971+-3.946] [ks=13.716]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "5600 [D loss: 7.97551393509, acc.: 0.00%] [G loss: 0.00322678731754] [mll=88.412+-3.807] [ks=13.912]\n",
      "5700 [D loss: 7.97700643539, acc.: 0.00%] [G loss: 0.00298859458417] [mll=88.005+-3.754] [ks=13.945]\n",
      "5800 [D loss: 7.97592401505, acc.: 0.00%] [G loss: 0.00299037457444] [mll=89.682+-3.907] [ks=13.770]\n",
      "5900 [D loss: 7.97750377655, acc.: 0.00%] [G loss: 0.00308696832508] [mll=89.691+-3.837] [ks=13.774]\n",
      "6000 [D loss: 7.97773838043, acc.: 0.00%] [G loss: 0.00299995974638] [mll=88.401+-3.829] [ks=13.902]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "6100 [D loss: 7.97964668274, acc.: 0.00%] [G loss: 0.00299062556587] [mll=89.905+-3.819] [ks=13.755]\n",
      "6200 [D loss: 7.983689785, acc.: 0.00%] [G loss: 0.00324280187488] [mll=89.772+-3.861] [ks=13.769]9]\n",
      "6300 [D loss: 7.98033571243, acc.: 0.00%] [G loss: 0.00320100574754] [mll=87.702+-3.776] [ks=13.969]\n",
      "6400 [D loss: 7.97970962524, acc.: 0.00%] [G loss: 0.00303287338465] [mll=91.063+-3.964] [ks=13.713]\n",
      "6500 [D loss: 7.97825193405, acc.: 0.00%] [G loss: 0.00301140337251] [mll=88.983+-3.826] [ks=13.853]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "6600 [D loss: 7.97617816925, acc.: 0.00%] [G loss: 0.00299937673844] [mll=90.349+-3.855] [ks=13.715]\n",
      "6700 [D loss: 7.98331165314, acc.: 0.00%] [G loss: 0.00323025835678] [mll=89.746+-3.895] [ks=13.766]\n",
      "6800 [D loss: 7.97959089279, acc.: 0.00%] [G loss: 0.00299149937928] [mll=87.991+-3.789] [ks=13.945]\n",
      "6900 [D loss: 7.9824347496, acc.: 0.00%] [G loss: 0.00315672298893] [mll=89.531+-3.940] [ks=13.781]]\n",
      "7000 [D loss: 7.98144626617, acc.: 0.00%] [G loss: 0.00305011658929] [mll=90.778+-3.939] [ks=13.712]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "7100 [D loss: 7.97831487656, acc.: 0.00%] [G loss: 0.00308211497031] [mll=90.306+-3.926] [ks=13.711]\n",
      "7200 [D loss: 7.98155832291, acc.: 0.00%] [G loss: 0.0030021534767] [mll=88.844+-3.743] [ks=13.867]]\n",
      "7300 [D loss: 7.97600078583, acc.: 0.00%] [G loss: 0.00300344475545] [mll=89.334+-3.910] [ks=13.810]\n",
      "7400 [D loss: 7.97925233841, acc.: 0.00%] [G loss: 0.00303160771728] [mll=89.971+-3.910] [ks=13.742]\n",
      "7500 [D loss: 7.97608184814, acc.: 0.00%] [G loss: 0.00299743190408] [mll=88.809+-3.852] [ks=13.864]\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "7600 [D loss: 7.9773850441, acc.: 0.00%] [G loss: 0.00306889018975] [mll=89.600+-3.852] [ks=13.776]]\n",
      "7700 [D loss: 7.98086452484, acc.: 0.00%] [G loss: 0.00305012217723] [mll=88.437+-3.741] [ks=13.912]\n",
      "7800 [D loss: 7.98410654068, acc.: 0.00%] [G loss: 0.00304106064141] [mll=90.420+-3.896] [ks=13.718]\n",
      "7900 [D loss: 7.98631811142, acc.: 0.00%] [G loss: 0.00309006473981] [mll=88.844+-3.793] [ks=13.869]\n",
      "8000 [D loss: 7.97952365875, acc.: 0.00%] [G loss: 0.0032428749837] [mll=90.655+-3.952] [ks=13.713]]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "8100 [D loss: 7.9770116806, acc.: 0.00%] [G loss: 0.0029931680765] [mll=91.124+-3.955] [ks=13.717]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8200 [D loss: 7.97718811035, acc.: 0.00%] [G loss: 0.00303532229736] [mll=89.869+-3.927] [ks=13.753]\n",
      "8300 [D loss: 7.98219490051, acc.: 0.00%] [G loss: 0.00300340540707] [mll=88.914+-3.779] [ks=13.856]\n",
      "8400 [D loss: 7.97820425034, acc.: 0.00%] [G loss: 0.00299254781567] [mll=89.958+-3.879] [ks=13.748]\n",
      "8500 [D loss: 7.99014616013, acc.: 0.00%] [G loss: 0.00298789492808] [mll=89.615+-3.887] [ks=13.784]\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "8600 [D loss: 7.97618198395, acc.: 0.00%] [G loss: 0.0029922646936] [mll=89.481+-3.836] [ks=13.794]]\n",
      "8700 [D loss: 7.97851800919, acc.: 0.00%] [G loss: 0.00307780108415] [mll=89.608+-3.850] [ks=13.779]\n",
      "8800 [D loss: 7.97941827774, acc.: 0.00%] [G loss: 0.00326327653602] [mll=88.481+-3.774] [ks=13.907]\n",
      "8900 [D loss: 7.97734260559, acc.: 0.00%] [G loss: 0.00307694613002] [mll=91.092+-3.976] [ks=13.710]\n",
      "9000 [D loss: 7.97642183304, acc.: 0.00%] [G loss: 0.00302586983889] [mll=90.380+-3.891] [ks=13.713]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "9100 [D loss: 7.98320674896, acc.: 0.00%] [G loss: 0.00314196734689] [mll=90.118+-3.832] [ks=13.724]\n",
      "9200 [D loss: 7.98315572739, acc.: 0.00%] [G loss: 0.00303229340352] [mll=90.758+-3.952] [ks=13.712]\n",
      "9300 [D loss: 7.97883701324, acc.: 0.00%] [G loss: 0.0030176078435] [mll=88.985+-3.824] [ks=13.847]]\n",
      "9400 [D loss: 7.98457050323, acc.: 0.00%] [G loss: 0.00303416722454] [mll=89.112+-3.839] [ks=13.831]\n",
      "9500 [D loss: 7.97618722916, acc.: 0.00%] [G loss: 0.00299046188593] [mll=90.446+-3.930] [ks=13.710]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "9600 [D loss: 7.97678613663, acc.: 0.00%] [G loss: 0.00312560820021] [mll=90.078+-3.911] [ks=13.728]\n",
      "9700 [D loss: 7.9785194397, acc.: 0.00%] [G loss: 0.00299523305148] [mll=88.555+-3.864] [ks=13.889]]\n",
      "9800 [D loss: 7.9784283638, acc.: 0.00%] [G loss: 0.0030916640535] [mll=89.926+-3.883] [ks=13.738]]]\n",
      "9900 [D loss: 7.9767742157, acc.: 0.00%] [G loss: 0.00299271987751] [mll=88.750+-3.897] [ks=13.872]]\n",
      "10000 [D loss: 7.97710132599, acc.: 0.00%] [G loss: 0.00300881988369] [mll=89.848+-3.945] [ks=13.746]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "10100 [D loss: 7.97635173798, acc.: 0.00%] [G loss: 0.00300514232367] [mll=89.838+-3.920] [ks=13.756]\n",
      "10200 [D loss: 7.97626256943, acc.: 0.00%] [G loss: 0.00299348309636] [mll=89.019+-3.817] [ks=13.848]\n",
      "10300 [D loss: 7.97929763794, acc.: 0.00%] [G loss: 0.00301440083422] [mll=89.310+-3.867] [ks=13.809]\n",
      "10400 [D loss: 8.01351642609, acc.: 0.00%] [G loss: 0.0030477065593] [mll=90.155+-3.849] [ks=13.719]]\n",
      "10500 [D loss: 7.98455524445, acc.: 0.00%] [G loss: 0.00306541076861] [mll=90.346+-3.889] [ks=13.712]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "10600 [D loss: 7.97682189941, acc.: 0.00%] [G loss: 0.00302999000996] [mll=88.794+-3.784] [ks=13.864]\n",
      "10700 [D loss: 7.97695636749, acc.: 0.00%] [G loss: 0.002994697541] [mll=90.456+-3.938] [ks=13.702]2]\n",
      "10800 [D loss: 7.98020362854, acc.: 0.00%] [G loss: 0.00305382255465] [mll=90.023+-3.914] [ks=13.721]\n",
      "10900 [D loss: 7.97809839249, acc.: 0.00%] [G loss: 0.00303036929108] [mll=90.297+-3.879] [ks=13.710]\n",
      "11000 [D loss: 7.97618484497, acc.: 0.00%] [G loss: 0.00300311646424] [mll=90.356+-3.930] [ks=13.706]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "11100 [D loss: 7.98320484161, acc.: 0.00%] [G loss: 0.00304369721562] [mll=89.861+-3.894] [ks=13.748]\n",
      "11200 [D loss: 7.98576688766, acc.: 0.00%] [G loss: 0.00299263186753] [mll=90.536+-3.883] [ks=13.708]\n",
      "11300 [D loss: 7.97872114182, acc.: 0.00%] [G loss: 0.00299473199993] [mll=89.674+-3.758] [ks=13.769]\n",
      "11400 [D loss: 7.97664165497, acc.: 0.00%] [G loss: 0.00299822818488] [mll=89.766+-3.839] [ks=13.752]\n",
      "11500 [D loss: 7.9787068367, acc.: 0.00%] [G loss: 0.00299578905106] [mll=89.112+-3.780] [ks=13.831]]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "11600 [D loss: 7.98157167435, acc.: 0.00%] [G loss: 0.0029932144098] [mll=90.163+-3.936] [ks=13.711]]\n",
      "11700 [D loss: 7.98093032837, acc.: 0.00%] [G loss: 0.00302972109057] [mll=89.547+-3.870] [ks=13.777]\n",
      "11800 [D loss: 7.97859430313, acc.: 0.00%] [G loss: 0.00299563840963] [mll=89.051+-3.799] [ks=13.842]\n",
      "11900 [D loss: 8.01166343689, acc.: 0.00%] [G loss: 0.00299362838268] [mll=90.000+-3.878] [ks=13.730]\n",
      "12000 [D loss: 7.99076604843, acc.: 0.00%] [G loss: 0.00319482060149] [mll=89.500+-3.795] [ks=13.785]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "12100 [D loss: 7.97590970993, acc.: 0.00%] [G loss: 0.00299003138207] [mll=90.595+-3.906] [ks=13.709]\n",
      "12200 [D loss: 7.97696065903, acc.: 0.00%] [G loss: 0.00300312251784] [mll=89.564+-3.786] [ks=13.779]\n",
      "12300 [D loss: 7.98305034637, acc.: 0.00%] [G loss: 0.00311136781238] [mll=89.274+-3.779] [ks=13.808]\n",
      "12400 [D loss: 7.97750282288, acc.: 0.00%] [G loss: 0.0031058313325] [mll=88.716+-3.876] [ks=13.865]]\n",
      "12500 [D loss: 7.97650671005, acc.: 0.00%] [G loss: 0.0029886434786] [mll=88.679+-3.821] [ks=13.868]]\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "12600 [D loss: 7.97666501999, acc.: 0.00%] [G loss: 0.00301289581694] [mll=89.470+-3.758] [ks=13.792]\n",
      "12700 [D loss: 7.97975635529, acc.: 0.00%] [G loss: 0.00304370396771] [mll=90.045+-3.911] [ks=13.726]\n",
      "12800 [D loss: 7.98515176773, acc.: 0.00%] [G loss: 0.00305328331888] [mll=88.840+-3.856] [ks=13.855]\n",
      "12900 [D loss: 7.98311758041, acc.: 0.00%] [G loss: 0.00299321580678] [mll=90.291+-3.868] [ks=13.710]\n",
      "13000 [D loss: 7.9788274765, acc.: 0.00%] [G loss: 0.00314786983654] [mll=90.018+-3.909] [ks=13.722]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "13100 [D loss: 7.97909212112, acc.: 0.00%] [G loss: 0.00298801017925] [mll=88.333+-3.739] [ks=13.914]\n",
      "13200 [D loss: 7.97679805756, acc.: 0.00%] [G loss: 0.00299082649872] [mll=89.722+-3.818] [ks=13.765]\n",
      "13300 [D loss: 7.97832965851, acc.: 0.00%] [G loss: 0.0030481852591] [mll=89.338+-3.826] [ks=13.801]]\n",
      "13400 [D loss: 7.97545814514, acc.: 0.00%] [G loss: 0.00299139716662] [mll=90.320+-3.891] [ks=13.708]\n",
      "13500 [D loss: 7.98722982407, acc.: 0.00%] [G loss: 0.00301538594067] [mll=89.830+-3.807] [ks=13.745]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "13600 [D loss: 7.97639703751, acc.: 0.00%] [G loss: 0.00298885721713] [mll=88.794+-3.763] [ks=13.866]\n",
      "13700 [D loss: 7.98058176041, acc.: 0.00%] [G loss: 0.00299611501396] [mll=89.190+-3.813] [ks=13.818]\n",
      "13800 [D loss: 7.98208379745, acc.: 0.00%] [G loss: 0.00299999699928] [mll=89.513+-3.875] [ks=13.787]\n",
      "13900 [D loss: 7.98682641983, acc.: 0.00%] [G loss: 0.00300710089505] [mll=89.110+-3.802] [ks=13.836]\n",
      "14000 [D loss: 7.97929096222, acc.: 0.00%] [G loss: 0.0029913673643] [mll=89.411+-3.809] [ks=13.794]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "14100 [D loss: 7.97779512405, acc.: 0.00%] [G loss: 0.00299836904742] [mll=89.582+-3.868] [ks=13.779]\n",
      "14200 [D loss: 7.97889661789, acc.: 0.00%] [G loss: 0.00300157722086] [mll=90.001+-3.844] [ks=13.735]\n",
      "14300 [D loss: 7.97745418549, acc.: 0.00%] [G loss: 0.00299879070371] [mll=89.719+-3.870] [ks=13.762]\n",
      "14400 [D loss: 7.97954177856, acc.: 0.00%] [G loss: 0.00299816671759] [mll=89.237+-3.896] [ks=13.809]\n",
      "14500 [D loss: 7.97965717316, acc.: 0.00%] [G loss: 0.00300243124366] [mll=89.443+-3.829] [ks=13.787]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "14600 [D loss: 7.97854423523, acc.: 0.00%] [G loss: 0.003075591987] [mll=90.098+-3.904] [ks=13.719]]]\n",
      "14700 [D loss: 7.97556638718, acc.: 0.00%] [G loss: 0.00299591897056] [mll=88.524+-3.747] [ks=13.891]\n",
      "14800 [D loss: 7.97823381424, acc.: 0.00%] [G loss: 0.00318039231934] [mll=90.005+-3.964] [ks=13.722]\n",
      "14900 [D loss: 7.98463439941, acc.: 0.00%] [G loss: 0.00298990495503] [mll=90.393+-3.890] [ks=13.706]\n",
      "15000 [D loss: 7.97987318039, acc.: 0.00%] [G loss: 0.00299615436234] [mll=89.916+-3.898] [ks=13.734]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "15100 [D loss: 7.97545623779, acc.: 0.00%] [G loss: 0.00302633433603] [mll=90.238+-3.801] [ks=13.715]\n",
      "15200 [D loss: 7.97785711288, acc.: 0.00%] [G loss: 0.00301324669272] [mll=88.942+-3.807] [ks=13.843]\n",
      "15300 [D loss: 7.97702026367, acc.: 0.00%] [G loss: 0.00310902833007] [mll=89.421+-3.827] [ks=13.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15400 [D loss: 7.97459220886, acc.: 0.00%] [G loss: 0.00299162091687] [mll=88.705+-3.884] [ks=13.856]\n",
      "15500 [D loss: 7.9828877449, acc.: 0.00%] [G loss: 0.00303718913347] [mll=89.685+-3.872] [ks=13.755]]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "15600 [D loss: 7.98075437546, acc.: 0.00%] [G loss: 0.00300221052021] [mll=89.124+-3.914] [ks=13.810]\n",
      "15700 [D loss: 7.97650384903, acc.: 0.00%] [G loss: 0.0031195175834] [mll=89.073+-3.848] [ks=13.824]]\n",
      "15800 [D loss: 7.98007202148, acc.: 0.00%] [G loss: 0.00304723065346] [mll=90.578+-3.913] [ks=13.703]\n",
      "15900 [D loss: 7.98192739487, acc.: 0.00%] [G loss: 0.00308101112023] [mll=88.666+-3.798] [ks=13.868]\n",
      "16000 [D loss: 7.97998476028, acc.: 0.00%] [G loss: 0.00302847661078] [mll=88.709+-3.753] [ks=13.863]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "16100 [D loss: 7.97802782059, acc.: 0.00%] [G loss: 0.00299566285685] [mll=89.968+-3.815] [ks=13.727]\n",
      "16200 [D loss: 7.97882843018, acc.: 0.00%] [G loss: 0.00299242674373] [mll=89.433+-3.950] [ks=13.779]\n",
      "16300 [D loss: 7.97907829285, acc.: 0.00%] [G loss: 0.00299168215133] [mll=89.291+-3.795] [ks=13.800]\n",
      "16400 [D loss: 7.98082923889, acc.: 0.00%] [G loss: 0.0030733847525] [mll=89.306+-3.890] [ks=13.797]]\n",
      "16500 [D loss: 7.97714662552, acc.: 0.00%] [G loss: 0.00301122129895] [mll=88.670+-3.752] [ks=13.869]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "16600 [D loss: 7.97713375092, acc.: 0.00%] [G loss: 0.00299358926713] [mll=89.800+-3.818] [ks=13.752]\n",
      "16700 [D loss: 7.97813415527, acc.: 0.00%] [G loss: 0.00299120182171] [mll=89.369+-3.818] [ks=13.792]\n",
      "16800 [D loss: 7.97655391693, acc.: 0.00%] [G loss: 0.00298891076818] [mll=89.710+-3.851] [ks=13.754]\n",
      "16900 [D loss: 7.97734832764, acc.: 0.00%] [G loss: 0.00298810936511] [mll=89.822+-3.909] [ks=13.741]\n",
      "17000 [D loss: 7.97884654999, acc.: 0.00%] [G loss: 0.00303462496959] [mll=89.774+-3.855] [ks=13.745]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "17100 [D loss: 7.97878313065, acc.: 0.00%] [G loss: 0.00300628482364] [mll=90.147+-3.938] [ks=13.702]\n",
      "17200 [D loss: 7.97756385803, acc.: 0.00%] [G loss: 0.00301981484517] [mll=89.417+-3.863] [ks=13.787]\n",
      "17300 [D loss: 7.97761487961, acc.: 0.00%] [G loss: 0.00302463769913] [mll=90.479+-3.903] [ks=13.697]\n",
      "17400 [D loss: 8.01781368256, acc.: 0.00%] [G loss: 0.00299828103743] [mll=89.505+-3.833] [ks=13.774]\n",
      "17500 [D loss: 7.97678375244, acc.: 0.00%] [G loss: 0.00307784648612] [mll=90.027+-3.880] [ks=13.712]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "17600 [D loss: 7.97633314133, acc.: 0.00%] [G loss: 0.00299415900372] [mll=90.626+-3.907] [ks=13.696]\n",
      "17700 [D loss: 7.99307489395, acc.: 0.00%] [G loss: 0.00300519703887] [mll=89.226+-3.823] [ks=13.808]\n",
      "17800 [D loss: 7.97824621201, acc.: 0.00%] [G loss: 0.00305389752612] [mll=89.864+-3.894] [ks=13.738]\n",
      "17900 [D loss: 7.97637748718, acc.: 0.00%] [G loss: 0.00298975058831] [mll=88.691+-3.861] [ks=13.845]\n",
      "18000 [D loss: 7.97718811035, acc.: 0.00%] [G loss: 0.00307193957269] [mll=89.533+-3.832] [ks=13.764]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "18100 [D loss: 7.97747755051, acc.: 0.00%] [G loss: 0.00299276434816] [mll=88.756+-3.819] [ks=13.849]\n",
      "18200 [D loss: 7.97877836227, acc.: 0.00%] [G loss: 0.00300353928469] [mll=89.635+-3.867] [ks=13.758]\n",
      "18300 [D loss: 8.08971881866, acc.: 0.00%] [G loss: 0.00313967443071] [mll=89.260+-3.873] [ks=13.796]\n",
      "18400 [D loss: 7.97755622864, acc.: 0.00%] [G loss: 0.00299488473684] [mll=88.407+-3.791] [ks=13.875]\n",
      "18500 [D loss: 7.97612190247, acc.: 0.00%] [G loss: 0.0030286104884] [mll=89.531+-3.893] [ks=13.766]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "18600 [D loss: 7.98012542725, acc.: 0.00%] [G loss: 0.00301023945212] [mll=89.145+-3.870] [ks=13.803]\n",
      "18700 [D loss: 7.97546005249, acc.: 0.00%] [G loss: 0.00303532555699] [mll=89.281+-3.782] [ks=13.799]\n",
      "18800 [D loss: 7.98550224304, acc.: 0.00%] [G loss: 0.00317230098881] [mll=89.059+-3.814] [ks=13.811]\n",
      "18900 [D loss: 7.98387145996, acc.: 0.00%] [G loss: 0.00302939349785] [mll=88.521+-3.840] [ks=13.865]\n",
      "19000 [D loss: 7.97881126404, acc.: 0.00%] [G loss: 0.00299756228924] [mll=88.872+-3.774] [ks=13.837]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "19100 [D loss: 8.06506156921, acc.: 0.00%] [G loss: 0.00298933661543] [mll=89.996+-3.836] [ks=13.717]\n",
      "19200 [D loss: 7.97849988937, acc.: 0.00%] [G loss: 0.00299073057249] [mll=89.742+-3.919] [ks=13.739]\n",
      "19300 [D loss: 7.97533845901, acc.: 0.00%] [G loss: 0.00299906893633] [mll=89.762+-3.856] [ks=13.736]\n",
      "19400 [D loss: 7.97684812546, acc.: 0.00%] [G loss: 0.00300302170217] [mll=89.852+-3.794] [ks=13.728]\n",
      "19500 [D loss: 7.97851133347, acc.: 0.00%] [G loss: 0.00314071937464] [mll=89.584+-3.859] [ks=13.761]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "19600 [D loss: 7.97815275192, acc.: 0.00%] [G loss: 0.00300152064301] [mll=90.579+-3.880] [ks=13.693]\n",
      "19700 [D loss: 7.97596883774, acc.: 0.00%] [G loss: 0.00300744874403] [mll=89.884+-3.811] [ks=13.732]\n",
      "19800 [D loss: 7.9789185524, acc.: 0.00%] [G loss: 0.0029943396803] [mll=90.082+-3.926] [ks=13.703]]]\n",
      "19900 [D loss: 7.97801828384, acc.: 0.00%] [G loss: 0.00301896245219] [mll=89.552+-3.867] [ks=13.763]\n",
      "20000 [D loss: 7.98140859604, acc.: 0.00%] [G loss: 0.00301652029157] [mll=88.943+-3.817] [ks=13.823]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "20100 [D loss: 7.97771263123, acc.: 0.00%] [G loss: 0.00300570717081] [mll=89.046+-3.819] [ks=13.816]\n",
      "20200 [D loss: 7.97677612305, acc.: 0.00%] [G loss: 0.0030049381312] [mll=90.131+-3.822] [ks=13.702]]\n",
      "20300 [D loss: 7.98109054565, acc.: 0.00%] [G loss: 0.00305581465364] [mll=88.983+-3.837] [ks=13.821]\n",
      "20400 [D loss: 7.98589992523, acc.: 0.00%] [G loss: 0.00301044969819] [mll=90.452+-3.866] [ks=13.692]\n",
      "20500 [D loss: 7.97686386108, acc.: 0.00%] [G loss: 0.00298966933042] [mll=89.095+-3.915] [ks=13.803]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "20600 [D loss: 7.97707509995, acc.: 0.00%] [G loss: 0.00302388519049] [mll=89.633+-3.868] [ks=13.755]\n",
      "20700 [D loss: 7.97624206543, acc.: 0.00%] [G loss: 0.00299185723998] [mll=89.110+-3.833] [ks=13.806]\n",
      "20800 [D loss: 7.97816371918, acc.: 0.00%] [G loss: 0.00308743771166] [mll=89.341+-3.843] [ks=13.782]\n",
      "20900 [D loss: 7.97825098038, acc.: 0.00%] [G loss: 0.00316155492328] [mll=88.910+-3.818] [ks=13.831]\n",
      "21000 [D loss: 7.97749567032, acc.: 0.00%] [G loss: 0.00299211754464] [mll=88.792+-3.860] [ks=13.832]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "21100 [D loss: 7.97865009308, acc.: 0.00%] [G loss: 0.00300301448442] [mll=89.332+-3.819] [ks=13.778]\n",
      "21200 [D loss: 7.97608327866, acc.: 0.00%] [G loss: 0.00308180949651] [mll=90.067+-3.916] [ks=13.697]\n",
      "21300 [D loss: 7.97618722916, acc.: 0.00%] [G loss: 0.00299449614249] [mll=88.691+-3.834] [ks=13.845]\n",
      "21400 [D loss: 7.98031520844, acc.: 0.00%] [G loss: 0.00306946411729] [mll=89.734+-3.860] [ks=13.737]\n",
      "21500 [D loss: 7.97837162018, acc.: 0.00%] [G loss: 0.00304292724468] [mll=90.237+-3.895] [ks=13.689]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "21600 [D loss: 7.98052692413, acc.: 0.00%] [G loss: 0.00301114446484] [mll=88.949+-3.856] [ks=13.810]\n",
      "21700 [D loss: 7.97694253922, acc.: 0.00%] [G loss: 0.00299127609469] [mll=89.819+-3.902] [ks=13.724]\n",
      "21800 [D loss: 7.97722244263, acc.: 0.00%] [G loss: 0.00304512493312] [mll=89.653+-3.873] [ks=13.740]\n",
      "21900 [D loss: 7.97548866272, acc.: 0.00%] [G loss: 0.00299955438823] [mll=90.226+-3.922] [ks=13.690]\n",
      "22000 [D loss: 7.97707843781, acc.: 0.00%] [G loss: 0.00305307493545] [mll=89.455+-3.811] [ks=13.763]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "22100 [D loss: 7.9956278801, acc.: 0.00%] [G loss: 0.0030143391341] [mll=90.436+-3.898] [ks=13.692]2]\n",
      "22200 [D loss: 7.97793102264, acc.: 0.00%] [G loss: 0.00298786722124] [mll=90.077+-3.954] [ks=13.702]\n",
      "22300 [D loss: 7.97783946991, acc.: 0.00%] [G loss: 0.0030520351138] [mll=89.467+-3.873] [ks=13.760]]\n",
      "22400 [D loss: 8.00474357605, acc.: 0.00%] [G loss: 0.00298915081657] [mll=89.209+-3.840] [ks=13.795]\n",
      "22500 [D loss: 7.97664785385, acc.: 0.00%] [G loss: 0.00311957579106] [mll=89.585+-3.834] [ks=13.747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 41us/step\n",
      "22600 [D loss: 7.97666072845, acc.: 0.00%] [G loss: 0.00301465741359] [mll=90.591+-3.901] [ks=13.689]\n",
      "22700 [D loss: 7.97768306732, acc.: 0.00%] [G loss: 0.00302713154815] [mll=89.292+-3.886] [ks=13.779]\n",
      "22800 [D loss: 7.97601747513, acc.: 0.00%] [G loss: 0.00300997402519] [mll=90.228+-3.893] [ks=13.691]\n",
      "22900 [D loss: 7.97668790817, acc.: 0.00%] [G loss: 0.00299907661974] [mll=90.227+-3.880] [ks=13.692]\n",
      "23000 [D loss: 7.97686243057, acc.: 0.00%] [G loss: 0.00305780931376] [mll=89.584+-3.947] [ks=13.751]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "23100 [D loss: 7.97634840012, acc.: 0.00%] [G loss: 0.00302666774951] [mll=88.480+-3.865] [ks=13.864]\n",
      "23200 [D loss: 7.97723817825, acc.: 0.00%] [G loss: 0.00302308821119] [mll=89.251+-3.806] [ks=13.788]\n",
      "23300 [D loss: 7.97592306137, acc.: 0.00%] [G loss: 0.00299719069153] [mll=88.978+-3.870] [ks=13.808]\n",
      "23400 [D loss: 7.97731876373, acc.: 0.00%] [G loss: 0.00299724750221] [mll=89.675+-3.871] [ks=13.741]\n",
      "23500 [D loss: 7.97657251358, acc.: 0.00%] [G loss: 0.0029939187225] [mll=89.034+-3.871] [ks=13.798]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "23600 [D loss: 7.98113965988, acc.: 0.00%] [G loss: 0.00300687830895] [mll=89.727+-3.820] [ks=13.731]\n",
      "23700 [D loss: 7.97614765167, acc.: 0.00%] [G loss: 0.00314300134778] [mll=89.195+-3.845] [ks=13.792]\n",
      "23800 [D loss: 7.97761297226, acc.: 0.00%] [G loss: 0.00299752666615] [mll=88.644+-3.765] [ks=13.850]\n",
      "23900 [D loss: 7.9759850502, acc.: 0.00%] [G loss: 0.0029998885002] [mll=89.574+-3.764] [ks=13.753]3]\n",
      "24000 [D loss: 7.98499536514, acc.: 0.00%] [G loss: 0.00315203564242] [mll=89.572+-3.831] [ks=13.758]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "24100 [D loss: 7.97803068161, acc.: 0.00%] [G loss: 0.00300003029406] [mll=88.559+-3.888] [ks=13.853]\n",
      "24200 [D loss: 7.97688341141, acc.: 0.00%] [G loss: 0.00301614962518] [mll=89.619+-3.867] [ks=13.747]\n",
      "24300 [D loss: 7.97977590561, acc.: 0.00%] [G loss: 0.00305582419969] [mll=89.188+-3.855] [ks=13.797]\n",
      "24400 [D loss: 7.97795438766, acc.: 0.00%] [G loss: 0.00300039188005] [mll=88.873+-3.789] [ks=13.826]\n",
      "24500 [D loss: 7.97632408142, acc.: 0.00%] [G loss: 0.00300075835548] [mll=89.805+-3.824] [ks=13.731]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "24600 [D loss: 7.97790813446, acc.: 0.00%] [G loss: 0.00304489396513] [mll=89.511+-3.796] [ks=13.763]\n",
      "24700 [D loss: 7.97793149948, acc.: 0.00%] [G loss: 0.0030317613855] [mll=89.134+-3.811] [ks=13.791]]\n",
      "24800 [D loss: 7.97686100006, acc.: 0.00%] [G loss: 0.00299089052714] [mll=90.107+-3.892] [ks=13.695]\n",
      "24900 [D loss: 7.98044395447, acc.: 0.00%] [G loss: 0.00304083852097] [mll=89.504+-3.877] [ks=13.756]\n",
      "25000 [D loss: 7.97950077057, acc.: 0.00%] [G loss: 0.00298858224414] [mll=88.876+-3.832] [ks=13.818]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "25100 [D loss: 7.9763469696, acc.: 0.00%] [G loss: 0.00311247236095] [mll=89.830+-3.806] [ks=13.722]]\n",
      "25200 [D loss: 7.97875165939, acc.: 0.00%] [G loss: 0.00299399811774] [mll=90.820+-3.897] [ks=13.694]\n",
      "25300 [D loss: 7.98234653473, acc.: 0.00%] [G loss: 0.00299074104987] [mll=89.311+-3.826] [ks=13.780]\n",
      "25400 [D loss: 7.9893579483, acc.: 0.00%] [G loss: 0.00302084744908] [mll=89.442+-3.855] [ks=13.766]]\n",
      "25500 [D loss: 7.99411296844, acc.: 0.00%] [G loss: 0.00299494480714] [mll=90.269+-3.900] [ks=13.687]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "25600 [D loss: 7.98527097702, acc.: 0.00%] [G loss: 0.00299598323181] [mll=89.307+-3.853] [ks=13.781]\n",
      "25700 [D loss: 7.97838783264, acc.: 0.00%] [G loss: 0.00302726402879] [mll=89.411+-3.811] [ks=13.767]\n",
      "25800 [D loss: 7.97634029388, acc.: 0.00%] [G loss: 0.00299719208851] [mll=88.946+-3.748] [ks=13.818]\n",
      "25900 [D loss: 7.97574520111, acc.: 0.00%] [G loss: 0.00300220935605] [mll=89.334+-3.864] [ks=13.768]\n",
      "26000 [D loss: 7.97669839859, acc.: 0.00%] [G loss: 0.00300280214287] [mll=89.190+-3.882] [ks=13.785]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "26100 [D loss: 7.99727630615, acc.: 0.00%] [G loss: 0.00302045396529] [mll=89.998+-3.901] [ks=13.704]\n",
      "26200 [D loss: 7.97779989243, acc.: 0.00%] [G loss: 0.0029895955231] [mll=89.148+-3.847] [ks=13.787]]\n",
      "26300 [D loss: 7.98994016647, acc.: 0.00%] [G loss: 0.00301198125817] [mll=89.453+-3.835] [ks=13.758]\n",
      "26400 [D loss: 7.97937679291, acc.: 0.00%] [G loss: 0.00299347587861] [mll=89.123+-3.864] [ks=13.785]\n",
      "26500 [D loss: 7.97951507568, acc.: 0.00%] [G loss: 0.00305770616978] [mll=89.416+-3.862] [ks=13.761]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "26600 [D loss: 7.97631502151, acc.: 0.00%] [G loss: 0.00304555241019] [mll=90.226+-3.937] [ks=13.685]\n",
      "26700 [D loss: 7.97805929184, acc.: 0.00%] [G loss: 0.00306261889637] [mll=88.889+-3.824] [ks=13.809]\n",
      "26800 [D loss: 7.97878551483, acc.: 0.00%] [G loss: 0.00299159414135] [mll=88.793+-3.836] [ks=13.826]\n",
      "26900 [D loss: 7.97558116913, acc.: 0.00%] [G loss: 0.00305046979338] [mll=89.284+-3.876] [ks=13.779]\n",
      "27000 [D loss: 7.97762966156, acc.: 0.00%] [G loss: 0.00303006730974] [mll=88.632+-3.796] [ks=13.841]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "27100 [D loss: 7.97638988495, acc.: 0.00%] [G loss: 0.00300890300423] [mll=88.805+-3.884] [ks=13.830]\n",
      "27200 [D loss: 7.97699737549, acc.: 0.00%] [G loss: 0.0029952081386] [mll=89.264+-3.864] [ks=13.771]]\n",
      "27300 [D loss: 7.97561120987, acc.: 0.00%] [G loss: 0.00298824370839] [mll=89.749+-3.827] [ks=13.729]\n",
      "27400 [D loss: 7.98336172104, acc.: 0.00%] [G loss: 0.00307314819656] [mll=89.938+-3.918] [ks=13.705]\n",
      "27500 [D loss: 7.97626781464, acc.: 0.00%] [G loss: 0.00299633108079] [mll=90.091+-3.921] [ks=13.686]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "27600 [D loss: 7.97710800171, acc.: 0.00%] [G loss: 0.00308256875724] [mll=89.266+-3.856] [ks=13.776]\n",
      "27700 [D loss: 7.97654056549, acc.: 0.00%] [G loss: 0.00305252312683] [mll=90.540+-3.903] [ks=13.686]\n",
      "27800 [D loss: 7.97574138641, acc.: 0.00%] [G loss: 0.00298900925554] [mll=89.025+-3.836] [ks=13.798]\n",
      "27900 [D loss: 7.97550392151, acc.: 0.00%] [G loss: 0.00301837339066] [mll=89.580+-3.791] [ks=13.743]\n",
      "28000 [D loss: 7.98040866852, acc.: 0.00%] [G loss: 0.00299627915956] [mll=89.260+-3.758] [ks=13.772]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "28100 [D loss: 7.97568321228, acc.: 0.00%] [G loss: 0.00299786380492] [mll=89.853+-3.924] [ks=13.713]\n",
      "28200 [D loss: 7.97918176651, acc.: 0.00%] [G loss: 0.00299534737132] [mll=89.290+-3.862] [ks=13.770]\n",
      "28300 [D loss: 7.97661113739, acc.: 0.00%] [G loss: 0.0029979662504] [mll=89.476+-3.864] [ks=13.749]]\n",
      "28400 [D loss: 7.97627162933, acc.: 0.00%] [G loss: 0.00299416459166] [mll=89.518+-3.899] [ks=13.747]\n",
      "28500 [D loss: 7.97544527054, acc.: 0.00%] [G loss: 0.00300005613826] [mll=89.602+-3.881] [ks=13.735]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "28600 [D loss: 7.9765996933, acc.: 0.00%] [G loss: 0.00298917386681] [mll=89.778+-3.896] [ks=13.727]]\n",
      "28700 [D loss: 7.97704696655, acc.: 0.00%] [G loss: 0.00306956074201] [mll=89.435+-3.839] [ks=13.751]\n",
      "28800 [D loss: 7.98503446579, acc.: 0.00%] [G loss: 0.00298844487406] [mll=90.452+-3.881] [ks=13.678]\n",
      "28900 [D loss: 7.97838115692, acc.: 0.00%] [G loss: 0.00298947677948] [mll=89.225+-3.875] [ks=13.775]\n",
      "29000 [D loss: 7.97859382629, acc.: 0.00%] [G loss: 0.00299333990552] [mll=89.915+-3.889] [ks=13.706]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "29100 [D loss: 7.97549200058, acc.: 0.00%] [G loss: 0.00302565935999] [mll=89.392+-3.881] [ks=13.756]\n",
      "29200 [D loss: 7.98008298874, acc.: 0.00%] [G loss: 0.00299082836136] [mll=90.207+-3.959] [ks=13.672]\n",
      "29300 [D loss: 8.0879535675, acc.: 0.00%] [G loss: 0.00299418158829] [mll=89.755+-3.854] [ks=13.722]]\n",
      "29400 [D loss: 7.97918558121, acc.: 0.00%] [G loss: 0.0029977823142] [mll=89.926+-3.877] [ks=13.706]]\n",
      "29500 [D loss: 7.9786491394, acc.: 0.00%] [G loss: 0.00299818441272] [mll=89.637+-3.826] [ks=13.727]]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "29600 [D loss: 7.97759246826, acc.: 0.00%] [G loss: 0.00303952186368] [mll=89.399+-3.908] [ks=13.751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29700 [D loss: 7.97868871689, acc.: 0.00%] [G loss: 0.00298779178411] [mll=90.114+-3.829] [ks=13.681]\n",
      "29800 [D loss: 7.97551631927, acc.: 0.00%] [G loss: 0.00305315013975] [mll=89.672+-3.880] [ks=13.728]\n",
      "29900 [D loss: 7.9791097641, acc.: 0.00%] [G loss: 0.00301939062774] [mll=88.807+-3.811] [ks=13.817]]\n",
      "30000 [D loss: 7.97697353363, acc.: 0.00%] [G loss: 0.00299505144358] [mll=89.649+-3.889] [ks=13.726]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "30100 [D loss: 7.98210906982, acc.: 0.00%] [G loss: 0.00298909074627] [mll=89.738+-3.852] [ks=13.721]\n",
      "30200 [D loss: 7.97585964203, acc.: 0.00%] [G loss: 0.00300716049969] [mll=89.944+-3.886] [ks=13.697]\n",
      "30300 [D loss: 7.97997665405, acc.: 0.00%] [G loss: 0.00300145242363] [mll=89.372+-3.859] [ks=13.752]\n",
      "30400 [D loss: 7.97749757767, acc.: 0.00%] [G loss: 0.00300668575801] [mll=89.479+-3.903] [ks=13.746]\n",
      "30500 [D loss: 7.97862243652, acc.: 0.00%] [G loss: 0.0029908514116] [mll=90.075+-3.945] [ks=13.689]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "30600 [D loss: 7.97628355026, acc.: 0.00%] [G loss: 0.00306631415151] [mll=89.460+-3.858] [ks=13.750]\n",
      "30700 [D loss: 7.98364496231, acc.: 0.00%] [G loss: 0.00301306671463] [mll=88.483+-3.815] [ks=13.854]\n",
      "30800 [D loss: 7.98066329956, acc.: 0.00%] [G loss: 0.0030044245068] [mll=90.307+-3.938] [ks=13.675]]\n",
      "30900 [D loss: 7.98259353638, acc.: 0.00%] [G loss: 0.00300746946596] [mll=89.110+-3.827] [ks=13.784]\n",
      "31000 [D loss: 7.97906064987, acc.: 0.00%] [G loss: 0.00300642754883] [mll=89.183+-3.824] [ks=13.782]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "31100 [D loss: 7.97761631012, acc.: 0.00%] [G loss: 0.00303715630434] [mll=90.060+-3.910] [ks=13.681]\n",
      "31200 [D loss: 7.98021316528, acc.: 0.00%] [G loss: 0.00300166709349] [mll=90.217+-3.879] [ks=13.679]\n",
      "31300 [D loss: 7.97662973404, acc.: 0.00%] [G loss: 0.00298854173161] [mll=89.769+-3.822] [ks=13.705]\n",
      "31400 [D loss: 7.97752571106, acc.: 0.00%] [G loss: 0.00299364188686] [mll=89.362+-3.826] [ks=13.749]\n",
      "31500 [D loss: 7.97909164429, acc.: 0.00%] [G loss: 0.00299035431817] [mll=89.481+-3.859] [ks=13.744]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "31600 [D loss: 7.97554302216, acc.: 0.00%] [G loss: 0.00300897704437] [mll=89.484+-3.852] [ks=13.743]\n",
      "31700 [D loss: 7.97613954544, acc.: 0.00%] [G loss: 0.00299406796694] [mll=89.965+-3.908] [ks=13.696]\n",
      "31800 [D loss: 7.97622251511, acc.: 0.00%] [G loss: 0.00298802531324] [mll=89.873+-3.848] [ks=13.717]\n",
      "31900 [D loss: 7.97965669632, acc.: 0.00%] [G loss: 0.00299532758072] [mll=89.841+-3.915] [ks=13.706]\n",
      "32000 [D loss: 7.97747898102, acc.: 0.00%] [G loss: 0.0030243457295] [mll=89.376+-3.850] [ks=13.752]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "32100 [D loss: 7.98145103455, acc.: 0.00%] [G loss: 0.0030006733723] [mll=90.096+-3.806] [ks=13.679]]\n",
      "32200 [D loss: 7.97623443604, acc.: 0.00%] [G loss: 0.00299754459411] [mll=89.410+-3.919] [ks=13.742]\n",
      "32300 [D loss: 7.97943210602, acc.: 0.00%] [G loss: 0.0030813892372] [mll=89.332+-3.847] [ks=13.752]]\n",
      "32400 [D loss: 7.97737932205, acc.: 0.00%] [G loss: 0.00299357902259] [mll=88.868+-3.899] [ks=13.794]\n",
      "32500 [D loss: 7.97660732269, acc.: 0.00%] [G loss: 0.0029911887832] [mll=89.240+-3.800] [ks=13.764]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "32600 [D loss: 7.98084878922, acc.: 0.00%] [G loss: 0.00301650562324] [mll=89.547+-3.884] [ks=13.730]\n",
      "32700 [D loss: 7.9759054184, acc.: 0.00%] [G loss: 0.0030441225972] [mll=90.059+-3.819] [ks=13.683]3]\n",
      "32800 [D loss: 7.97625541687, acc.: 0.00%] [G loss: 0.00299935578369] [mll=88.702+-3.866] [ks=13.824]\n",
      "32900 [D loss: 7.9788107872, acc.: 0.00%] [G loss: 0.00305567542091] [mll=89.529+-3.845] [ks=13.733]]\n",
      "33000 [D loss: 7.97620248795, acc.: 0.00%] [G loss: 0.00298954825848] [mll=88.663+-3.778] [ks=13.827]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "33100 [D loss: 7.97677659988, acc.: 0.00%] [G loss: 0.00301692984067] [mll=89.608+-3.861] [ks=13.714]\n",
      "33200 [D loss: 7.97816610336, acc.: 0.00%] [G loss: 0.00305026792921] [mll=89.474+-3.865] [ks=13.740]\n",
      "33300 [D loss: 7.97602748871, acc.: 0.00%] [G loss: 0.00300165801309] [mll=90.068+-3.856] [ks=13.680]\n",
      "33400 [D loss: 7.98052692413, acc.: 0.00%] [G loss: 0.00311257480644] [mll=89.540+-3.806] [ks=13.731]\n",
      "33500 [D loss: 7.97914552689, acc.: 0.00%] [G loss: 0.00302168889903] [mll=88.695+-3.810] [ks=13.819]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "33600 [D loss: 7.97846317291, acc.: 0.00%] [G loss: 0.00303059350699] [mll=89.266+-3.864] [ks=13.759]\n",
      "33700 [D loss: 7.97646331787, acc.: 0.00%] [G loss: 0.00299742654897] [mll=89.911+-3.909] [ks=13.689]\n",
      "33800 [D loss: 7.9761838913, acc.: 0.00%] [G loss: 0.00310413516127] [mll=89.261+-3.833] [ks=13.757]]\n",
      "33900 [D loss: 7.97790813446, acc.: 0.00%] [G loss: 0.00300982547924] [mll=88.453+-3.835] [ks=13.842]\n",
      "34000 [D loss: 7.97630786896, acc.: 0.00%] [G loss: 0.0030036510434] [mll=89.217+-3.899] [ks=13.758]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "34100 [D loss: 7.97744750977, acc.: 0.00%] [G loss: 0.0030263515655] [mll=89.817+-3.887] [ks=13.711]]\n",
      "34200 [D loss: 7.97961854935, acc.: 0.00%] [G loss: 0.0029914053157] [mll=88.899+-3.792] [ks=13.793]]\n",
      "34300 [D loss: 7.97887134552, acc.: 0.00%] [G loss: 0.00301229115576] [mll=89.441+-3.923] [ks=13.732]\n",
      "34400 [D loss: 7.9771566391, acc.: 0.00%] [G loss: 0.00304956943728] [mll=89.279+-3.860] [ks=13.751]]\n",
      "34500 [D loss: 7.97763681412, acc.: 0.00%] [G loss: 0.00306781777181] [mll=90.137+-3.883] [ks=13.663]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "34600 [D loss: 7.98105049133, acc.: 0.00%] [G loss: 0.00299416761845] [mll=90.178+-3.832] [ks=13.673]\n",
      "34700 [D loss: 7.9784989357, acc.: 0.00%] [G loss: 0.00299247005023] [mll=89.811+-3.932] [ks=13.702]]\n",
      "34800 [D loss: 7.97827291489, acc.: 0.00%] [G loss: 0.00299945659935] [mll=89.571+-3.867] [ks=13.719]\n",
      "34900 [D loss: 7.9779343605, acc.: 0.00%] [G loss: 0.00298842974007] [mll=89.571+-3.861] [ks=13.720]]\n",
      "35000 [D loss: 7.98273563385, acc.: 0.00%] [G loss: 0.00300227617845] [mll=89.802+-3.826] [ks=13.696]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "35100 [D loss: 7.97991943359, acc.: 0.00%] [G loss: 0.00312932441011] [mll=90.119+-3.865] [ks=13.670]\n",
      "35200 [D loss: 8.01229667664, acc.: 0.00%] [G loss: 0.00301277614199] [mll=90.742+-3.923] [ks=13.654]\n",
      "35300 [D loss: 7.98044061661, acc.: 0.00%] [G loss: 0.00301533774473] [mll=89.268+-3.803] [ks=13.759]\n",
      "35400 [D loss: 8.09215164185, acc.: 0.00%] [G loss: 0.00302027352154] [mll=88.887+-3.799] [ks=13.797]\n",
      "35500 [D loss: 7.97738599777, acc.: 0.00%] [G loss: 0.00310021732002] [mll=88.964+-3.778] [ks=13.784]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "35600 [D loss: 7.98746776581, acc.: 0.00%] [G loss: 0.00300407758914] [mll=88.612+-3.810] [ks=13.820]\n",
      "35700 [D loss: 7.98009395599, acc.: 0.00%] [G loss: 0.00299106352031] [mll=89.499+-3.892] [ks=13.734]\n",
      "35800 [D loss: 7.98096418381, acc.: 0.00%] [G loss: 0.00301914010197] [mll=89.600+-3.816] [ks=13.717]\n",
      "35900 [D loss: 7.97790193558, acc.: 0.00%] [G loss: 0.00299635343254] [mll=89.153+-3.851] [ks=13.771]\n",
      "36000 [D loss: 7.97761917114, acc.: 0.00%] [G loss: 0.00308794877492] [mll=89.343+-3.840] [ks=13.746]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "36100 [D loss: 7.97711133957, acc.: 0.00%] [G loss: 0.00303353206255] [mll=90.456+-3.853] [ks=13.673]\n",
      "36200 [D loss: 7.99205970764, acc.: 0.00%] [G loss: 0.00301746255718] [mll=90.177+-3.870] [ks=13.663]\n",
      "36287 [D loss: 7.97770452499, acc.: 0.00%] [G loss: 0.00298810168169] [mll=90.283+-3.876] [ks=13.668]BREAKING because disc/gen loss has remained the same for 1/1001 epochs!\n",
      "Scaling jet pts\n",
      "Scaling lep isos\n",
      "Discriminator params: 161537\n",
      "Generator params: 340497\n",
      "scaling lepton isolations\n",
      "scaling jet pts\n",
      "100 [D loss: 0.510963499546, acc.: 0.00%] [G loss: 2.5069475174] [mll=-1.000+--1.000] [ks=999.000]]\n",
      "KS score improved from 999.00 to 14.77, saving models to progress/jetisoscale_mllwidth_flatNegNoise_4/gen_100.weights\n",
      "200 [D loss: 1.03330636024, acc.: 50.00%] [G loss: 5.03680562973] [mll=6.565+-0.694] [ks=14.773]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 [D loss: 0.303522258997, acc.: 0.00%] [G loss: 5.02805376053] [mll=nan+-nan] [ks=15.502]]\n",
      "400 [D loss: 0.0882520973682, acc.: 0.00%] [G loss: 4.94688081741] [mll=48.964+-4.655] [ks=14.879]\n",
      "KS score improved from 14.77 to 13.78, saving models to progress/jetisoscale_mllwidth_flatNegNoise_4/gen_400.weights\n",
      "500 [D loss: 0.0654927790165, acc.: 0.00%] [G loss: 7.47213697433] [mll=65.860+-5.995] [ks=13.780]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "600 [D loss: 0.467883110046, acc.: 50.00%] [G loss: 6.3535733223] [mll=58.974+-5.132] [ks=13.919]]\n",
      "700 [D loss: 0.0535607524216, acc.: 0.00%] [G loss: 5.01256608963] [mll=nan+-nan] [ks=14.342]\n",
      "KS score improved from 13.78 to 13.04, saving models to progress/jetisoscale_mllwidth_flatNegNoise_4/gen_700.weights\n",
      "800 [D loss: 0.0674073472619, acc.: 0.00%] [G loss: 5.50756931305] [mll=79.094+-7.052] [ks=13.041]\n",
      "900 [D loss: 0.162493005395, acc.: 0.00%] [G loss: 4.1611328125] [mll=86.188+-7.219] [ks=14.365]]]\n",
      "1000 [D loss: 0.205898061395, acc.: 0.00%] [G loss: 6.17874622345] [mll=55.111+-3.504] [ks=14.652]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "1100 [D loss: 0.0560741946101, acc.: 0.00%] [G loss: 4.96062660217] [mll=29.112+-1.585] [ks=15.367]\n",
      "1200 [D loss: 0.104636259377, acc.: 0.00%] [G loss: 6.4517865181] [mll=77.551+-5.457] [ks=13.950]]]\n",
      "1300 [D loss: 0.160312145948, acc.: 0.00%] [G loss: 7.52582263947] [mll=77.536+-5.895] [ks=14.586]]\n",
      "1400 [D loss: 0.0621106103063, acc.: 0.00%] [G loss: 6.68201065063] [mll=60.502+-4.115] [ks=13.897]\n",
      "1500 [D loss: 1.03076672554, acc.: 0.00%] [G loss: 9.90657901764] [mll=134.168+-10.118] [ks=14.926]6]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "1600 [D loss: 7.97727203369, acc.: 0.00%] [G loss: 0.00327253737487] [mll=57.485+-3.754] [ks=15.205]\n",
      "1700 [D loss: 7.98190021515, acc.: 0.00%] [G loss: 0.00512867001817] [mll=89.650+-4.925] [ks=13.652]\n",
      "1800 [D loss: 7.97788858414, acc.: 0.00%] [G loss: 0.00524251628667] [mll=93.924+-4.477] [ks=13.889]\n",
      "1900 [D loss: 7.97944402695, acc.: 0.00%] [G loss: 0.00560813443735] [mll=93.836+-3.918] [ks=13.892]\n",
      "2000 [D loss: 7.97721290588, acc.: 0.00%] [G loss: 0.00530388299376] [mll=94.256+-3.724] [ks=13.989]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "2100 [D loss: 7.97894906998, acc.: 0.00%] [G loss: 0.00479477457702] [mll=93.829+-3.755] [ks=13.981]\n",
      "2200 [D loss: 7.9812746048, acc.: 0.00%] [G loss: 0.00499086081982] [mll=93.696+-3.953] [ks=13.951]]\n",
      "2300 [D loss: 7.97841644287, acc.: 0.00%] [G loss: 0.00392239959911] [mll=93.762+-3.993] [ks=13.966]\n",
      "2400 [D loss: 7.9890370369, acc.: 0.00%] [G loss: 0.00383957102895] [mll=92.278+-3.964] [ks=13.828]]\n",
      "2500 [D loss: 7.98067331314, acc.: 0.00%] [G loss: 0.00316975614987] [mll=92.197+-3.918] [ks=13.826]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "2600 [D loss: 8.00012207031, acc.: 0.00%] [G loss: 0.00373685359955] [mll=90.692+-3.896] [ks=13.720]\n",
      "2700 [D loss: 7.98852586746, acc.: 0.00%] [G loss: 0.00430589495227] [mll=92.267+-3.971] [ks=13.827]\n",
      "2800 [D loss: 7.97808361053, acc.: 0.00%] [G loss: 0.00332240341231] [mll=93.118+-3.965] [ks=13.902]\n",
      "2900 [D loss: 7.97807216644, acc.: 0.00%] [G loss: 0.0039746160619] [mll=91.333+-3.922] [ks=13.751]]\n",
      "3000 [D loss: 7.97630882263, acc.: 0.00%] [G loss: 0.0035593600478] [mll=86.297+-3.589] [ks=14.136]]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "3100 [D loss: 7.98178768158, acc.: 0.00%] [G loss: 0.00335145043209] [mll=87.532+-3.716] [ks=14.013]\n",
      "3200 [D loss: 7.97784948349, acc.: 0.00%] [G loss: 0.00304612866603] [mll=87.494+-3.674] [ks=14.028]\n",
      "3300 [D loss: 7.97736310959, acc.: 0.00%] [G loss: 0.00346059724689] [mll=90.504+-3.936] [ks=13.726]\n",
      "3400 [D loss: 7.97867202759, acc.: 0.00%] [G loss: 0.00407992722467] [mll=91.229+-3.836] [ks=13.743]\n",
      "3500 [D loss: 7.97923994064, acc.: 0.00%] [G loss: 0.00316114677116] [mll=86.280+-3.636] [ks=14.139]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "3600 [D loss: 7.9788684845, acc.: 0.00%] [G loss: 0.00352112948895] [mll=88.180+-3.711] [ks=13.955]]\n",
      "3700 [D loss: 7.97619009018, acc.: 0.00%] [G loss: 0.00302167772315] [mll=91.921+-3.971] [ks=13.781]\n",
      "3800 [D loss: 7.97619152069, acc.: 0.00%] [G loss: 0.00344677316025] [mll=90.200+-3.899] [ks=13.721]\n",
      "3900 [D loss: 7.9853348732, acc.: 0.00%] [G loss: 0.00305164023302] [mll=91.564+-3.903] [ks=13.706]]\n",
      "4000 [D loss: 7.9862985611, acc.: 0.00%] [G loss: 0.00330574600957] [mll=90.402+-3.890] [ks=13.685]]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "4100 [D loss: 7.97821474075, acc.: 0.00%] [G loss: 0.00306023750454] [mll=87.668+-3.725] [ks=13.977]\n",
      "4200 [D loss: 7.98544883728, acc.: 0.00%] [G loss: 0.00299033499323] [mll=88.780+-3.811] [ks=13.814]\n",
      "4300 [D loss: 7.97877216339, acc.: 0.00%] [G loss: 0.00299628102221] [mll=89.420+-3.849] [ks=13.679]\n",
      "4400 [D loss: 8.00192832947, acc.: 0.00%] [G loss: 0.00300070550293] [mll=89.532+-3.861] [ks=13.611]\n",
      "4500 [D loss: 7.97867298126, acc.: 0.00%] [G loss: 0.00319671630859] [mll=89.188+-3.825] [ks=13.642]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "4600 [D loss: 7.98012924194, acc.: 0.00%] [G loss: 0.00345174269751] [mll=91.160+-3.980] [ks=13.383]\n",
      "4700 [D loss: 7.97822141647, acc.: 0.00%] [G loss: 0.00304733193479] [mll=87.613+-3.686] [ks=13.781]\n",
      "4800 [D loss: 7.97665548325, acc.: 0.00%] [G loss: 0.00299783446826] [mll=90.543+-3.915] [ks=13.343]\n",
      "4900 [D loss: 7.97639608383, acc.: 0.00%] [G loss: 0.00300285057165] [mll=89.306+-3.849] [ks=13.447]\n",
      "5000 [D loss: 7.97621440887, acc.: 0.00%] [G loss: 0.0030787489377] [mll=89.976+-3.868] [ks=13.443]]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "5100 [D loss: 7.97953033447, acc.: 0.00%] [G loss: 0.00318782194518] [mll=88.667+-3.737] [ks=13.614]\n",
      "5200 [D loss: 7.97997236252, acc.: 0.00%] [G loss: 0.00299342256039] [mll=90.884+-3.880] [ks=13.683]\n",
      "5300 [D loss: 7.97874832153, acc.: 0.00%] [G loss: 0.00309858261608] [mll=89.628+-3.863] [ks=13.667]\n",
      "5400 [D loss: 7.97788763046, acc.: 0.00%] [G loss: 0.00300207268447] [mll=88.385+-3.805] [ks=13.733]\n",
      "5500 [D loss: 7.97535467148, acc.: 0.00%] [G loss: 0.0031161417719] [mll=90.075+-3.876] [ks=13.795]]\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "5600 [D loss: 7.97503471375, acc.: 0.00%] [G loss: 0.00309355952777] [mll=90.792+-3.907] [ks=13.905]\n",
      "5700 [D loss: 7.979159832, acc.: 0.00%] [G loss: 0.00299958302639] [mll=90.534+-3.884] [ks=13.937]7]\n",
      "5800 [D loss: 7.97789859772, acc.: 0.00%] [G loss: 0.00299479044043] [mll=89.084+-3.829] [ks=14.000]\n",
      "5900 [D loss: 7.98170137405, acc.: 0.00%] [G loss: 0.00300550926477] [mll=89.732+-3.910] [ks=13.990]\n",
      "6000 [D loss: 7.97905254364, acc.: 0.00%] [G loss: 0.003150297096] [mll=89.823+-3.787] [ks=14.034]4]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "6100 [D loss: 8.03092193604, acc.: 0.00%] [G loss: 0.00317185209133] [mll=90.633+-3.908] [ks=14.059]\n",
      "6200 [D loss: 7.9839758873, acc.: 0.00%] [G loss: 0.00301901437342] [mll=90.675+-3.906] [ks=14.096]]\n",
      "6300 [D loss: 7.97869873047, acc.: 0.00%] [G loss: 0.00300484872423] [mll=90.216+-3.905] [ks=14.058]\n",
      "6400 [D loss: 7.97768497467, acc.: 0.00%] [G loss: 0.00303786993027] [mll=89.944+-3.859] [ks=14.090]\n",
      "6500 [D loss: 7.9771232605, acc.: 0.00%] [G loss: 0.00319606461562] [mll=90.337+-3.836] [ks=14.113]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "6600 [D loss: 7.98347091675, acc.: 0.00%] [G loss: 0.00303699797951] [mll=88.105+-3.719] [ks=14.225]\n",
      "6700 [D loss: 7.97718715668, acc.: 0.00%] [G loss: 0.00308004487306] [mll=88.801+-3.786] [ks=14.225]\n",
      "6800 [D loss: 7.9768819809, acc.: 0.00%] [G loss: 0.00315499654971] [mll=88.331+-3.773] [ks=14.262]]\n",
      "6900 [D loss: 7.9777803421, acc.: 0.00%] [G loss: 0.00326253497042] [mll=91.021+-3.930] [ks=14.213]]\n",
      "7000 [D loss: 7.97876596451, acc.: 0.00%] [G loss: 0.00311695225537] [mll=91.050+-3.870] [ks=14.256]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "7100 [D loss: 7.98346996307, acc.: 0.00%] [G loss: 0.00303941057064] [mll=90.420+-3.901] [ks=14.231]\n",
      "7200 [D loss: 7.97930765152, acc.: 0.00%] [G loss: 0.00301531539299] [mll=88.942+-3.804] [ks=14.328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300 [D loss: 7.9764790535, acc.: 0.00%] [G loss: 0.00309536373243] [mll=89.225+-3.816] [ks=14.323]]\n",
      "7400 [D loss: 7.98093605042, acc.: 0.00%] [G loss: 0.00310421152972] [mll=88.601+-3.863] [ks=14.361]\n",
      "7500 [D loss: 7.9801940918, acc.: 0.00%] [G loss: 0.00300275511108] [mll=88.535+-3.779] [ks=14.396]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "7600 [D loss: 7.97528600693, acc.: 0.00%] [G loss: 0.00300464383326] [mll=89.372+-3.851] [ks=14.345]\n",
      "7700 [D loss: 7.97789907455, acc.: 0.00%] [G loss: 0.00322809861973] [mll=88.937+-3.806] [ks=14.381]\n",
      "7800 [D loss: 7.97771501541, acc.: 0.00%] [G loss: 0.00300537794828] [mll=88.057+-3.780] [ks=14.468]\n",
      "7900 [D loss: 8.00759124756, acc.: 0.00%] [G loss: 0.00309909484349] [mll=90.143+-3.922] [ks=14.291]\n",
      "8000 [D loss: 7.97799634933, acc.: 0.00%] [G loss: 0.00303117162548] [mll=90.672+-3.927] [ks=14.304]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "8100 [D loss: 7.97884702682, acc.: 0.00%] [G loss: 0.0030003504362] [mll=89.154+-3.855] [ks=14.407]]\n",
      "8200 [D loss: 7.97694969177, acc.: 0.00%] [G loss: 0.00300155254081] [mll=89.976+-3.900] [ks=14.330]\n",
      "8300 [D loss: 7.97665929794, acc.: 0.00%] [G loss: 0.00305924518034] [mll=89.176+-3.825] [ks=14.418]\n",
      "8400 [D loss: 7.98345088959, acc.: 0.00%] [G loss: 0.00301154050976] [mll=90.148+-3.901] [ks=14.325]\n",
      "8500 [D loss: 7.97577524185, acc.: 0.00%] [G loss: 0.00311933108605] [mll=90.304+-3.882] [ks=14.329]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "8600 [D loss: 7.97771644592, acc.: 0.00%] [G loss: 0.00298979668878] [mll=90.364+-3.897] [ks=14.336]\n",
      "8700 [D loss: 7.97932815552, acc.: 0.00%] [G loss: 0.00302064698189] [mll=89.435+-3.864] [ks=14.409]\n",
      "8800 [D loss: 7.97584676743, acc.: 0.00%] [G loss: 0.00298839900643] [mll=90.079+-3.940] [ks=14.338]\n",
      "8900 [D loss: 7.97840547562, acc.: 0.00%] [G loss: 0.00313827348873] [mll=89.520+-3.823] [ks=14.401]\n",
      "9000 [D loss: 7.97875833511, acc.: 0.00%] [G loss: 0.00298895523883] [mll=90.586+-3.866] [ks=14.360]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "9100 [D loss: 7.97576570511, acc.: 0.00%] [G loss: 0.00300109176897] [mll=89.854+-3.888] [ks=14.368]\n",
      "9200 [D loss: 7.97855472565, acc.: 0.00%] [G loss: 0.00303813815117] [mll=90.077+-3.858] [ks=14.365]\n",
      "9300 [D loss: 7.97664403915, acc.: 0.00%] [G loss: 0.00300660752691] [mll=88.765+-3.858] [ks=14.478]\n",
      "9400 [D loss: 7.97971868515, acc.: 0.00%] [G loss: 0.00300924945623] [mll=89.999+-3.887] [ks=14.360]\n",
      "9500 [D loss: 7.98168373108, acc.: 0.00%] [G loss: 0.00306304730475] [mll=90.250+-3.933] [ks=14.352]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "9600 [D loss: 7.97898769379, acc.: 0.00%] [G loss: 0.00322901643813] [mll=90.392+-3.881] [ks=14.360]\n",
      "9700 [D loss: 8.00454139709, acc.: 0.00%] [G loss: 0.00303117325529] [mll=90.989+-3.927] [ks=14.366]\n",
      "9800 [D loss: 7.97672319412, acc.: 0.00%] [G loss: 0.00303842290305] [mll=89.015+-3.868] [ks=14.466]\n",
      "9900 [D loss: 7.97617912292, acc.: 0.00%] [G loss: 0.00301780528389] [mll=89.108+-3.859] [ks=14.455]\n",
      "10000 [D loss: 7.97826528549, acc.: 0.00%] [G loss: 0.00302867195569] [mll=89.058+-3.849] [ks=14.465]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "10100 [D loss: 7.97556304932, acc.: 0.00%] [G loss: 0.00305315502919] [mll=89.026+-3.803] [ks=14.476]\n",
      "10200 [D loss: 7.97823095322, acc.: 0.00%] [G loss: 0.00301142735407] [mll=88.794+-3.797] [ks=14.496]\n",
      "10300 [D loss: 7.98174238205, acc.: 0.00%] [G loss: 0.00302580348216] [mll=89.286+-3.847] [ks=14.459]\n",
      "10400 [D loss: 7.97783279419, acc.: 0.00%] [G loss: 0.00298821157776] [mll=89.093+-3.855] [ks=14.472]\n",
      "10500 [D loss: 7.97733354568, acc.: 0.00%] [G loss: 0.00302637228742] [mll=89.630+-3.897] [ks=14.412]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "10600 [D loss: 7.97961902618, acc.: 0.00%] [G loss: 0.00299633084796] [mll=89.037+-3.819] [ks=14.481]\n",
      "10700 [D loss: 7.97638702393, acc.: 0.00%] [G loss: 0.00305148679763] [mll=90.142+-3.904] [ks=14.361]\n",
      "10800 [D loss: 7.97758722305, acc.: 0.00%] [G loss: 0.00311014638282] [mll=88.994+-3.794] [ks=14.481]\n",
      "10900 [D loss: 7.97728490829, acc.: 0.00%] [G loss: 0.00299052987248] [mll=88.496+-3.727] [ks=14.547]\n",
      "11000 [D loss: 8.014793396, acc.: 0.00%] [G loss: 0.00299194105901] [mll=89.792+-3.886] [ks=14.407]7]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "11100 [D loss: 7.9756360054, acc.: 0.00%] [G loss: 0.00300028198399] [mll=89.825+-3.889] [ks=14.399]]\n",
      "11200 [D loss: 7.97645425797, acc.: 0.00%] [G loss: 0.00298853032291] [mll=89.813+-3.883] [ks=14.405]\n",
      "11300 [D loss: 7.97877168655, acc.: 0.00%] [G loss: 0.00300111994147] [mll=89.677+-3.862] [ks=14.414]\n",
      "11400 [D loss: 7.98089313507, acc.: 0.00%] [G loss: 0.0030225997325] [mll=89.015+-3.822] [ks=14.490]]\n",
      "11500 [D loss: 7.98089981079, acc.: 0.00%] [G loss: 0.00299589987844] [mll=90.319+-3.975] [ks=14.368]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "11600 [D loss: 7.9769654274, acc.: 0.00%] [G loss: 0.00298945466056] [mll=89.576+-3.861] [ks=14.430]]\n",
      "11700 [D loss: 7.98238039017, acc.: 0.00%] [G loss: 0.00315432972275] [mll=89.707+-3.831] [ks=14.416]\n",
      "11800 [D loss: 7.97903394699, acc.: 0.00%] [G loss: 0.00307418056764] [mll=90.894+-3.955] [ks=14.373]\n",
      "11900 [D loss: 7.98135137558, acc.: 0.00%] [G loss: 0.00304584950209] [mll=88.798+-3.825] [ks=14.514]\n",
      "12000 [D loss: 7.98347759247, acc.: 0.00%] [G loss: 0.00298930867575] [mll=90.323+-3.903] [ks=14.374]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "12100 [D loss: 7.97524356842, acc.: 0.00%] [G loss: 0.00298784696497] [mll=89.734+-3.900] [ks=14.410]\n",
      "12200 [D loss: 7.97653007507, acc.: 0.00%] [G loss: 0.00299135013483] [mll=89.546+-3.854] [ks=14.430]\n",
      "12300 [D loss: 7.97686862946, acc.: 0.00%] [G loss: 0.00302261207253] [mll=89.534+-3.900] [ks=14.437]\n",
      "12400 [D loss: 7.97552394867, acc.: 0.00%] [G loss: 0.00301394471899] [mll=88.847+-3.797] [ks=14.511]\n",
      "12473 [D loss: 7.97665071487, acc.: 0.00%] [G loss: 0.00305032148026] [mll=90.077+-3.850] [ks=14.375]BREAKING because disc/gen loss has remained the same for 1/1001 epochs!\n",
      "Scaling jet pts\n",
      "Scaling lep isos\n",
      "Discriminator params: 161537\n",
      "Generator params: 340497\n",
      "scaling lepton isolations\n",
      "scaling jet pts\n",
      "100 [D loss: 0.417592793703, acc.: 0.00%] [G loss: 2.61370301247] [mll=-1.000+--1.000] [ks=999.000]\n",
      "KS score improved from 999.00 to 14.96, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_100.weights\n",
      "200 [D loss: 0.931889057159, acc.: 0.00%] [G loss: 5.15448331833] [mll=8.076+-0.935] [ks=14.957]\n",
      "KS score improved from 14.96 to 14.92, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_200.weights\n",
      "300 [D loss: 0.149842992425, acc.: 0.00%] [G loss: 6.17465400696] [mll=13.320+-1.256] [ks=14.923]]\n",
      "400 [D loss: 0.577594280243, acc.: 0.00%] [G loss: 6.42395687103] [mll=46.945+-4.599] [ks=14.975]]\n",
      "500 [D loss: 0.292371630669, acc.: 0.00%] [G loss: 6.95783948898] [mll=4.533+-2.089] [ks=15.194]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "KS score improved from 14.92 to 14.22, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_500.weights\n",
      "600 [D loss: 0.0915894955397, acc.: 0.00%] [G loss: 5.36636304855] [mll=69.514+-5.592] [ks=14.224]\n",
      "700 [D loss: 0.113237112761, acc.: 0.00%] [G loss: 5.024538517] [mll=62.793+-4.262] [ks=15.308]08]\n",
      "800 [D loss: 0.098196297884, acc.: 0.00%] [G loss: 5.31454086304] [mll=52.878+-3.598] [ks=15.456]]\n",
      "900 [D loss: 0.0589521899819, acc.: 0.00%] [G loss: 4.96546220779] [mll=69.462+-4.844] [ks=15.488]\n",
      "1000 [D loss: 0.0957651138306, acc.: 0.00%] [G loss: 4.12404966354] [mll=70.819+-4.121] [ks=15.274]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "1100 [D loss: 0.303910672665, acc.: 0.00%] [G loss: 5.91074800491] [mll=57.270+-4.148] [ks=14.669]]\n",
      "1200 [D loss: 0.032679118216, acc.: 0.00%] [G loss: 5.09557771683] [mll=33.251+-1.460] [ks=15.795]]\n",
      "KS score improved from 14.22 to 13.71, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_1200.weights\n",
      "1300 [D loss: 0.0801144763827, acc.: 0.00%] [G loss: 6.23475456238] [mll=79.283+-7.130] [ks=13.712]\n",
      "1400 [D loss: 0.0841717496514, acc.: 0.00%] [G loss: 5.25688505173] [mll=55.811+-3.909] [ks=15.049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 [D loss: 0.0520392209291, acc.: 0.00%] [G loss: 5.52059221268] [mll=54.130+-3.699] [ks=15.158]\n",
      "10000/10000 [==============================] - 1s 53us/step\n",
      "1600 [D loss: 0.0354265123606, acc.: 0.00%] [G loss: 5.36886644363] [mll=60.496+-3.448] [ks=14.397]\n",
      "1700 [D loss: 0.114809378982, acc.: 0.00%] [G loss: 3.12543821335] [mll=80.466+-3.990] [ks=13.734]]\n",
      "KS score improved from 13.71 to 13.61, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_1700.weights\n",
      "1800 [D loss: 0.0511783212423, acc.: 0.00%] [G loss: 4.78382253647] [mll=74.999+-9.419] [ks=13.607]\n",
      "1900 [D loss: 0.0528489015996, acc.: 0.00%] [G loss: 4.53350400925] [mll=90.542+-7.246] [ks=14.160]\n",
      "2000 [D loss: 0.151114925742, acc.: 0.00%] [G loss: 4.77079820633] [mll=79.591+-3.629] [ks=14.694]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "2100 [D loss: 0.181116729975, acc.: 0.00%] [G loss: 3.9755551815] [mll=78.871+-6.015] [ks=14.642]]]\n",
      "KS score improved from 13.61 to 12.93, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_2100.weights\n",
      "2200 [D loss: 0.306444227695, acc.: 0.00%] [G loss: 3.45030546188] [mll=44.323+-17.912] [ks=12.925]]\n",
      "KS score improved from 12.93 to 10.90, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_2200.weights\n",
      "2300 [D loss: 0.280299454927, acc.: 0.00%] [G loss: 3.36475157738] [mll=73.194+-4.451] [ks=10.899]]\n",
      "2400 [D loss: 0.197286456823, acc.: 0.00%] [G loss: 3.75600767136] [mll=133.618+-29.094] [ks=11.700]]\n",
      "KS score improved from 10.90 to 10.53, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_2400.weights\n",
      "2500 [D loss: 0.170969873667, acc.: 0.00%] [G loss: 2.99451804161] [mll=58.450+-15.511] [ks=10.531]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "KS score improved from 10.53 to 9.15, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_2500.weights\n",
      "2600 [D loss: 0.233245328069, acc.: 0.00%] [G loss: 2.38565325737] [mll=86.945+-19.401] [ks=9.153]]\n",
      "2700 [D loss: 0.224516808987, acc.: 0.00%] [G loss: 2.72642755508] [mll=97.025+-7.819] [ks=9.991]]\n",
      "2800 [D loss: 0.128891006112, acc.: 0.00%] [G loss: 3.24231743813] [mll=86.584+-14.191] [ks=9.214]]\n",
      "2900 [D loss: 0.143233016133, acc.: 0.00%] [G loss: 3.12769675255] [mll=68.927+-15.514] [ks=11.125]]\n",
      "3000 [D loss: 0.517374873161, acc.: 0.00%] [G loss: 2.06976699829] [mll=85.027+-15.541] [ks=11.435]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "3100 [D loss: 0.405088186264, acc.: 0.00%] [G loss: 1.94716525078] [mll=76.385+-15.044] [ks=9.550]]\n",
      "KS score improved from 9.15 to 8.79, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_3100.weights\n",
      "3200 [D loss: 0.372449815273, acc.: 0.00%] [G loss: 2.30444359779] [mll=98.413+-11.476] [ks=8.786]]\n",
      "3300 [D loss: 0.4507637918, acc.: 0.00%] [G loss: 2.08229088783] [mll=91.246+-9.323] [ks=9.620]0]]\n",
      "KS score improved from 8.79 to 8.06, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_3300.weights\n",
      "3400 [D loss: 0.53831756115, acc.: 0.00%] [G loss: 1.78993904591] [mll=89.871+-15.617] [ks=8.060]]\n",
      "KS score improved from 8.06 to 8.00, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_3400.weights\n",
      "3500 [D loss: 0.721205532551, acc.: 0.00%] [G loss: 1.93607985973] [mll=99.891+-9.179] [ks=7.995]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "3600 [D loss: 0.18398655951, acc.: 0.00%] [G loss: 2.27314782143] [mll=91.918+-10.123] [ks=8.212]]\n",
      "3700 [D loss: 0.309267729521, acc.: 0.00%] [G loss: 1.95236027241] [mll=89.192+-8.875] [ks=9.223]\n",
      "3800 [D loss: 0.251247465611, acc.: 0.00%] [G loss: 2.11005020142] [mll=92.355+-10.132] [ks=8.120]]\n",
      "3900 [D loss: 0.226207271218, acc.: 0.00%] [G loss: 2.33414769173] [mll=90.428+-8.207] [ks=11.124]]\n",
      "4000 [D loss: 1.13070499897, acc.: 0.00%] [G loss: 2.52602744102] [mll=94.575+-8.893] [ks=8.814]]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "4100 [D loss: 0.371634960175, acc.: 0.00%] [G loss: 2.24974536896] [mll=93.095+-7.936] [ks=8.761]\n",
      "KS score improved from 8.00 to 7.71, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_4100.weights\n",
      "4200 [D loss: 0.41322812438, acc.: 0.00%] [G loss: 1.80235671997] [mll=85.658+-9.123] [ks=7.709]]]\n",
      "4300 [D loss: 0.702172875404, acc.: 0.78%] [G loss: 1.68936157227] [mll=84.880+-9.878] [ks=7.953]]\n",
      "4400 [D loss: 0.187345564365, acc.: 0.00%] [G loss: 2.24381446838] [mll=127.335+-25.350] [ks=8.494]]\n",
      "4500 [D loss: 0.438222706318, acc.: 0.00%] [G loss: 1.98280525208] [mll=84.975+-9.152] [ks=9.835]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "KS score improved from 7.71 to 6.95, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_4500.weights\n",
      "4600 [D loss: 0.498924970627, acc.: 0.00%] [G loss: 1.71970665455] [mll=88.584+-10.021] [ks=6.946]]\n",
      "4700 [D loss: 0.60989934206, acc.: 0.00%] [G loss: 1.76996123791] [mll=97.918+-7.670] [ks=7.893]]\n",
      "4800 [D loss: 0.469886094332, acc.: 0.00%] [G loss: 1.99872875214] [mll=105.327+-9.918] [ks=8.531]\n",
      "4900 [D loss: 0.958377957344, acc.: 0.00%] [G loss: 1.73120975494] [mll=91.249+-8.331] [ks=8.185]\n",
      "5000 [D loss: 0.513726234436, acc.: 0.00%] [G loss: 1.47906196117] [mll=94.911+-10.782] [ks=8.800]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "5100 [D loss: 0.496052533388, acc.: 0.59%] [G loss: 1.57173538208] [mll=92.855+-7.616] [ks=8.196]\n",
      "5200 [D loss: 0.572356104851, acc.: 0.00%] [G loss: 1.35023617744] [mll=119.330+-25.664] [ks=7.227]\n",
      "5300 [D loss: 0.603301286697, acc.: 0.00%] [G loss: 1.45705401897] [mll=93.391+-6.811] [ks=6.988]\n",
      "5400 [D loss: 0.589347660542, acc.: 0.00%] [G loss: 1.43307852745] [mll=96.281+-7.550] [ks=7.699]\n",
      "5500 [D loss: 0.571292459965, acc.: 0.00%] [G loss: 1.37673664093] [mll=75.829+-14.748] [ks=7.559]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "5600 [D loss: 0.634081184864, acc.: 0.20%] [G loss: 1.33676445484] [mll=92.963+-9.408] [ks=8.180]\n",
      "5700 [D loss: 0.364478170872, acc.: 0.00%] [G loss: 2.33596682549] [mll=128.451+-32.404] [ks=8.681]\n",
      "5800 [D loss: 0.359647452831, acc.: 4.88%] [G loss: 4.30084991455] [mll=71.499+-11.804] [ks=8.760]\n",
      "5900 [D loss: 0.330730557442, acc.: 0.98%] [G loss: 6.83946323395] [mll=12.299+-4.451] [ks=13.007]\n",
      "6000 [D loss: 0.345417767763, acc.: 16.80%] [G loss: 6.54309129715] [mll=10.047+-6.432] [ks=12.682]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "6100 [D loss: 0.220565095544, acc.: 0.00%] [G loss: 6.60556697845] [mll=24.038+-20.540] [ks=11.279]]\n",
      "6200 [D loss: 0.25870475173, acc.: 0.59%] [G loss: 10.5236654282] [mll=33.137+-11.201] [ks=11.433]]\n",
      "6300 [D loss: 0.171041712165, acc.: 0.00%] [G loss: 7.5562582016] [mll=27.977+-12.711] [ks=10.550]]]\n",
      "6400 [D loss: 0.144166335464, acc.: 0.00%] [G loss: 5.41818904877] [mll=43.760+-17.689] [ks=10.042]]\n",
      "6500 [D loss: 0.291259229183, acc.: 0.00%] [G loss: 2.54407095909] [mll=74.655+-17.835] [ks=9.101]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "6600 [D loss: 0.380467861891, acc.: 0.00%] [G loss: 2.38003230095] [mll=94.537+-12.960] [ks=8.318]\n",
      "6700 [D loss: 0.269650936127, acc.: 0.00%] [G loss: 2.05372548103] [mll=90.322+-12.166] [ks=8.421]\n",
      "6800 [D loss: 0.452849388123, acc.: 0.00%] [G loss: 2.16819500923] [mll=89.487+-9.525] [ks=7.823]\n",
      "6900 [D loss: 0.627178668976, acc.: 0.20%] [G loss: 1.60460662842] [mll=92.507+-9.963] [ks=7.259]]\n",
      "KS score improved from 6.95 to 6.94, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_6900.weights\n",
      "7000 [D loss: 0.592463254929, acc.: 0.00%] [G loss: 1.58937978745] [mll=114.493+-27.416] [ks=6.937]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "KS score improved from 6.94 to 6.39, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_7000.weights\n",
      "7100 [D loss: 0.696107149124, acc.: 0.00%] [G loss: 1.27064192295] [mll=82.762+-22.138] [ks=6.389]\n",
      "7200 [D loss: 0.603542149067, acc.: 0.00%] [G loss: 1.28008544445] [mll=94.191+-9.031] [ks=6.580]\n",
      "KS score improved from 6.39 to 5.98, saving models to progress/jetisoscale_mllwidth_flatNegNoise_5/gen_7200.weights\n",
      "7300 [D loss: 0.670505404472, acc.: 0.00%] [G loss: 1.2019109726] [mll=94.850+-7.050] [ks=5.984]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7400 [D loss: 0.475203096867, acc.: 0.00%] [G loss: 1.15427482128] [mll=95.695+-11.108] [ks=7.487]]\n",
      "7500 [D loss: 0.50173419714, acc.: 0.00%] [G loss: 1.97593104839] [mll=88.163+-7.375] [ks=7.438]]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "7600 [D loss: 0.505082666874, acc.: 0.00%] [G loss: 7.96181488037] [mll=79.545+-10.345] [ks=7.752]\n",
      "7700 [D loss: 0.371441245079, acc.: 0.00%] [G loss: 6.60071277618] [mll=19.370+-3.706] [ks=15.003]\n",
      "7800 [D loss: 0.317417860031, acc.: 0.00%] [G loss: 7.53052473068] [mll=17.543+-14.978] [ks=13.221]\n",
      "7900 [D loss: 0.29347217083, acc.: 0.20%] [G loss: 8.33675098419] [mll=37.352+-23.385] [ks=10.635]]\n",
      "8000 [D loss: 0.337361305952, acc.: 0.98%] [G loss: 5.06802034378] [mll=37.799+-14.693] [ks=10.499]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "8100 [D loss: 0.485266625881, acc.: 0.00%] [G loss: 1.84310555458] [mll=60.499+-18.144] [ks=9.373]\n",
      "8200 [D loss: 0.546724319458, acc.: 0.00%] [G loss: 1.40710532665] [mll=84.303+-21.119] [ks=8.135]\n",
      "8300 [D loss: 0.65948933363, acc.: 0.00%] [G loss: 1.36560606956] [mll=95.733+-12.409] [ks=8.322]]\n",
      "8400 [D loss: 0.687086999416, acc.: 0.00%] [G loss: 1.08345353603] [mll=88.810+-10.984] [ks=7.630]\n",
      "8500 [D loss: 0.62452507019, acc.: 0.00%] [G loss: 1.03500068188] [mll=92.586+-9.147] [ks=6.738]]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "8600 [D loss: 0.703811168671, acc.: 0.20%] [G loss: 0.900235295296] [mll=93.478+-7.328] [ks=6.859]\n",
      "8700 [D loss: 0.67137748003, acc.: 0.00%] [G loss: 0.894410073757] [mll=93.653+-8.053] [ks=7.309]]\n",
      "8800 [D loss: 0.282279312611, acc.: 0.00%] [G loss: 7.63459682465] [mll=94.356+-6.113] [ks=7.666]]\n",
      "8900 [D loss: 0.285425752401, acc.: 0.00%] [G loss: 10.0890779495] [mll=21.117+-7.537] [ks=12.654]\n",
      "9000 [D loss: 0.256427556276, acc.: 2.34%] [G loss: 12.2536401749] [mll=19.370+-20.100] [ks=13.638]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "9100 [D loss: 0.0220797415823, acc.: 0.00%] [G loss: 16.1620483398] [mll=28.529+-21.903] [ks=10.327]\n",
      "9200 [D loss: 0.460205435753, acc.: 0.00%] [G loss: 1.51758956909] [mll=77.639+-13.897] [ks=9.461]]]\n",
      "9300 [D loss: 0.456743478775, acc.: 0.00%] [G loss: 1.37382173538] [mll=79.123+-12.130] [ks=8.641]\n",
      "9400 [D loss: 0.685288012028, acc.: 0.00%] [G loss: 1.11613190174] [mll=91.531+-10.992] [ks=7.929]\n",
      "9500 [D loss: 0.692846655846, acc.: 0.00%] [G loss: 0.908220291138] [mll=90.448+-9.010] [ks=7.578]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "9600 [D loss: 0.716734528542, acc.: 0.00%] [G loss: 0.852667868137] [mll=89.794+-7.297] [ks=7.286]\n",
      "9700 [D loss: 0.722517132759, acc.: 0.20%] [G loss: 0.829740524292] [mll=91.574+-6.605] [ks=7.303]\n",
      "9800 [D loss: 0.697602152824, acc.: 0.00%] [G loss: 0.839192271233] [mll=93.371+-9.076] [ks=8.220]\n",
      "9900 [D loss: 0.692899227142, acc.: 0.00%] [G loss: 0.801667273045] [mll=89.012+-5.349] [ks=7.004]\n",
      "10000 [D loss: 0.712661266327, acc.: 0.00%] [G loss: 0.796656668186] [mll=91.464+-7.570] [ks=7.844]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "10100 [D loss: 0.71309030056, acc.: 0.00%] [G loss: 0.759291231632] [mll=90.676+-5.681] [ks=7.418]]\n",
      "10200 [D loss: 0.70838111639, acc.: 0.00%] [G loss: 0.754948139191] [mll=89.524+-6.189] [ks=7.904]]\n",
      "10300 [D loss: 0.305427163839, acc.: 0.00%] [G loss: 6.26927518845] [mll=93.014+-5.699] [ks=7.952]]\n",
      "10400 [D loss: 0.287037134171, acc.: 0.39%] [G loss: 9.53859615326] [mll=24.745+-6.028] [ks=11.728]\n",
      "10500 [D loss: 0.176394075155, acc.: 0.78%] [G loss: 8.67090320587] [mll=47.691+-22.229] [ks=11.971]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "10600 [D loss: 0.139217555523, acc.: 0.39%] [G loss: 10.2468481064] [mll=41.530+-15.624] [ks=11.523]\n",
      "10700 [D loss: 0.164951682091, acc.: 0.20%] [G loss: 8.38660144806] [mll=44.207+-12.835] [ks=11.390]\n",
      "10800 [D loss: 0.126447975636, acc.: 0.00%] [G loss: 10.6183252335] [mll=51.969+-16.671] [ks=10.784]]\n",
      "10900 [D loss: 0.152828246355, acc.: 0.00%] [G loss: 8.01760196686] [mll=59.950+-14.848] [ks=10.747]]\n",
      "11000 [D loss: 0.596676528454, acc.: 0.00%] [G loss: 1.13560593128] [mll=66.351+-14.352] [ks=10.515]]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "11100 [D loss: 0.549817800522, acc.: 0.00%] [G loss: 1.26796925068] [mll=100.497+-14.673] [ks=8.850]\n",
      "11200 [D loss: 0.6843110919, acc.: 0.00%] [G loss: 0.901401102543] [mll=92.732+-8.848] [ks=8.468]8]\n",
      "11300 [D loss: 0.622742176056, acc.: 0.00%] [G loss: 0.850630819798] [mll=91.746+-7.351] [ks=7.771]\n",
      "11400 [D loss: 0.703193187714, acc.: 0.00%] [G loss: 0.836776852608] [mll=89.653+-7.055] [ks=7.734]\n",
      "11500 [D loss: 0.642185628414, acc.: 0.00%] [G loss: 0.81897932291] [mll=91.337+-6.671] [ks=7.590]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "11600 [D loss: 0.73459148407, acc.: 0.98%] [G loss: 0.840863347054] [mll=91.651+-10.544] [ks=7.772]]\n",
      "11700 [D loss: 0.683831512928, acc.: 0.00%] [G loss: 0.872386932373] [mll=91.104+-24.904] [ks=7.846]\n",
      "11800 [D loss: 0.292909413576, acc.: 0.00%] [G loss: 5.41298866272] [mll=92.097+-6.606] [ks=7.614]]\n",
      "11900 [D loss: 0.118866302073, acc.: 0.00%] [G loss: 12.8316793442] [mll=48.107+-9.128] [ks=11.709]\n",
      "12000 [D loss: 0.295702755451, acc.: 0.00%] [G loss: 4.10568189621] [mll=51.742+-15.479] [ks=11.280]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "12100 [D loss: 0.117796212435, acc.: 0.00%] [G loss: 8.56293106079] [mll=58.800+-13.634] [ks=11.186]]\n",
      "12200 [D loss: 0.15357363224, acc.: 0.00%] [G loss: 8.82343196869] [mll=52.312+-11.861] [ks=11.272]]]\n",
      "12300 [D loss: 0.236893385649, acc.: 0.00%] [G loss: 6.72227525711] [mll=54.805+-13.449] [ks=11.182]]\n",
      "12400 [D loss: 0.647152841091, acc.: 0.00%] [G loss: 0.992118835449] [mll=68.593+-17.211] [ks=10.213]\n",
      "12500 [D loss: 0.652613818645, acc.: 0.00%] [G loss: 0.982401788235] [mll=93.269+-10.217] [ks=8.406]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "12600 [D loss: 0.727358281612, acc.: 0.20%] [G loss: 0.850235521793] [mll=90.593+-7.119] [ks=7.947]\n",
      "12700 [D loss: 0.683506608009, acc.: 0.00%] [G loss: 0.795918047428] [mll=91.971+-7.426] [ks=8.250]\n",
      "12800 [D loss: 0.687940359116, acc.: 0.00%] [G loss: 0.776537060738] [mll=89.040+-5.843] [ks=7.966]\n",
      "12900 [D loss: 0.700824975967, acc.: 0.00%] [G loss: 0.761608719826] [mll=89.935+-6.066] [ks=7.946]\n",
      "13000 [D loss: 0.870629251003, acc.: 0.00%] [G loss: 0.75161254406] [mll=89.641+-5.375] [ks=7.789]]\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "13100 [D loss: 0.719858646393, acc.: 0.00%] [G loss: 0.741828978062] [mll=89.617+-4.860] [ks=7.998]\n",
      "13200 [D loss: 0.703012704849, acc.: 0.00%] [G loss: 0.750910043716] [mll=90.287+-5.108] [ks=7.739]\n",
      "13300 [D loss: 0.711800336838, acc.: 0.00%] [G loss: 0.759099423885] [mll=89.205+-5.742] [ks=7.985]\n",
      "13400 [D loss: 0.713698863983, acc.: 0.00%] [G loss: 0.761206567287] [mll=89.679+-4.909] [ks=8.012]\n",
      "13500 [D loss: 0.695925176144, acc.: 0.00%] [G loss: 0.740828573704] [mll=89.802+-5.706] [ks=7.757]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "13600 [D loss: 0.691340088844, acc.: 0.00%] [G loss: 0.733705103397] [mll=89.830+-5.340] [ks=7.988]\n",
      "13700 [D loss: 0.707754850388, acc.: 0.20%] [G loss: 0.736838698387] [mll=90.433+-6.490] [ks=8.358]\n",
      "13800 [D loss: 0.702777266502, acc.: 0.00%] [G loss: 0.732033133507] [mll=89.205+-5.006] [ks=7.919]\n",
      "13900 [D loss: 0.634515702724, acc.: 0.00%] [G loss: 0.821988165379] [mll=89.168+-5.086] [ks=7.920]\n",
      "14000 [D loss: 0.706915140152, acc.: 0.00%] [G loss: 0.748554587364] [mll=84.497+-6.805] [ks=9.822]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "14100 [D loss: 0.69984292984, acc.: 0.00%] [G loss: 0.733297109604] [mll=89.414+-4.937] [ks=7.648]]\n",
      "14200 [D loss: 0.704039335251, acc.: 0.00%] [G loss: 0.721004545689] [mll=88.947+-4.839] [ks=7.996]\n",
      "14300 [D loss: 0.701190233231, acc.: 0.00%] [G loss: 0.719619333744] [mll=84.768+-10.749] [ks=8.229]\n",
      "14400 [D loss: 0.697912991047, acc.: 0.00%] [G loss: 0.721311151981] [mll=90.439+-4.839] [ks=7.836]\n",
      "14500 [D loss: 0.709276914597, acc.: 0.00%] [G loss: 0.7148193717] [mll=89.386+-4.825] [ks=8.027]]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14600 [D loss: 0.704327702522, acc.: 0.00%] [G loss: 0.729191720486] [mll=89.306+-4.754] [ks=7.642]\n",
      "14700 [D loss: 0.70255792141, acc.: 0.00%] [G loss: 0.729280412197] [mll=89.428+-5.526] [ks=8.014]]\n",
      "14800 [D loss: 0.701068818569, acc.: 0.00%] [G loss: 0.716749191284] [mll=89.826+-5.070] [ks=7.612]\n",
      "14900 [D loss: 0.701082229614, acc.: 0.00%] [G loss: 0.709774374962] [mll=89.445+-4.370] [ks=7.773]\n",
      "15000 [D loss: 0.703158378601, acc.: 0.00%] [G loss: 0.711762487888] [mll=89.823+-4.406] [ks=7.610]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "15100 [D loss: 0.7008279562, acc.: 0.00%] [G loss: 0.717368662357] [mll=89.689+-4.497] [ks=7.459]9]\n",
      "15200 [D loss: 0.704186558723, acc.: 0.00%] [G loss: 0.70673429966] [mll=89.596+-4.445] [ks=7.506]]\n",
      "15300 [D loss: 0.699190855026, acc.: 0.00%] [G loss: 0.710054934025] [mll=89.303+-4.938] [ks=7.593]\n",
      "15400 [D loss: 0.7138697505, acc.: 0.00%] [G loss: 0.717558801174] [mll=89.690+-4.329] [ks=7.695]5]\n",
      "15500 [D loss: 0.701491057873, acc.: 0.00%] [G loss: 0.71310043335] [mll=89.984+-4.700] [ks=8.300]]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "15600 [D loss: 0.700168013573, acc.: 0.00%] [G loss: 0.712987363338] [mll=90.867+-4.963] [ks=7.609]\n",
      "15700 [D loss: 0.757890701294, acc.: 0.20%] [G loss: 0.815568506718] [mll=89.667+-4.047] [ks=8.144]\n",
      "15800 [D loss: 0.700899362564, acc.: 0.00%] [G loss: 0.707615494728] [mll=99.159+-22.390] [ks=7.970]\n",
      "15900 [D loss: 0.699743211269, acc.: 0.00%] [G loss: 0.708770811558] [mll=88.617+-5.037] [ks=7.479]\n",
      "16000 [D loss: 0.70366871357, acc.: 0.00%] [G loss: 0.710869431496] [mll=89.548+-4.318] [ks=7.838]]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "16100 [D loss: 0.703375697136, acc.: 0.00%] [G loss: 0.707246899605] [mll=90.244+-4.640] [ks=8.187]\n",
      "16200 [D loss: 0.704899072647, acc.: 0.00%] [G loss: 0.710521638393] [mll=89.822+-4.381] [ks=7.805]\n",
      "16300 [D loss: 0.709945499897, acc.: 0.00%] [G loss: 0.706655919552] [mll=89.835+-4.414] [ks=7.829]\n",
      "16400 [D loss: 0.700752735138, acc.: 0.00%] [G loss: 0.706133842468] [mll=89.310+-4.535] [ks=7.783]\n",
      "16500 [D loss: 0.70423167944, acc.: 0.00%] [G loss: 0.703865468502] [mll=90.030+-4.222] [ks=7.786]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "16600 [D loss: 0.709015011787, acc.: 0.00%] [G loss: 0.703528940678] [mll=89.797+-4.408] [ks=7.788]\n",
      "16700 [D loss: 0.698734045029, acc.: 0.00%] [G loss: 0.702317237854] [mll=89.166+-4.048] [ks=7.826]\n",
      "16800 [D loss: 0.709515690804, acc.: 0.00%] [G loss: 0.700591683388] [mll=84.927+-9.973] [ks=7.914]\n",
      "16900 [D loss: 0.705159246922, acc.: 0.00%] [G loss: 0.708585143089] [mll=89.663+-4.484] [ks=7.540]\n",
      "17000 [D loss: 0.699231564999, acc.: 0.00%] [G loss: 0.705935895443] [mll=91.390+-18.680] [ks=7.857]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "17100 [D loss: 0.701187133789, acc.: 0.00%] [G loss: 0.705139398575] [mll=89.779+-4.263] [ks=7.654]\n",
      "17200 [D loss: 0.697347283363, acc.: 0.00%] [G loss: 0.714873254299] [mll=89.185+-4.283] [ks=7.571]\n",
      "17300 [D loss: 0.702556610107, acc.: 0.00%] [G loss: 0.712091505527] [mll=90.254+-4.022] [ks=7.660]\n",
      "17400 [D loss: 0.702218770981, acc.: 0.00%] [G loss: 0.708241999149] [mll=89.634+-4.412] [ks=7.547]\n",
      "17500 [D loss: 0.701725661755, acc.: 0.00%] [G loss: 0.70412582159] [mll=89.420+-4.242] [ks=7.530]]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "17600 [D loss: 0.704085171223, acc.: 0.00%] [G loss: 0.702780485153] [mll=89.052+-4.130] [ks=7.603]\n",
      "17700 [D loss: 0.700093150139, acc.: 0.00%] [G loss: 0.707913935184] [mll=89.293+-4.200] [ks=7.783]\n",
      "17800 [D loss: 0.707890272141, acc.: 0.00%] [G loss: 0.7022985816] [mll=90.028+-4.428] [ks=8.010]0]\n",
      "17900 [D loss: 0.707776427269, acc.: 0.00%] [G loss: 0.735752522945] [mll=87.268+-4.612] [ks=7.987]\n",
      "18000 [D loss: 0.701222538948, acc.: 0.00%] [G loss: 0.707222223282] [mll=86.506+-9.368] [ks=7.753]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "18100 [D loss: 0.69664978981, acc.: 0.00%] [G loss: 0.705356955528] [mll=89.601+-4.214] [ks=7.878]]\n",
      "18200 [D loss: 0.701861858368, acc.: 0.00%] [G loss: 0.701874792576] [mll=89.385+-5.305] [ks=8.452]\n",
      "18300 [D loss: 0.79998666048, acc.: 0.00%] [G loss: 0.706112742424] [mll=90.278+-4.406] [ks=7.512]]\n",
      "18400 [D loss: 0.702233791351, acc.: 0.00%] [G loss: 0.703738212585] [mll=89.918+-4.876] [ks=8.137]\n",
      "18500 [D loss: 0.699895143509, acc.: 0.00%] [G loss: 0.700234055519] [mll=89.240+-4.155] [ks=7.669]\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "18600 [D loss: 0.701830148697, acc.: 0.00%] [G loss: 0.705792546272] [mll=89.903+-4.426] [ks=7.915]\n",
      "18700 [D loss: 0.702440619469, acc.: 0.00%] [G loss: 0.705022454262] [mll=89.835+-4.389] [ks=7.783]\n",
      "18800 [D loss: 0.701052188873, acc.: 0.00%] [G loss: 0.708957910538] [mll=89.851+-4.864] [ks=8.160]\n",
      "18900 [D loss: 0.703671216965, acc.: 0.00%] [G loss: 0.70414596796] [mll=90.201+-4.940] [ks=7.637]]\n",
      "19000 [D loss: 0.792580842972, acc.: 0.00%] [G loss: 0.705340743065] [mll=89.317+-4.209] [ks=7.683]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "19100 [D loss: 0.701420068741, acc.: 0.00%] [G loss: 0.70374828577] [mll=90.183+-4.036] [ks=7.692]]\n",
      "19200 [D loss: 0.721409082413, acc.: 0.00%] [G loss: 0.703318655491] [mll=89.123+-4.128] [ks=7.771]\n",
      "19300 [D loss: 0.706040680408, acc.: 0.00%] [G loss: 0.70276504755] [mll=89.544+-4.353] [ks=7.853]]\n",
      "19400 [D loss: 0.725363969803, acc.: 0.00%] [G loss: 0.739028930664] [mll=88.823+-4.292] [ks=7.394]\n",
      "19500 [D loss: 0.705186128616, acc.: 0.00%] [G loss: 0.704583644867] [mll=91.001+-5.811] [ks=7.925]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "19600 [D loss: 0.705388784409, acc.: 0.00%] [G loss: 0.70917057991] [mll=89.779+-3.871] [ks=7.507]]\n",
      "19700 [D loss: 0.702813863754, acc.: 0.00%] [G loss: 0.738763689995] [mll=89.719+-4.174] [ks=7.578]\n",
      "19800 [D loss: 0.725060462952, acc.: 0.20%] [G loss: 0.742414414883] [mll=89.811+-4.293] [ks=7.200]\n",
      "19900 [D loss: 0.701124966145, acc.: 0.00%] [G loss: 0.707247972488] [mll=94.525+-10.237] [ks=8.429]\n",
      "20000 [D loss: 0.74971729517, acc.: 0.00%] [G loss: 0.711172521114] [mll=90.093+-6.327] [ks=8.260]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "20100 [D loss: 0.737125694752, acc.: 0.00%] [G loss: 0.705639898777] [mll=89.353+-4.052] [ks=7.570]\n",
      "20200 [D loss: 0.611754417419, acc.: 0.00%] [G loss: 1.184897542] [mll=89.395+-4.128] [ks=7.807]07]\n",
      "20300 [D loss: 0.702654838562, acc.: 0.00%] [G loss: 0.722507417202] [mll=87.166+-5.649] [ks=10.030]\n",
      "20400 [D loss: 0.728101968765, acc.: 1.76%] [G loss: 0.762576460838] [mll=90.470+-5.361] [ks=7.465]\n",
      "20500 [D loss: 0.706013560295, acc.: 0.00%] [G loss: 0.720931589603] [mll=88.827+-19.101] [ks=7.950]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "20600 [D loss: 0.700661301613, acc.: 0.00%] [G loss: 0.71101385355] [mll=90.622+-4.738] [ks=7.650]]\n",
      "20700 [D loss: 0.705267190933, acc.: 0.00%] [G loss: 0.707331895828] [mll=90.298+-4.789] [ks=8.228]\n",
      "20800 [D loss: 0.706424236298, acc.: 0.00%] [G loss: 0.710298597813] [mll=90.612+-4.249] [ks=7.684]\n",
      "20900 [D loss: 0.698668539524, acc.: 0.00%] [G loss: 0.710323750973] [mll=89.708+-4.532] [ks=7.114]\n",
      "21000 [D loss: 0.703314781189, acc.: 0.00%] [G loss: 0.702950537205] [mll=89.634+-4.552] [ks=8.159]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "21100 [D loss: 0.713888704777, acc.: 0.00%] [G loss: 0.703917503357] [mll=89.200+-4.246] [ks=8.026]\n",
      "21200 [D loss: 0.703138947487, acc.: 0.00%] [G loss: 0.702873170376] [mll=89.078+-4.459] [ks=7.553]\n",
      "21300 [D loss: 0.706370294094, acc.: 0.00%] [G loss: 0.703670442104] [mll=89.556+-4.497] [ks=7.454]\n",
      "21400 [D loss: 0.704622805119, acc.: 0.00%] [G loss: 0.71298879385] [mll=84.950+-7.362] [ks=7.941]]\n",
      "21500 [D loss: 0.701837539673, acc.: 0.00%] [G loss: 0.705383419991] [mll=83.914+-12.346] [ks=7.835]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "21600 [D loss: 0.705090403557, acc.: 0.00%] [G loss: 0.706427633762] [mll=89.820+-4.178] [ks=7.594]\n",
      "21700 [D loss: 0.703845322132, acc.: 0.00%] [G loss: 0.72769266367] [mll=89.509+-4.660] [ks=7.621]]\n",
      "21800 [D loss: 0.702321410179, acc.: 0.00%] [G loss: 0.712803244591] [mll=89.918+-4.478] [ks=8.228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21900 [D loss: 0.703327178955, acc.: 0.00%] [G loss: 0.707821846008] [mll=89.040+-4.402] [ks=7.590]\n",
      "22000 [D loss: 0.701475381851, acc.: 0.00%] [G loss: 0.708820283413] [mll=89.864+-4.236] [ks=7.689]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "22100 [D loss: 0.710734128952, acc.: 0.00%] [G loss: 0.724276602268] [mll=90.859+-5.228] [ks=8.323]\n",
      "22200 [D loss: 0.700624465942, acc.: 0.00%] [G loss: 0.709187626839] [mll=89.272+-4.321] [ks=7.807]\n",
      "22300 [D loss: 0.681262969971, acc.: 0.00%] [G loss: 0.718971848488] [mll=90.059+-4.151] [ks=7.590]\n",
      "22400 [D loss: 0.707994222641, acc.: 0.00%] [G loss: 0.714367926121] [mll=90.916+-4.815] [ks=8.403]\n",
      "22500 [D loss: 0.707648277283, acc.: 0.00%] [G loss: 0.706982076168] [mll=89.018+-4.414] [ks=7.642]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "22600 [D loss: 0.705088198185, acc.: 0.00%] [G loss: 0.70991653204] [mll=89.476+-4.363] [ks=7.822]]\n",
      "22700 [D loss: 0.662792563438, acc.: 0.00%] [G loss: 0.783995866776] [mll=87.638+-13.127] [ks=7.634]\n",
      "22800 [D loss: 0.703631401062, acc.: 0.00%] [G loss: 0.731055676937] [mll=91.312+-4.535] [ks=8.539]\n",
      "22900 [D loss: 0.705107033253, acc.: 0.00%] [G loss: 0.710463941097] [mll=90.430+-4.923] [ks=7.419]\n",
      "23000 [D loss: 0.749810695648, acc.: 2.54%] [G loss: 0.799633622169] [mll=88.935+-4.398] [ks=7.933]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "23100 [D loss: 0.703771948814, acc.: 0.00%] [G loss: 0.703336119652] [mll=93.117+-11.704] [ks=8.124]\n",
      "23200 [D loss: 0.706507623196, acc.: 0.00%] [G loss: 0.700377941132] [mll=88.726+-4.047] [ks=7.862]\n",
      "23300 [D loss: 0.702710330486, acc.: 0.00%] [G loss: 0.700848519802] [mll=89.554+-4.416] [ks=7.567]\n",
      "23400 [D loss: 0.710959255695, acc.: 0.00%] [G loss: 0.702139616013] [mll=89.535+-4.452] [ks=7.707]\n",
      "23500 [D loss: 0.701375007629, acc.: 0.00%] [G loss: 0.705387711525] [mll=89.637+-4.488] [ks=7.798]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "23600 [D loss: 0.709669351578, acc.: 0.00%] [G loss: 0.702534258366] [mll=89.996+-3.781] [ks=7.722]\n",
      "23700 [D loss: 0.710860133171, acc.: 0.00%] [G loss: 0.711280405521] [mll=89.806+-3.937] [ks=7.154]\n",
      "23800 [D loss: 0.705807089806, acc.: 0.00%] [G loss: 0.709591925144] [mll=90.137+-3.903] [ks=7.593]\n",
      "23900 [D loss: 0.703837156296, acc.: 0.00%] [G loss: 0.706378400326] [mll=88.705+-4.365] [ks=7.743]\n",
      "24000 [D loss: 0.71488571167, acc.: 0.00%] [G loss: 0.743872523308] [mll=87.816+-5.229] [ks=7.946]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "24100 [D loss: 0.697379291058, acc.: 0.00%] [G loss: 0.707219541073] [mll=84.383+-6.870] [ks=7.559]\n",
      "24200 [D loss: 0.701034188271, acc.: 0.00%] [G loss: 0.703277170658] [mll=90.018+-5.614] [ks=7.732]\n",
      "24300 [D loss: 0.7002851367, acc.: 0.00%] [G loss: 0.704023599625] [mll=90.192+-4.170] [ks=7.713]3]\n",
      "24400 [D loss: 0.714877843857, acc.: 0.00%] [G loss: 0.705970346928] [mll=89.840+-3.654] [ks=7.178]\n",
      "24500 [D loss: 0.713677346706, acc.: 0.39%] [G loss: 0.728429853916] [mll=89.176+-4.216] [ks=7.074]\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "24600 [D loss: 0.700516462326, acc.: 0.00%] [G loss: 0.708792746067] [mll=92.636+-12.353] [ks=7.651]\n",
      "24700 [D loss: 0.710287332535, acc.: 0.00%] [G loss: 0.799737989902] [mll=89.240+-4.276] [ks=7.871]\n",
      "24800 [D loss: 0.702130794525, acc.: 0.00%] [G loss: 0.711509644985] [mll=90.889+-5.598] [ks=8.128]\n",
      "24900 [D loss: 0.704373240471, acc.: 0.00%] [G loss: 0.707537412643] [mll=89.324+-4.150] [ks=7.719]\n",
      "25000 [D loss: 0.702429711819, acc.: 0.00%] [G loss: 0.701960146427] [mll=89.618+-4.312] [ks=7.432]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "25100 [D loss: 0.708514392376, acc.: 0.00%] [G loss: 0.7240691185] [mll=89.147+-3.812] [ks=7.245]5]\n",
      "25200 [D loss: 0.704407811165, acc.: 0.00%] [G loss: 0.703288793564] [mll=85.883+-10.413] [ks=7.554]\n",
      "25300 [D loss: 0.704377293587, acc.: 0.00%] [G loss: 0.70116174221] [mll=90.264+-3.869] [ks=7.163]]\n",
      "25400 [D loss: 0.701629042625, acc.: 0.00%] [G loss: 0.701895833015] [mll=89.990+-3.831] [ks=7.075]\n",
      "25500 [D loss: 0.701086640358, acc.: 0.00%] [G loss: 0.709717810154] [mll=89.861+-4.341] [ks=7.255]\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "25600 [D loss: 0.70808082819, acc.: 0.00%] [G loss: 0.701080441475] [mll=91.087+-4.630] [ks=7.818]]\n",
      "25700 [D loss: 0.706639766693, acc.: 0.00%] [G loss: 0.70216012001] [mll=89.478+-4.277] [ks=7.629]]\n",
      "25800 [D loss: 0.707719802856, acc.: 0.00%] [G loss: 0.701701521873] [mll=90.072+-3.918] [ks=7.759]\n",
      "25900 [D loss: 0.703380405903, acc.: 0.00%] [G loss: 0.706198453903] [mll=91.599+-4.579] [ks=7.932]\n",
      "26000 [D loss: 0.70406973362, acc.: 0.00%] [G loss: 0.701766073704] [mll=89.505+-4.025] [ks=7.340]]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "26100 [D loss: 0.630602240562, acc.: 0.00%] [G loss: 0.719868600368] [mll=89.453+-3.741] [ks=7.276]\n",
      "26200 [D loss: 0.708413243294, acc.: 0.00%] [G loss: 0.721239447594] [mll=90.710+-5.972] [ks=8.876]\n",
      "26300 [D loss: 0.73949021101, acc.: 0.00%] [G loss: 0.707833230495] [mll=89.869+-4.138] [ks=7.577]]\n",
      "26400 [D loss: 0.717770338058, acc.: 0.00%] [G loss: 0.699719309807] [mll=89.693+-3.957] [ks=8.172]\n",
      "26500 [D loss: 0.709572732449, acc.: 0.00%] [G loss: 0.70268291235] [mll=89.231+-4.245] [ks=7.743]]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "26600 [D loss: 0.703635692596, acc.: 0.00%] [G loss: 0.703206539154] [mll=90.956+-4.719] [ks=7.811]\n",
      "26700 [D loss: 0.7010191679, acc.: 0.00%] [G loss: 0.701522827148] [mll=89.361+-4.862] [ks=7.661]1]\n",
      "26800 [D loss: 0.701577484608, acc.: 0.00%] [G loss: 0.705023407936] [mll=89.416+-4.111] [ks=7.475]\n",
      "26900 [D loss: 0.707373976707, acc.: 0.00%] [G loss: 0.7003698349] [mll=89.845+-4.218] [ks=7.650]0]\n",
      "27000 [D loss: 0.704037666321, acc.: 0.00%] [G loss: 0.704477787018] [mll=89.458+-3.814] [ks=7.961]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "27100 [D loss: 0.70224404335, acc.: 0.00%] [G loss: 0.703716814518] [mll=90.137+-3.851] [ks=8.004]]\n",
      "27200 [D loss: 0.70280122757, acc.: 0.00%] [G loss: 0.701287209988] [mll=88.900+-3.865] [ks=7.777]]\n",
      "27300 [D loss: 0.702870965004, acc.: 0.00%] [G loss: 0.703213334084] [mll=90.233+-4.235] [ks=7.539]\n",
      "27400 [D loss: 0.699207246304, acc.: 0.00%] [G loss: 0.703936576843] [mll=89.832+-4.258] [ks=7.724]\n",
      "27500 [D loss: 0.706435084343, acc.: 0.00%] [G loss: 0.704291284084] [mll=89.731+-4.052] [ks=7.888]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "27600 [D loss: 0.70373916626, acc.: 0.00%] [G loss: 0.706283330917] [mll=89.631+-4.310] [ks=7.619]]\n",
      "27700 [D loss: 0.701203107834, acc.: 0.00%] [G loss: 0.70278352499] [mll=93.264+-7.361] [ks=8.184]]\n",
      "27800 [D loss: 0.708089828491, acc.: 0.00%] [G loss: 0.725391924381] [mll=89.714+-4.084] [ks=7.787]\n",
      "27900 [D loss: 0.699131429195, acc.: 0.00%] [G loss: 0.705204486847] [mll=90.317+-6.415] [ks=8.201]\n",
      "28000 [D loss: 0.706485927105, acc.: 0.00%] [G loss: 0.701438367367] [mll=90.184+-3.694] [ks=7.821]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "28100 [D loss: 0.707454383373, acc.: 0.00%] [G loss: 0.706490576267] [mll=89.872+-3.888] [ks=7.452]\n",
      "28200 [D loss: 0.711589634418, acc.: 0.20%] [G loss: 0.715449392796] [mll=92.459+-6.416] [ks=7.619]\n",
      "28300 [D loss: 0.706211447716, acc.: 0.00%] [G loss: 0.703412175179] [mll=93.151+-12.169] [ks=7.660]\n",
      "28400 [D loss: 0.703450322151, acc.: 0.00%] [G loss: 0.710250020027] [mll=89.073+-4.121] [ks=7.659]\n",
      "28500 [D loss: 0.711107850075, acc.: 0.00%] [G loss: 0.703515470028] [mll=91.713+-9.591] [ks=8.046]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "28600 [D loss: 0.707508802414, acc.: 0.00%] [G loss: 0.703602850437] [mll=89.316+-3.866] [ks=7.339]\n",
      "28700 [D loss: 0.714188098907, acc.: 0.00%] [G loss: 0.701903939247] [mll=88.923+-4.072] [ks=7.594]\n",
      "28800 [D loss: 0.669900417328, acc.: 0.00%] [G loss: 0.760583937168] [mll=93.893+-7.612] [ks=7.611]\n",
      "28900 [D loss: 0.697313904762, acc.: 0.00%] [G loss: 0.706780910492] [mll=90.203+-5.119] [ks=8.193]\n",
      "29000 [D loss: 0.700617551804, acc.: 0.00%] [G loss: 0.705870687962] [mll=89.076+-3.977] [ks=7.952]\n",
      "10000/10000 [==============================] - 0s 39us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29100 [D loss: 0.703477621078, acc.: 0.00%] [G loss: 0.701275765896] [mll=90.731+-7.234] [ks=7.588]\n",
      "29200 [D loss: 0.795669317245, acc.: 0.00%] [G loss: 0.703700125217] [mll=89.091+-4.913] [ks=8.001]\n",
      "29300 [D loss: 0.704116940498, acc.: 0.00%] [G loss: 0.703828752041] [mll=89.792+-3.917] [ks=7.723]\n",
      "29400 [D loss: 0.701603293419, acc.: 0.00%] [G loss: 0.74785220623] [mll=90.113+-3.836] [ks=7.587]]\n",
      "29500 [D loss: 0.707288324833, acc.: 0.00%] [G loss: 0.708042085171] [mll=90.140+-5.016] [ks=7.622]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "29600 [D loss: 0.704044222832, acc.: 0.00%] [G loss: 0.705066800117] [mll=89.241+-4.105] [ks=7.555]\n",
      "29700 [D loss: 0.704377293587, acc.: 0.00%] [G loss: 0.704105019569] [mll=90.001+-4.418] [ks=7.583]\n",
      "29800 [D loss: 0.688271284103, acc.: 0.00%] [G loss: 0.747160315514] [mll=90.029+-4.022] [ks=7.335]\n",
      "29900 [D loss: 0.701583206654, acc.: 0.00%] [G loss: 0.709289908409] [mll=90.305+-5.498] [ks=8.055]\n",
      "30000 [D loss: 0.710812807083, acc.: 0.00%] [G loss: 0.705704331398] [mll=89.326+-4.276] [ks=7.625]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "30100 [D loss: 0.704617738724, acc.: 0.00%] [G loss: 0.703535079956] [mll=89.425+-3.755] [ks=7.864]\n",
      "30200 [D loss: 0.702221632004, acc.: 0.00%] [G loss: 0.704080104828] [mll=88.090+-4.144] [ks=7.561]\n",
      "30300 [D loss: 0.702882409096, acc.: 0.00%] [G loss: 0.703497648239] [mll=89.554+-4.138] [ks=7.601]\n",
      "30400 [D loss: 0.70310240984, acc.: 0.00%] [G loss: 0.706459879875] [mll=89.511+-4.068] [ks=7.783]]\n",
      "30500 [D loss: 0.701974034309, acc.: 0.00%] [G loss: 0.703438520432] [mll=89.560+-4.407] [ks=7.832]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "30600 [D loss: 0.717044174671, acc.: 0.00%] [G loss: 0.709687709808] [mll=89.313+-3.876] [ks=7.395]\n",
      "30700 [D loss: 0.707368016243, acc.: 0.00%] [G loss: 0.704371392727] [mll=90.107+-5.298] [ks=8.210]\n",
      "30800 [D loss: 0.710013270378, acc.: 0.00%] [G loss: 0.716521322727] [mll=90.027+-3.868] [ks=7.528]\n",
      "30900 [D loss: 0.722813725471, acc.: 0.00%] [G loss: 0.704818189144] [mll=90.549+-4.287] [ks=8.067]\n",
      "31000 [D loss: 0.700954675674, acc.: 0.00%] [G loss: 0.705234587193] [mll=88.123+-4.339] [ks=7.603]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "31100 [D loss: 0.705009818077, acc.: 0.00%] [G loss: 0.710178852081] [mll=90.055+-4.444] [ks=8.167]\n",
      "31200 [D loss: 0.703804731369, acc.: 0.00%] [G loss: 0.703965425491] [mll=90.125+-6.328] [ks=8.350]\n",
      "31300 [D loss: 0.70460152626, acc.: 0.00%] [G loss: 0.705565333366] [mll=89.439+-4.059] [ks=7.616]]\n",
      "31400 [D loss: 0.702990710735, acc.: 0.00%] [G loss: 0.703646302223] [mll=89.945+-4.145] [ks=7.561]\n",
      "31500 [D loss: 0.706239521503, acc.: 0.00%] [G loss: 0.704140126705] [mll=89.643+-4.444] [ks=7.904]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "31600 [D loss: 0.706706523895, acc.: 0.00%] [G loss: 0.706322729588] [mll=85.943+-7.096] [ks=7.703]\n",
      "31700 [D loss: 0.700025081635, acc.: 0.00%] [G loss: 0.707094609737] [mll=89.278+-4.667] [ks=7.803]\n",
      "31800 [D loss: 0.706790804863, acc.: 0.00%] [G loss: 0.707069337368] [mll=89.016+-4.222] [ks=7.586]\n",
      "31900 [D loss: 0.70903801918, acc.: 0.00%] [G loss: 0.718431890011] [mll=89.912+-4.047] [ks=7.856]]\n",
      "32000 [D loss: 0.704315781593, acc.: 0.00%] [G loss: 0.703322649002] [mll=89.264+-4.926] [ks=7.405]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "32100 [D loss: 0.718297362328, acc.: 0.39%] [G loss: 0.725670278072] [mll=89.667+-4.380] [ks=7.326]\n",
      "32200 [D loss: 0.702237248421, acc.: 0.00%] [G loss: 0.731731832027] [mll=92.605+-19.609] [ks=8.019]\n",
      "32300 [D loss: 0.701809167862, acc.: 0.00%] [G loss: 0.706345498562] [mll=85.118+-10.512] [ks=7.615]\n",
      "32400 [D loss: 0.701025605202, acc.: 0.00%] [G loss: 0.704953312874] [mll=89.070+-4.031] [ks=7.505]\n",
      "32500 [D loss: 0.707165837288, acc.: 0.00%] [G loss: 0.705645620823] [mll=90.758+-4.203] [ks=7.535]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "32600 [D loss: 0.698773443699, acc.: 0.00%] [G loss: 0.712130308151] [mll=89.388+-4.131] [ks=7.461]\n",
      "32700 [D loss: 0.708114147186, acc.: 0.00%] [G loss: 0.804943621159] [mll=90.469+-5.665] [ks=8.079]\n",
      "32800 [D loss: 0.705654621124, acc.: 0.00%] [G loss: 0.72683095932] [mll=89.431+-4.832] [ks=7.933]]\n",
      "32900 [D loss: 0.704327821732, acc.: 0.00%] [G loss: 0.712156355381] [mll=89.049+-4.323] [ks=7.974]\n",
      "33000 [D loss: 0.705419063568, acc.: 0.00%] [G loss: 0.706219553947] [mll=90.025+-4.008] [ks=7.714]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "33100 [D loss: 0.71009516716, acc.: 0.00%] [G loss: 0.70974868536] [mll=89.656+-3.989] [ks=7.679]9]\n",
      "33200 [D loss: 0.708679139614, acc.: 0.20%] [G loss: 0.73333221674] [mll=86.909+-7.922] [ks=7.881]]\n",
      "33300 [D loss: 0.720563948154, acc.: 0.00%] [G loss: 0.704199254513] [mll=89.928+-9.009] [ks=7.880]\n",
      "33400 [D loss: 0.708624839783, acc.: 0.00%] [G loss: 0.702321946621] [mll=95.040+-12.992] [ks=7.932]\n",
      "33500 [D loss: 0.70247387886, acc.: 0.00%] [G loss: 0.702486932278] [mll=90.001+-4.005] [ks=7.593]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "33600 [D loss: 0.275734752417, acc.: 0.39%] [G loss: 7.23655033112] [mll=89.574+-3.709] [ks=7.669]]\n",
      "33700 [D loss: 0.162726849318, acc.: 0.00%] [G loss: 16.0675373077] [mll=42.695+-7.328] [ks=12.196]]\n",
      "33800 [D loss: 0.161405563354, acc.: 0.39%] [G loss: 13.6547489166] [mll=38.273+-13.024] [ks=12.420]]\n",
      "33900 [D loss: 0.218159452081, acc.: 0.00%] [G loss: 8.79316043854] [mll=54.358+-15.507] [ks=11.943]]\n",
      "34000 [D loss: 0.250923991203, acc.: 0.78%] [G loss: 8.06039810181] [mll=61.090+-13.622] [ks=10.437]]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "34100 [D loss: 0.218295156956, acc.: 2.73%] [G loss: 10.0797729492] [mll=65.769+-16.730] [ks=9.950]\n",
      "34200 [D loss: 0.445494174957, acc.: 0.00%] [G loss: 1.41949224472] [mll=60.901+-15.827] [ks=10.332]\n",
      "34300 [D loss: 0.621296584606, acc.: 0.00%] [G loss: 1.04955387115] [mll=84.366+-13.103] [ks=9.310]\n",
      "34400 [D loss: 0.709530472755, acc.: 0.00%] [G loss: 0.859881043434] [mll=92.872+-9.555] [ks=7.968]\n",
      "34500 [D loss: 0.698971629143, acc.: 0.00%] [G loss: 0.818972945213] [mll=90.804+-7.683] [ks=7.830]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "34600 [D loss: 0.694635808468, acc.: 0.00%] [G loss: 0.782732248306] [mll=92.817+-8.573] [ks=8.234]\n",
      "34700 [D loss: 0.69875150919, acc.: 0.00%] [G loss: 0.76703029871] [mll=90.008+-5.923] [ks=7.557]7]\n",
      "34800 [D loss: 0.706896066666, acc.: 0.00%] [G loss: 0.743390023708] [mll=90.509+-7.133] [ks=7.696]\n",
      "34900 [D loss: 0.716103434563, acc.: 0.00%] [G loss: 0.749351561069] [mll=91.023+-5.596] [ks=7.407]\n",
      "35000 [D loss: 0.701021790504, acc.: 0.00%] [G loss: 0.729585886002] [mll=89.875+-4.679] [ks=7.729]\n",
      "10000/10000 [==============================] - 1s 53us/step\n",
      "35100 [D loss: 0.691625475883, acc.: 0.00%] [G loss: 0.719317495823] [mll=88.743+-5.107] [ks=7.692]\n",
      "35200 [D loss: 0.692798256874, acc.: 0.00%] [G loss: 0.720168709755] [mll=89.685+-4.901] [ks=8.235]\n",
      "35300 [D loss: 0.69972038269, acc.: 0.00%] [G loss: 0.71819794178] [mll=89.001+-4.453] [ks=8.176]6]\n",
      "35400 [D loss: 0.699975311756, acc.: 0.00%] [G loss: 0.719253599644] [mll=89.313+-5.492] [ks=8.074]\n",
      "35500 [D loss: 0.700612902641, acc.: 0.00%] [G loss: 0.709009110928] [mll=89.416+-4.493] [ks=7.862]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "35600 [D loss: 0.70332556963, acc.: 0.00%] [G loss: 0.758917927742] [mll=90.307+-5.241] [ks=7.641]]\n",
      "35700 [D loss: 0.717407345772, acc.: 0.00%] [G loss: 0.755223214626] [mll=90.647+-7.109] [ks=8.033]\n",
      "35800 [D loss: 0.700078010559, acc.: 0.00%] [G loss: 0.716534733772] [mll=95.631+-14.798] [ks=7.909]\n",
      "35900 [D loss: 0.697361946106, acc.: 0.00%] [G loss: 0.721877515316] [mll=89.946+-4.516] [ks=7.816]\n",
      "36000 [D loss: 0.693230807781, acc.: 0.00%] [G loss: 0.71552079916] [mll=89.941+-5.645] [ks=7.910]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "36100 [D loss: 0.697092533112, acc.: 0.00%] [G loss: 0.712354242802] [mll=89.480+-4.779] [ks=7.977]\n",
      "36200 [D loss: 0.701884567738, acc.: 0.00%] [G loss: 0.715371549129] [mll=90.087+-4.794] [ks=8.093]\n",
      "36300 [D loss: 0.703293740749, acc.: 0.00%] [G loss: 0.708868920803] [mll=88.820+-4.601] [ks=7.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36400 [D loss: 0.701387465, acc.: 0.00%] [G loss: 0.711517751217] [mll=90.189+-4.049] [ks=7.909]09]\n",
      "36500 [D loss: 0.699099719524, acc.: 0.00%] [G loss: 0.710174500942] [mll=89.845+-4.254] [ks=7.625]\n",
      "10000/10000 [==============================] - 1s 53us/step\n",
      "36600 [D loss: 0.860686659813, acc.: 0.00%] [G loss: 0.709992408752] [mll=89.861+-4.888] [ks=7.689]\n",
      "36700 [D loss: 0.694974124432, acc.: 0.00%] [G loss: 0.713644564152] [mll=88.903+-4.912] [ks=7.648]\n",
      "36800 [D loss: 0.701932072639, acc.: 0.00%] [G loss: 0.707232534885] [mll=89.943+-4.449] [ks=8.031]\n",
      "36900 [D loss: 0.704258799553, acc.: 0.00%] [G loss: 0.712030053139] [mll=91.302+-5.211] [ks=7.586]\n",
      "37000 [D loss: 0.702536702156, acc.: 0.00%] [G loss: 0.709780454636] [mll=89.624+-4.235] [ks=7.848]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "37100 [D loss: 0.706593811512, acc.: 0.00%] [G loss: 0.709078729153] [mll=89.766+-4.672] [ks=7.378]\n",
      "37200 [D loss: 0.697534501553, acc.: 0.00%] [G loss: 0.712702810764] [mll=89.460+-4.540] [ks=7.842]\n",
      "37300 [D loss: 0.701028227806, acc.: 0.39%] [G loss: 0.720663130283] [mll=89.531+-4.458] [ks=7.333]\n",
      "37400 [D loss: 0.701386332512, acc.: 0.00%] [G loss: 0.712184965611] [mll=96.228+-18.365] [ks=8.116]\n",
      "37500 [D loss: 0.727011919022, acc.: 0.00%] [G loss: 0.708827912807] [mll=90.480+-4.823] [ks=7.455]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "37600 [D loss: 0.702183246613, acc.: 0.00%] [G loss: 0.709059298038] [mll=89.699+-4.454] [ks=7.678]\n",
      "37700 [D loss: 0.702255368233, acc.: 0.00%] [G loss: 0.709944009781] [mll=90.460+-4.154] [ks=7.921]\n",
      "37800 [D loss: 0.694201827049, acc.: 0.00%] [G loss: 0.71077722311] [mll=89.509+-4.977] [ks=7.839]]\n",
      "37900 [D loss: 0.701731324196, acc.: 0.00%] [G loss: 0.713009119034] [mll=89.505+-4.929] [ks=8.092]\n",
      "38000 [D loss: 0.696567177773, acc.: 0.00%] [G loss: 0.707026898861] [mll=89.764+-4.440] [ks=7.790]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "38100 [D loss: 0.704263985157, acc.: 0.00%] [G loss: 0.713295817375] [mll=89.790+-4.322] [ks=7.798]\n",
      "38200 [D loss: 0.701967656612, acc.: 0.00%] [G loss: 0.712722361088] [mll=90.449+-5.592] [ks=7.679]\n",
      "38300 [D loss: 0.700467705727, acc.: 0.00%] [G loss: 0.71197026968] [mll=89.358+-4.084] [ks=7.929]]\n",
      "38400 [D loss: 0.696053147316, acc.: 0.00%] [G loss: 0.70966821909] [mll=89.520+-4.004] [ks=8.079]]\n",
      "38500 [D loss: 0.700577259064, acc.: 0.00%] [G loss: 0.721035420895] [mll=89.065+-5.330] [ks=8.025]\n",
      "10000/10000 [==============================] - 1s 54us/step\n",
      "38600 [D loss: 0.705463409424, acc.: 0.00%] [G loss: 0.71033012867] [mll=89.575+-5.825] [ks=8.139]]\n",
      "38700 [D loss: 0.696100831032, acc.: 0.00%] [G loss: 0.710401952267] [mll=89.563+-4.278] [ks=8.310]\n",
      "38800 [D loss: 0.696108222008, acc.: 0.00%] [G loss: 0.712697088718] [mll=89.089+-4.541] [ks=7.895]\n",
      "38900 [D loss: 0.698202848434, acc.: 0.00%] [G loss: 0.720776438713] [mll=89.168+-4.666] [ks=8.472]\n",
      "39000 [D loss: 0.699192643166, acc.: 0.00%] [G loss: 0.705209195614] [mll=89.706+-4.702] [ks=7.773]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "39100 [D loss: 0.704115748405, acc.: 0.00%] [G loss: 0.713232755661] [mll=89.802+-4.557] [ks=8.083]\n",
      "39200 [D loss: 0.697740495205, acc.: 0.00%] [G loss: 0.711653769016] [mll=92.610+-9.916] [ks=7.981]\n",
      "39300 [D loss: 0.696994543076, acc.: 0.00%] [G loss: 0.708114564419] [mll=89.620+-6.263] [ks=8.271]\n",
      "39400 [D loss: 0.700793504715, acc.: 0.00%] [G loss: 0.70875620842] [mll=86.537+-6.558] [ks=8.196]]\n",
      "39500 [D loss: 0.700388908386, acc.: 0.00%] [G loss: 0.709698140621] [mll=89.539+-4.265] [ks=7.504]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "39600 [D loss: 0.706047058105, acc.: 0.00%] [G loss: 0.704189777374] [mll=89.499+-4.621] [ks=7.810]\n",
      "39700 [D loss: 0.704210162163, acc.: 0.00%] [G loss: 0.710861206055] [mll=89.697+-4.621] [ks=8.012]\n",
      "39800 [D loss: 0.700807034969, acc.: 0.00%] [G loss: 0.707919359207] [mll=89.341+-5.533] [ks=8.090]\n",
      "39900 [D loss: 0.699208021164, acc.: 0.00%] [G loss: 0.702345311642] [mll=89.540+-4.414] [ks=7.537]\n",
      "40000 [D loss: 0.756706953049, acc.: 0.00%] [G loss: 0.70737183094] [mll=89.340+-5.081] [ks=7.925]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "40100 [D loss: 0.708066225052, acc.: 0.00%] [G loss: 0.707489848137] [mll=89.654+-4.321] [ks=7.691]\n",
      "40200 [D loss: 0.713156461716, acc.: 0.00%] [G loss: 0.70614284277] [mll=89.721+-4.122] [ks=7.844]]\n",
      "40300 [D loss: 0.698478937149, acc.: 0.00%] [G loss: 0.702883303165] [mll=89.749+-4.038] [ks=7.708]\n",
      "40400 [D loss: 0.727201223373, acc.: 0.00%] [G loss: 0.704312205315] [mll=89.985+-4.514] [ks=7.894]\n",
      "40500 [D loss: 0.735034346581, acc.: 0.98%] [G loss: 0.754619181156] [mll=90.047+-4.940] [ks=8.205]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "40600 [D loss: 0.704839468002, acc.: 0.00%] [G loss: 0.704554498196] [mll=94.275+-10.274] [ks=8.448]\n",
      "40700 [D loss: 0.704751312733, acc.: 0.00%] [G loss: 0.705092847347] [mll=89.535+-4.109] [ks=7.563]\n",
      "40800 [D loss: 0.70255625248, acc.: 0.00%] [G loss: 0.706807136536] [mll=89.768+-4.521] [ks=7.488]]\n",
      "40900 [D loss: 0.700585961342, acc.: 0.00%] [G loss: 0.702921450138] [mll=90.103+-4.078] [ks=8.064]\n",
      "41000 [D loss: 0.696397542953, acc.: 0.00%] [G loss: 0.702624797821] [mll=89.420+-4.119] [ks=7.854]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "41100 [D loss: 0.695836365223, acc.: 0.00%] [G loss: 0.702809214592] [mll=90.474+-4.279] [ks=8.124]\n",
      "41200 [D loss: 0.70118200779, acc.: 0.00%] [G loss: 0.705950856209] [mll=89.697+-4.499] [ks=7.775]]\n",
      "41300 [D loss: 0.700386762619, acc.: 0.00%] [G loss: 0.702702522278] [mll=90.632+-4.033] [ks=7.526]\n",
      "41400 [D loss: 0.699432849884, acc.: 0.00%] [G loss: 0.707132816315] [mll=89.625+-4.003] [ks=8.038]\n",
      "41500 [D loss: 0.724539279938, acc.: 0.00%] [G loss: 0.703315317631] [mll=89.248+-4.334] [ks=7.763]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "41600 [D loss: 0.706618070602, acc.: 0.00%] [G loss: 0.704549789429] [mll=89.568+-4.517] [ks=7.382]\n",
      "41700 [D loss: 0.701997518539, acc.: 0.20%] [G loss: 0.705406248569] [mll=89.878+-4.149] [ks=7.944]\n",
      "41800 [D loss: 0.704359829426, acc.: 0.00%] [G loss: 0.704203248024] [mll=89.752+-4.113] [ks=7.745]\n",
      "41900 [D loss: 0.701657056808, acc.: 0.00%] [G loss: 0.705568671227] [mll=89.541+-3.957] [ks=7.490]\n",
      "42000 [D loss: 0.700079917908, acc.: 0.00%] [G loss: 0.70416790247] [mll=89.373+-4.671] [ks=7.547]]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "42100 [D loss: 0.708402276039, acc.: 0.00%] [G loss: 0.707311213017] [mll=87.799+-4.717] [ks=7.825]\n",
      "42200 [D loss: 0.698218107224, acc.: 0.00%] [G loss: 0.706589102745] [mll=89.834+-4.718] [ks=7.968]\n",
      "42300 [D loss: 0.705086052418, acc.: 0.00%] [G loss: 0.7018866539] [mll=89.543+-4.146] [ks=8.056]6]\n",
      "42400 [D loss: 0.705985546112, acc.: 0.00%] [G loss: 0.703349709511] [mll=88.761+-4.946] [ks=7.678]\n",
      "42500 [D loss: 0.712217628956, acc.: 0.00%] [G loss: 0.709528565407] [mll=89.844+-4.181] [ks=7.603]\n",
      "10000/10000 [==============================] - 1s 51us/step\n",
      "42600 [D loss: 0.707672536373, acc.: 0.00%] [G loss: 0.708226680756] [mll=89.588+-4.319] [ks=7.693]\n",
      "42700 [D loss: 0.702136993408, acc.: 0.00%] [G loss: 0.701910436153] [mll=89.635+-4.019] [ks=7.478]\n",
      "42800 [D loss: 0.706043958664, acc.: 0.00%] [G loss: 0.703723847866] [mll=89.439+-4.247] [ks=7.576]\n",
      "42900 [D loss: 0.697637200356, acc.: 0.00%] [G loss: 0.702300012112] [mll=89.429+-4.522] [ks=8.013]\n",
      "43000 [D loss: 0.721378564835, acc.: 0.98%] [G loss: 0.738458693027] [mll=89.891+-4.468] [ks=7.891]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "43100 [D loss: 0.699869632721, acc.: 0.00%] [G loss: 0.701310575008] [mll=94.639+-10.583] [ks=7.526]\n",
      "43200 [D loss: 0.706547558308, acc.: 0.00%] [G loss: 0.699624300003] [mll=83.913+-9.193] [ks=7.832]\n",
      "43300 [D loss: 0.875029802322, acc.: 0.00%] [G loss: 0.698312520981] [mll=89.918+-4.247] [ks=7.761]\n",
      "43400 [D loss: 0.707464933395, acc.: 0.00%] [G loss: 0.704508841038] [mll=89.726+-5.975] [ks=7.502]\n",
      "43500 [D loss: 0.698551476002, acc.: 0.00%] [G loss: 0.704443097115] [mll=92.417+-6.200] [ks=7.467]\n",
      "10000/10000 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43600 [D loss: 0.696934044361, acc.: 0.00%] [G loss: 0.703618109226] [mll=89.470+-4.426] [ks=7.560]\n",
      "43700 [D loss: 0.701866567135, acc.: 0.00%] [G loss: 0.705558300018] [mll=90.092+-4.133] [ks=7.985]\n",
      "43800 [D loss: 0.70417714119, acc.: 0.00%] [G loss: 0.704063773155] [mll=89.660+-4.025] [ks=7.918]]\n",
      "43900 [D loss: 0.699636101723, acc.: 0.00%] [G loss: 0.702772140503] [mll=90.069+-4.641] [ks=7.325]\n",
      "44000 [D loss: 0.705267190933, acc.: 0.00%] [G loss: 0.702031672001] [mll=88.230+-4.587] [ks=7.428]\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "44100 [D loss: 0.698930382729, acc.: 0.00%] [G loss: 0.704757452011] [mll=89.791+-4.506] [ks=7.306]\n",
      "44200 [D loss: 0.700287461281, acc.: 0.00%] [G loss: 0.704918324947] [mll=88.899+-4.171] [ks=7.239]\n",
      "44300 [D loss: 0.699128508568, acc.: 0.00%] [G loss: 0.709341466427] [mll=88.843+-4.204] [ks=7.530]\n",
      "44400 [D loss: 0.700369775295, acc.: 0.00%] [G loss: 0.702709138393] [mll=90.412+-3.970] [ks=7.772]\n",
      "44500 [D loss: 0.706981301308, acc.: 0.00%] [G loss: 0.716639757156] [mll=89.589+-3.868] [ks=7.779]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "44600 [D loss: 0.705275833607, acc.: 0.00%] [G loss: 0.706715703011] [mll=95.980+-13.115] [ks=7.930]\n",
      "44700 [D loss: 0.716808319092, acc.: 0.00%] [G loss: 0.705461263657] [mll=84.618+-10.919] [ks=8.170]\n",
      "44800 [D loss: 0.698690295219, acc.: 0.00%] [G loss: 0.706769049168] [mll=90.945+-4.676] [ks=7.784]\n",
      "44900 [D loss: 0.700939178467, acc.: 0.00%] [G loss: 0.704208791256] [mll=86.383+-6.820] [ks=7.591]\n",
      "45000 [D loss: 0.698755979538, acc.: 0.00%] [G loss: 0.705836832523] [mll=89.562+-3.990] [ks=7.672]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "45100 [D loss: 0.708994865417, acc.: 0.00%] [G loss: 0.702316343784] [mll=89.731+-4.637] [ks=7.899]\n",
      "45200 [D loss: 0.695956468582, acc.: 0.00%] [G loss: 0.704410016537] [mll=89.865+-4.543] [ks=7.818]\n",
      "45300 [D loss: 0.700712323189, acc.: 0.00%] [G loss: 0.703678071499] [mll=89.859+-4.155] [ks=7.646]\n",
      "45400 [D loss: 0.738692641258, acc.: 0.00%] [G loss: 0.706368684769] [mll=89.920+-3.883] [ks=7.702]\n",
      "45500 [D loss: 0.724498867989, acc.: 0.00%] [G loss: 0.704437673092] [mll=89.317+-4.746] [ks=7.644]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "45600 [D loss: 0.705676555634, acc.: 0.00%] [G loss: 0.703519821167] [mll=89.595+-4.341] [ks=8.015]\n",
      "45700 [D loss: 0.709538698196, acc.: 0.00%] [G loss: 0.702801644802] [mll=89.639+-4.062] [ks=7.904]\n",
      "45800 [D loss: 0.702504634857, acc.: 0.00%] [G loss: 0.705256223679] [mll=89.857+-4.573] [ks=7.519]\n",
      "45900 [D loss: 0.719887256622, acc.: 0.00%] [G loss: 0.704123616219] [mll=89.455+-4.172] [ks=7.726]\n",
      "46000 [D loss: 0.699635863304, acc.: 0.00%] [G loss: 0.703423857689] [mll=89.361+-4.319] [ks=7.530]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "46100 [D loss: 0.702007889748, acc.: 0.00%] [G loss: 0.702040553093] [mll=89.626+-4.209] [ks=7.541]\n",
      "46200 [D loss: 0.698719143867, acc.: 0.00%] [G loss: 0.703792631626] [mll=89.677+-4.169] [ks=7.681]\n",
      "46300 [D loss: 0.703965485096, acc.: 0.00%] [G loss: 0.703001022339] [mll=89.921+-4.285] [ks=7.956]\n",
      "46400 [D loss: 0.710664093494, acc.: 0.00%] [G loss: 0.704693853855] [mll=89.243+-4.236] [ks=8.052]\n",
      "46500 [D loss: 0.705766916275, acc.: 0.00%] [G loss: 0.706762373447] [mll=89.341+-3.484] [ks=7.973]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "46600 [D loss: 0.701015532017, acc.: 0.00%] [G loss: 0.704839289188] [mll=89.416+-3.796] [ks=7.902]\n",
      "46700 [D loss: 0.702202558517, acc.: 0.00%] [G loss: 0.701890707016] [mll=89.990+-4.045] [ks=8.195]\n",
      "46800 [D loss: 0.700521945953, acc.: 0.00%] [G loss: 0.703708529472] [mll=89.834+-3.841] [ks=7.687]\n",
      "46900 [D loss: 0.702062487602, acc.: 0.00%] [G loss: 0.707417547703] [mll=89.585+-4.046] [ks=7.525]\n",
      "47000 [D loss: 0.704475641251, acc.: 0.00%] [G loss: 0.706421256065] [mll=89.584+-4.077] [ks=7.858]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "47100 [D loss: 0.700724363327, acc.: 0.00%] [G loss: 0.703688085079] [mll=90.217+-7.001] [ks=7.263]\n",
      "47200 [D loss: 0.705863714218, acc.: 0.00%] [G loss: 0.702576637268] [mll=89.699+-4.340] [ks=8.338]\n",
      "47300 [D loss: 0.700934171677, acc.: 0.00%] [G loss: 0.705912470818] [mll=89.463+-4.030] [ks=7.804]\n",
      "47400 [D loss: 0.713411331177, acc.: 0.00%] [G loss: 0.70164257288] [mll=89.752+-4.053] [ks=7.955]]\n",
      "47500 [D loss: 0.704860150814, acc.: 0.00%] [G loss: 0.700890481472] [mll=90.252+-4.236] [ks=8.083]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "47600 [D loss: 0.702761530876, acc.: 0.00%] [G loss: 0.700255811214] [mll=88.725+-4.029] [ks=7.491]\n",
      "47700 [D loss: 0.701768577099, acc.: 0.00%] [G loss: 0.703853189945] [mll=89.703+-4.269] [ks=7.696]\n",
      "47800 [D loss: 0.671078205109, acc.: 0.00%] [G loss: 0.723446309566] [mll=88.671+-4.701] [ks=8.379]\n",
      "47900 [D loss: 0.704427719116, acc.: 0.00%] [G loss: 0.715936601162] [mll=89.355+-4.211] [ks=8.945]\n",
      "48000 [D loss: 0.703278779984, acc.: 0.00%] [G loss: 0.706454694271] [mll=87.176+-4.855] [ks=8.225]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "48100 [D loss: 0.699953973293, acc.: 0.00%] [G loss: 0.704676091671] [mll=89.356+-3.850] [ks=7.779]\n",
      "48200 [D loss: 0.704517424107, acc.: 0.00%] [G loss: 0.703984677792] [mll=89.675+-4.395] [ks=7.895]\n",
      "48300 [D loss: 0.701723814011, acc.: 0.00%] [G loss: 0.704028666019] [mll=89.592+-4.020] [ks=7.770]\n",
      "48400 [D loss: 0.702270030975, acc.: 0.00%] [G loss: 0.702346682549] [mll=89.908+-3.893] [ks=8.028]\n",
      "48500 [D loss: 0.703775465488, acc.: 0.00%] [G loss: 0.708486914635] [mll=89.511+-4.179] [ks=7.166]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "48600 [D loss: 0.70146894455, acc.: 0.00%] [G loss: 0.705574989319] [mll=89.591+-4.249] [ks=7.656]]\n",
      "48700 [D loss: 0.703680634499, acc.: 0.00%] [G loss: 0.702060759068] [mll=89.634+-4.009] [ks=7.693]\n",
      "48800 [D loss: 0.706180691719, acc.: 0.00%] [G loss: 0.701342999935] [mll=89.541+-4.164] [ks=7.178]\n",
      "48900 [D loss: 0.704124927521, acc.: 0.00%] [G loss: 0.700976729393] [mll=89.704+-4.196] [ks=7.561]\n",
      "49000 [D loss: 0.70767390728, acc.: 0.00%] [G loss: 0.712009966373] [mll=89.328+-3.739] [ks=7.673]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "49100 [D loss: 0.70348572731, acc.: 0.00%] [G loss: 0.704756617546] [mll=89.456+-4.069] [ks=7.408]]\n",
      "49200 [D loss: 0.701606988907, acc.: 0.00%] [G loss: 0.701779782772] [mll=90.051+-4.313] [ks=7.341]\n",
      "49300 [D loss: 0.702444911003, acc.: 0.00%] [G loss: 0.700111031532] [mll=89.502+-3.480] [ks=7.488]\n",
      "49400 [D loss: 0.71373128891, acc.: 0.00%] [G loss: 0.702254354954] [mll=89.867+-3.949] [ks=7.109]]\n",
      "49500 [D loss: 0.69872546196, acc.: 0.00%] [G loss: 0.716579556465] [mll=89.954+-4.398] [ks=7.458]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "49600 [D loss: 0.709583818913, acc.: 0.39%] [G loss: 0.711156249046] [mll=89.766+-3.922] [ks=7.569]\n",
      "49700 [D loss: 0.704126596451, acc.: 0.00%] [G loss: 0.701385915279] [mll=92.974+-11.063] [ks=8.043]\n",
      "49800 [D loss: 0.702208459377, acc.: 0.00%] [G loss: 0.701469779015] [mll=89.261+-4.659] [ks=7.489]\n",
      "49900 [D loss: 0.704328536987, acc.: 0.00%] [G loss: 0.701305508614] [mll=89.850+-3.924] [ks=7.727]\n",
      "50000 [D loss: 0.706193685532, acc.: 0.00%] [G loss: 0.702998280525] [mll=89.426+-4.297] [ks=7.395]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "50100 [D loss: 0.706906676292, acc.: 0.00%] [G loss: 0.702205717564] [mll=89.338+-4.146] [ks=7.672]\n",
      "50200 [D loss: 0.703360021114, acc.: 0.00%] [G loss: 0.707216799259] [mll=89.698+-4.309] [ks=7.493]\n",
      "50300 [D loss: 0.702842950821, acc.: 0.00%] [G loss: 0.703190803528] [mll=89.879+-4.347] [ks=7.441]\n",
      "50400 [D loss: 0.709822416306, acc.: 0.00%] [G loss: 0.718957960606] [mll=89.194+-3.841] [ks=7.294]\n",
      "50500 [D loss: 0.706248044968, acc.: 0.00%] [G loss: 0.704444825649] [mll=89.635+-5.521] [ks=8.196]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "50600 [D loss: 0.708464741707, acc.: 0.00%] [G loss: 0.707151830196] [mll=89.736+-4.175] [ks=7.117]\n",
      "50700 [D loss: 0.702172279358, acc.: 0.00%] [G loss: 0.702119410038] [mll=87.830+-4.357] [ks=7.953]\n",
      "50800 [D loss: 0.709388494492, acc.: 0.00%] [G loss: 0.708924531937] [mll=89.941+-3.843] [ks=7.466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50900 [D loss: 0.700698375702, acc.: 0.00%] [G loss: 0.703439712524] [mll=85.043+-8.335] [ks=7.880]\n",
      "51000 [D loss: 0.704203605652, acc.: 0.00%] [G loss: 0.70223236084] [mll=91.628+-5.353] [ks=8.048]]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "51100 [D loss: 0.702677488327, acc.: 0.00%] [G loss: 0.702347636223] [mll=89.416+-4.098] [ks=7.376]\n",
      "51200 [D loss: 0.774956285954, acc.: 0.00%] [G loss: 0.700510442257] [mll=89.887+-4.460] [ks=7.077]\n",
      "51300 [D loss: 0.701767921448, acc.: 0.00%] [G loss: 0.702345907688] [mll=88.084+-4.312] [ks=8.001]\n",
      "51400 [D loss: 0.705055058002, acc.: 0.00%] [G loss: 0.709190011024] [mll=90.046+-4.320] [ks=7.150]\n",
      "51500 [D loss: 0.700976610184, acc.: 0.00%] [G loss: 0.704200208187] [mll=86.592+-10.358] [ks=7.755]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "51600 [D loss: 0.709210753441, acc.: 0.00%] [G loss: 0.702862739563] [mll=89.752+-4.162] [ks=7.917]\n",
      "51700 [D loss: 0.705660641193, acc.: 0.00%] [G loss: 0.70158046484] [mll=89.509+-4.389] [ks=7.794]]\n",
      "51800 [D loss: 0.707607626915, acc.: 0.00%] [G loss: 0.700642645359] [mll=89.731+-4.176] [ks=7.312]\n",
      "51900 [D loss: 0.709065556526, acc.: 0.00%] [G loss: 0.704640388489] [mll=89.398+-4.032] [ks=7.315]\n",
      "52000 [D loss: 0.753080368042, acc.: 0.00%] [G loss: 0.704034090042] [mll=89.825+-5.825] [ks=7.242]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "52100 [D loss: 0.703021287918, acc.: 0.00%] [G loss: 0.700037121773] [mll=89.680+-4.430] [ks=7.112]\n",
      "52200 [D loss: 0.707202792168, acc.: 0.00%] [G loss: 0.700491368771] [mll=90.168+-4.003] [ks=6.700]\n",
      "52300 [D loss: 0.703934013844, acc.: 0.00%] [G loss: 0.701552450657] [mll=89.735+-4.417] [ks=6.384]\n",
      "52400 [D loss: 0.708680391312, acc.: 0.20%] [G loss: 0.701761245728] [mll=89.412+-4.281] [ks=7.182]\n",
      "52500 [D loss: 0.710678339005, acc.: 0.00%] [G loss: 0.702514111996] [mll=89.953+-4.417] [ks=7.113]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "52600 [D loss: 0.708164691925, acc.: 0.00%] [G loss: 0.703363418579] [mll=89.806+-3.941] [ks=7.409]\n",
      "52700 [D loss: 0.703339576721, acc.: 0.00%] [G loss: 0.701477587223] [mll=89.914+-5.126] [ks=7.983]\n",
      "52800 [D loss: 0.702893257141, acc.: 0.00%] [G loss: 0.703515589237] [mll=89.993+-4.744] [ks=7.967]\n",
      "52900 [D loss: 0.70642209053, acc.: 0.00%] [G loss: 0.70200252533] [mll=89.248+-4.223] [ks=7.628]8]\n",
      "53000 [D loss: 0.709537446499, acc.: 0.00%] [G loss: 0.701723098755] [mll=89.418+-4.218] [ks=8.024]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "53100 [D loss: 0.704312086105, acc.: 0.00%] [G loss: 0.70183891058] [mll=89.071+-3.991] [ks=7.380]]\n",
      "53200 [D loss: 0.70375418663, acc.: 0.00%] [G loss: 0.702740132809] [mll=89.586+-4.072] [ks=7.878]]\n",
      "53300 [D loss: 0.700231969357, acc.: 0.00%] [G loss: 0.727539479733] [mll=88.751+-3.843] [ks=7.881]\n",
      "53400 [D loss: 0.702845036983, acc.: 0.00%] [G loss: 0.703943371773] [mll=90.727+-3.824] [ks=7.496]\n",
      "53500 [D loss: 0.705085098743, acc.: 0.00%] [G loss: 0.702088713646] [mll=89.002+-4.134] [ks=7.600]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "53600 [D loss: 0.705778837204, acc.: 0.00%] [G loss: 0.701979219913] [mll=86.704+-6.159] [ks=7.514]\n",
      "53700 [D loss: 0.700829029083, acc.: 0.00%] [G loss: 0.70324999094] [mll=89.029+-4.720] [ks=7.398]]\n",
      "53800 [D loss: 0.720406293869, acc.: 0.00%] [G loss: 0.716373383999] [mll=90.324+-4.547] [ks=7.439]\n",
      "53900 [D loss: 0.73035132885, acc.: 0.00%] [G loss: 0.706822037697] [mll=89.461+-4.765] [ks=7.652]]\n",
      "54000 [D loss: 0.70311665535, acc.: 0.00%] [G loss: 0.703550755978] [mll=91.661+-5.278] [ks=7.520]]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "54100 [D loss: 0.701671779156, acc.: 0.00%] [G loss: 0.711884260178] [mll=89.790+-3.897] [ks=7.680]\n",
      "54200 [D loss: 0.70382219553, acc.: 0.00%] [G loss: 0.705246210098] [mll=89.507+-3.831] [ks=7.486]]\n",
      "54300 [D loss: 0.702637791634, acc.: 0.00%] [G loss: 0.70363765955] [mll=89.398+-4.292] [ks=7.159]]\n",
      "54400 [D loss: 0.715460538864, acc.: 0.00%] [G loss: 0.70214754343] [mll=89.542+-4.322] [ks=7.589]]\n",
      "54500 [D loss: 0.712716221809, acc.: 0.00%] [G loss: 0.700912117958] [mll=89.734+-4.180] [ks=7.825]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "54600 [D loss: 0.705669283867, acc.: 0.00%] [G loss: 0.704279005527] [mll=89.397+-4.016] [ks=7.447]\n",
      "54700 [D loss: 0.701273798943, acc.: 0.00%] [G loss: 0.703921377659] [mll=90.511+-4.172] [ks=7.437]\n",
      "54800 [D loss: 0.702852129936, acc.: 0.00%] [G loss: 0.703909993172] [mll=88.697+-4.393] [ks=7.710]\n",
      "54900 [D loss: 0.701774299145, acc.: 0.00%] [G loss: 0.701289892197] [mll=89.996+-4.105] [ks=7.992]\n",
      "55000 [D loss: 0.714546561241, acc.: 0.00%] [G loss: 0.703258156776] [mll=89.620+-4.226] [ks=7.539]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "55100 [D loss: 0.701555609703, acc.: 0.00%] [G loss: 0.702542901039] [mll=89.165+-3.608] [ks=7.966]\n",
      "55200 [D loss: 0.701123952866, acc.: 0.00%] [G loss: 0.702806532383] [mll=89.500+-4.458] [ks=7.858]\n",
      "55300 [D loss: 0.708329200745, acc.: 0.00%] [G loss: 0.703847527504] [mll=91.328+-5.982] [ks=7.766]\n",
      "55400 [D loss: 0.702668607235, acc.: 0.00%] [G loss: 0.702178061008] [mll=87.257+-5.005] [ks=7.640]\n",
      "55500 [D loss: 0.70375919342, acc.: 0.00%] [G loss: 0.702020704746] [mll=88.902+-3.810] [ks=7.814]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "55600 [D loss: 0.71337968111, acc.: 0.00%] [G loss: 0.702336370945] [mll=90.313+-4.235] [ks=7.705]]\n",
      "55700 [D loss: 0.705178201199, acc.: 0.00%] [G loss: 0.703706383705] [mll=91.005+-4.766] [ks=7.049]\n",
      "55800 [D loss: 0.736490368843, acc.: 0.39%] [G loss: 0.717544019222] [mll=90.274+-4.521] [ks=7.554]\n",
      "55900 [D loss: 0.704902410507, acc.: 0.00%] [G loss: 0.701643526554] [mll=94.353+-9.323] [ks=7.898]\n",
      "56000 [D loss: 0.704343616962, acc.: 0.00%] [G loss: 0.701252102852] [mll=89.354+-4.387] [ks=7.470]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "56100 [D loss: 0.703500270844, acc.: 0.00%] [G loss: 0.703069269657] [mll=88.853+-4.304] [ks=7.573]\n",
      "56200 [D loss: 0.699812054634, acc.: 0.00%] [G loss: 0.704019010067] [mll=89.906+-3.796] [ks=7.698]\n",
      "56300 [D loss: 0.70621073246, acc.: 0.00%] [G loss: 0.704655110836] [mll=89.374+-4.043] [ks=7.756]]\n",
      "56400 [D loss: 0.705750286579, acc.: 0.00%] [G loss: 0.702107071877] [mll=88.589+-4.486] [ks=7.895]\n",
      "56500 [D loss: 0.706655144691, acc.: 0.00%] [G loss: 0.704693317413] [mll=89.541+-4.029] [ks=7.665]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "56600 [D loss: 0.701779067516, acc.: 0.00%] [G loss: 0.702175855637] [mll=90.270+-4.030] [ks=7.442]\n",
      "56700 [D loss: 0.704031229019, acc.: 0.00%] [G loss: 0.702115595341] [mll=87.660+-4.445] [ks=7.773]\n",
      "56800 [D loss: 0.701620340347, acc.: 0.00%] [G loss: 0.705577611923] [mll=89.975+-4.501] [ks=7.715]\n",
      "56900 [D loss: 0.702478885651, acc.: 0.00%] [G loss: 0.702602803707] [mll=89.657+-4.702] [ks=7.572]\n",
      "57000 [D loss: 0.702368974686, acc.: 0.00%] [G loss: 0.706573426723] [mll=88.942+-4.657] [ks=7.601]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "57100 [D loss: 0.762434124947, acc.: 0.00%] [G loss: 0.702946603298] [mll=89.575+-4.787] [ks=7.944]\n",
      "57200 [D loss: 0.702903091908, acc.: 0.00%] [G loss: 0.702227115631] [mll=89.845+-4.292] [ks=7.565]\n",
      "57300 [D loss: 0.70766210556, acc.: 0.00%] [G loss: 0.704340100288] [mll=88.309+-6.320] [ks=7.617]]\n",
      "57400 [D loss: 0.703380703926, acc.: 0.00%] [G loss: 0.704814493656] [mll=90.094+-4.524] [ks=7.460]\n",
      "57500 [D loss: 0.700760126114, acc.: 0.00%] [G loss: 0.703755319118] [mll=89.678+-4.003] [ks=7.710]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "57600 [D loss: 0.706256389618, acc.: 0.00%] [G loss: 0.701789915562] [mll=89.836+-4.669] [ks=8.016]\n",
      "57700 [D loss: 0.705311000347, acc.: 0.00%] [G loss: 0.702165663242] [mll=87.817+-5.139] [ks=7.875]\n",
      "57800 [D loss: 0.703339219093, acc.: 0.00%] [G loss: 0.706145882607] [mll=89.022+-4.344] [ks=7.667]\n",
      "57900 [D loss: 0.701323032379, acc.: 0.00%] [G loss: 0.705189228058] [mll=89.660+-4.192] [ks=7.455]\n",
      "58000 [D loss: 0.700793266296, acc.: 0.00%] [G loss: 0.704865396023] [mll=89.542+-4.094] [ks=7.567]\n",
      "10000/10000 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58100 [D loss: 0.711838364601, acc.: 0.00%] [G loss: 0.70298743248] [mll=89.480+-4.507] [ks=7.473]]\n",
      "58200 [D loss: 0.701161026955, acc.: 0.00%] [G loss: 0.703679144382] [mll=89.888+-3.750] [ks=8.152]\n",
      "58300 [D loss: 0.704209446907, acc.: 0.00%] [G loss: 0.712934076786] [mll=92.117+-5.648] [ks=7.860]\n",
      "58400 [D loss: 0.712320446968, acc.: 0.00%] [G loss: 0.704463422298] [mll=89.519+-4.382] [ks=7.875]\n",
      "58500 [D loss: 0.701880931854, acc.: 0.00%] [G loss: 0.703644752502] [mll=89.241+-4.966] [ks=7.775]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "58600 [D loss: 0.702122449875, acc.: 0.00%] [G loss: 0.706834316254] [mll=89.618+-4.093] [ks=7.983]\n",
      "58700 [D loss: 0.706398546696, acc.: 0.00%] [G loss: 0.704048216343] [mll=89.544+-4.724] [ks=7.454]\n",
      "58800 [D loss: 0.70367872715, acc.: 0.00%] [G loss: 0.70907920599] [mll=89.923+-4.741] [ks=8.139]9]\n",
      "58900 [D loss: 0.702985346317, acc.: 0.00%] [G loss: 0.704036295414] [mll=89.762+-4.732] [ks=7.288]\n",
      "59000 [D loss: 0.707367539406, acc.: 0.00%] [G loss: 0.702634871006] [mll=91.583+-6.821] [ks=7.494]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "59100 [D loss: 0.802491784096, acc.: 0.00%] [G loss: 0.702779829502] [mll=90.847+-4.866] [ks=7.807]\n",
      "59200 [D loss: 0.704444587231, acc.: 0.00%] [G loss: 0.704523324966] [mll=89.419+-4.200] [ks=7.346]\n",
      "59300 [D loss: 0.703203558922, acc.: 0.00%] [G loss: 0.704240441322] [mll=88.748+-4.217] [ks=7.688]\n",
      "59400 [D loss: 0.726273059845, acc.: 0.00%] [G loss: 0.704368531704] [mll=89.874+-4.376] [ks=8.001]\n",
      "59500 [D loss: 0.703132629395, acc.: 0.00%] [G loss: 0.70708745718] [mll=89.189+-3.911] [ks=7.704]]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "59600 [D loss: 0.705651879311, acc.: 0.00%] [G loss: 0.702532827854] [mll=89.098+-4.216] [ks=7.572]\n",
      "59700 [D loss: 0.710913538933, acc.: 0.00%] [G loss: 0.71045011282] [mll=89.518+-4.827] [ks=7.518]]\n",
      "59800 [D loss: 0.701366841793, acc.: 0.00%] [G loss: 0.70256114006] [mll=89.147+-4.706] [ks=8.015]]\n",
      "59900 [D loss: 0.714030861855, acc.: 0.00%] [G loss: 0.704797804356] [mll=88.476+-4.542] [ks=7.574]\n",
      "60000 [D loss: 0.704597473145, acc.: 0.00%] [G loss: 0.704187810421] [mll=89.647+-4.238] [ks=7.713]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "60100 [D loss: 0.704647302628, acc.: 0.00%] [G loss: 0.700816988945] [mll=89.048+-4.138] [ks=7.654]\n",
      "60200 [D loss: 0.705335617065, acc.: 0.00%] [G loss: 0.704902768135] [mll=89.815+-5.306] [ks=7.267]\n",
      "60300 [D loss: 0.706404209137, acc.: 0.00%] [G loss: 0.703860521317] [mll=89.872+-4.044] [ks=7.612]\n",
      "60400 [D loss: 0.701316952705, acc.: 0.00%] [G loss: 0.706044197083] [mll=89.300+-3.877] [ks=7.449]\n",
      "60500 [D loss: 0.709263086319, acc.: 0.00%] [G loss: 0.69910132885] [mll=89.697+-4.074] [ks=7.644]]\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "60600 [D loss: 0.708843171597, acc.: 0.00%] [G loss: 0.718578279018] [mll=89.173+-4.540] [ks=7.715]\n",
      "60700 [D loss: 0.706300616264, acc.: 0.00%] [G loss: 0.705328583717] [mll=87.899+-3.967] [ks=8.489]\n",
      "60800 [D loss: 0.703376054764, acc.: 0.00%] [G loss: 0.704634726048] [mll=90.667+-5.189] [ks=7.658]\n",
      "60900 [D loss: 0.70360159874, acc.: 0.00%] [G loss: 0.703670561314] [mll=89.341+-3.813] [ks=7.979]]\n",
      "61000 [D loss: 0.70433652401, acc.: 0.00%] [G loss: 0.704313695431] [mll=88.950+-3.462] [ks=7.788]]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "61100 [D loss: 0.703075110912, acc.: 0.00%] [G loss: 0.702140927315] [mll=89.826+-3.967] [ks=8.073]\n",
      "61200 [D loss: 0.75046312809, acc.: 1.17%] [G loss: 0.778952479362] [mll=88.449+-4.808] [ks=8.383]]\n",
      "61300 [D loss: 0.70245218277, acc.: 0.00%] [G loss: 0.702086925507] [mll=94.725+-13.824] [ks=8.167]]\n",
      "61400 [D loss: 0.732710242271, acc.: 0.00%] [G loss: 0.702083170414] [mll=89.431+-4.686] [ks=7.988]\n",
      "61500 [D loss: 0.704904913902, acc.: 0.00%] [G loss: 0.711724698544] [mll=89.228+-3.952] [ks=7.983]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "61600 [D loss: 0.701920032501, acc.: 0.00%] [G loss: 0.704968988895] [mll=89.302+-4.398] [ks=7.583]\n",
      "61700 [D loss: 0.705922842026, acc.: 0.00%] [G loss: 0.704702317715] [mll=89.747+-3.891] [ks=7.677]\n",
      "61800 [D loss: 0.696793377399, acc.: 0.00%] [G loss: 0.710373163223] [mll=89.030+-4.246] [ks=7.695]\n",
      "61900 [D loss: 0.592913866043, acc.: 0.00%] [G loss: 0.770032346249] [mll=90.019+-4.676] [ks=8.703]\n",
      "62000 [D loss: 0.713743567467, acc.: 0.00%] [G loss: 0.722390592098] [mll=85.303+-5.692] [ks=10.034]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "62100 [D loss: 0.571233332157, acc.: 0.00%] [G loss: 0.810886919498] [mll=89.946+-4.621] [ks=8.355]\n",
      "62200 [D loss: 0.733556985855, acc.: 0.00%] [G loss: 0.768806040287] [mll=87.933+-5.830] [ks=9.269]\n",
      "62300 [D loss: 0.737600445747, acc.: 0.00%] [G loss: 0.718697667122] [mll=89.236+-4.381] [ks=7.970]\n",
      "62400 [D loss: 0.702525496483, acc.: 0.00%] [G loss: 0.708695948124] [mll=89.698+-4.366] [ks=7.654]\n",
      "62500 [D loss: 0.718451499939, acc.: 0.00%] [G loss: 0.708021402359] [mll=89.677+-3.909] [ks=7.725]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "62600 [D loss: 0.703053176403, acc.: 0.00%] [G loss: 0.702198922634] [mll=88.714+-4.964] [ks=7.844]\n",
      "62700 [D loss: 0.702870547771, acc.: 0.00%] [G loss: 0.703431725502] [mll=90.187+-4.106] [ks=8.013]\n",
      "62800 [D loss: 0.703199386597, acc.: 0.00%] [G loss: 0.703168988228] [mll=88.882+-3.962] [ks=8.051]\n",
      "62900 [D loss: 0.74252307415, acc.: 0.00%] [G loss: 0.70965474844] [mll=89.548+-3.826] [ks=7.841]1]\n",
      "63000 [D loss: 0.707816720009, acc.: 0.00%] [G loss: 0.702692449093] [mll=89.468+-3.865] [ks=7.692]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "63100 [D loss: 0.703316926956, acc.: 0.00%] [G loss: 0.702035367489] [mll=89.539+-4.121] [ks=7.881]\n",
      "63200 [D loss: 0.706216096878, acc.: 0.00%] [G loss: 0.7034304142] [mll=89.737+-3.907] [ks=8.124]4]\n",
      "63300 [D loss: 0.712389707565, acc.: 0.00%] [G loss: 0.704078137875] [mll=89.480+-3.911] [ks=8.204]\n",
      "63400 [D loss: 0.703542113304, acc.: 0.00%] [G loss: 0.705217599869] [mll=89.136+-4.291] [ks=8.371]\n",
      "63500 [D loss: 0.704694032669, acc.: 0.00%] [G loss: 0.71565246582] [mll=88.001+-5.744] [ks=7.744]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "63600 [D loss: 0.703000426292, acc.: 0.00%] [G loss: 0.707208633423] [mll=90.137+-3.272] [ks=7.794]\n",
      "63700 [D loss: 0.704837560654, acc.: 0.00%] [G loss: 0.701961994171] [mll=89.305+-3.857] [ks=7.918]\n",
      "63800 [D loss: 0.703116595745, acc.: 0.00%] [G loss: 0.702529549599] [mll=89.525+-4.404] [ks=8.175]\n",
      "63900 [D loss: 0.701766371727, acc.: 0.00%] [G loss: 0.70781570673] [mll=86.092+-7.427] [ks=8.433]]\n",
      "64000 [D loss: 0.710849881172, acc.: 0.00%] [G loss: 0.701648116112] [mll=89.453+-4.293] [ks=7.724]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "64100 [D loss: 0.704007863998, acc.: 0.00%] [G loss: 0.70967400074] [mll=89.143+-4.585] [ks=7.657]]\n",
      "64200 [D loss: 0.711594343185, acc.: 0.00%] [G loss: 0.70994669199] [mll=88.565+-4.491] [ks=8.250]]\n",
      "64300 [D loss: 0.709730923176, acc.: 0.00%] [G loss: 0.703157961369] [mll=92.085+-6.083] [ks=8.126]\n",
      "64400 [D loss: 0.70217859745, acc.: 0.00%] [G loss: 0.7034111619] [mll=89.471+-4.056] [ks=7.852]52]\n",
      "64500 [D loss: 0.708853185177, acc.: 0.00%] [G loss: 0.70319455862] [mll=88.998+-3.957] [ks=7.889]]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "64600 [D loss: 0.70523005724, acc.: 0.00%] [G loss: 0.701887845993] [mll=89.687+-4.185] [ks=7.881]]\n",
      "64700 [D loss: 0.708162009716, acc.: 0.00%] [G loss: 0.702166497707] [mll=89.376+-4.600] [ks=7.683]\n",
      "64800 [D loss: 0.704768240452, acc.: 0.00%] [G loss: 0.720691204071] [mll=89.518+-4.705] [ks=7.953]\n",
      "64900 [D loss: 0.704543232918, acc.: 0.00%] [G loss: 0.706265032291] [mll=89.007+-4.111] [ks=7.706]\n",
      "65000 [D loss: 0.70879817009, acc.: 0.00%] [G loss: 0.703134596348] [mll=89.434+-4.187] [ks=7.526]]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "65100 [D loss: 0.703430294991, acc.: 0.00%] [G loss: 0.713872790337] [mll=89.686+-4.287] [ks=7.796]\n",
      "65200 [D loss: 0.705227375031, acc.: 0.00%] [G loss: 0.706544458866] [mll=88.461+-4.204] [ks=8.425]\n",
      "65300 [D loss: 0.70213496685, acc.: 0.00%] [G loss: 0.704039514065] [mll=89.191+-4.879] [ks=7.767]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65400 [D loss: 0.72151863575, acc.: 0.00%] [G loss: 0.704356133938] [mll=89.376+-4.448] [ks=7.472]]\n",
      "65500 [D loss: 0.704776823521, acc.: 0.00%] [G loss: 0.703522086143] [mll=89.704+-4.409] [ks=7.803]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "65600 [D loss: 0.702484190464, acc.: 0.00%] [G loss: 0.703435361385] [mll=89.729+-3.977] [ks=7.847]\n",
      "65700 [D loss: 0.707089424133, acc.: 0.00%] [G loss: 0.702313184738] [mll=89.523+-4.020] [ks=7.260]\n",
      "65800 [D loss: 0.722918391228, acc.: 0.00%] [G loss: 0.702241003513] [mll=89.442+-4.109] [ks=7.442]\n",
      "65900 [D loss: 0.704788088799, acc.: 0.00%] [G loss: 0.704679012299] [mll=89.533+-4.275] [ks=7.949]\n",
      "66000 [D loss: 0.714151620865, acc.: 0.20%] [G loss: 0.713401317596] [mll=89.670+-4.098] [ks=7.985]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "66100 [D loss: 0.705102026463, acc.: 0.00%] [G loss: 0.706397473812] [mll=92.111+-14.183] [ks=8.023]\n",
      "66200 [D loss: 0.702829241753, acc.: 0.00%] [G loss: 0.702626347542] [mll=89.371+-4.744] [ks=7.705]\n",
      "66300 [D loss: 0.703986763954, acc.: 0.00%] [G loss: 0.703297138214] [mll=87.743+-4.860] [ks=7.958]\n",
      "66400 [D loss: 0.749725222588, acc.: 0.00%] [G loss: 0.703564167023] [mll=89.894+-4.254] [ks=7.783]\n",
      "66500 [D loss: 0.703631639481, acc.: 0.00%] [G loss: 0.703238070011] [mll=89.440+-4.105] [ks=8.189]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "66600 [D loss: 0.70388007164, acc.: 0.00%] [G loss: 0.704328000546] [mll=88.895+-4.064] [ks=7.894]]\n",
      "66700 [D loss: 0.704252243042, acc.: 0.00%] [G loss: 0.711794257164] [mll=89.454+-4.499] [ks=7.832]\n",
      "66800 [D loss: 0.704942822456, acc.: 0.00%] [G loss: 0.70451438427] [mll=92.116+-6.228] [ks=8.110]]\n",
      "66900 [D loss: 0.725088834763, acc.: 0.00%] [G loss: 0.702501058578] [mll=89.408+-3.892] [ks=8.122]\n",
      "67000 [D loss: 0.710802555084, acc.: 0.00%] [G loss: 0.702863454819] [mll=89.592+-4.577] [ks=7.836]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "67100 [D loss: 0.706486165524, acc.: 0.00%] [G loss: 0.702028334141] [mll=89.381+-4.420] [ks=7.402]\n",
      "67200 [D loss: 0.70730638504, acc.: 0.00%] [G loss: 0.707954466343] [mll=89.500+-4.537] [ks=7.794]]\n",
      "67300 [D loss: 0.702407240868, acc.: 0.00%] [G loss: 0.701760053635] [mll=90.114+-4.905] [ks=7.655]\n",
      "67400 [D loss: 0.701669096947, acc.: 0.00%] [G loss: 0.703298807144] [mll=89.452+-4.953] [ks=7.665]\n",
      "67500 [D loss: 0.702508568764, acc.: 0.00%] [G loss: 0.70625436306] [mll=89.598+-4.153] [ks=7.779]]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "67600 [D loss: 0.695543587208, acc.: 0.00%] [G loss: 0.714352071285] [mll=88.708+-5.414] [ks=7.942]\n",
      "67700 [D loss: 0.699386835098, acc.: 0.00%] [G loss: 0.797521531582] [mll=87.893+-4.502] [ks=7.556]\n",
      "67800 [D loss: 0.716723442078, acc.: 0.00%] [G loss: 0.724871873856] [mll=89.165+-5.081] [ks=8.040]\n",
      "67900 [D loss: 0.709292769432, acc.: 0.00%] [G loss: 0.710122585297] [mll=90.249+-5.080] [ks=7.407]\n",
      "68000 [D loss: 0.701948881149, acc.: 0.00%] [G loss: 0.705434203148] [mll=89.489+-4.724] [ks=7.974]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "68100 [D loss: 0.702904999256, acc.: 0.00%] [G loss: 0.704068541527] [mll=89.142+-4.597] [ks=7.692]\n",
      "68200 [D loss: 0.707460045815, acc.: 0.00%] [G loss: 0.706775605679] [mll=91.926+-6.412] [ks=7.338]\n",
      "68300 [D loss: 0.710528492928, acc.: 0.00%] [G loss: 0.701645791531] [mll=89.260+-4.474] [ks=7.467]\n",
      "68400 [D loss: 0.701803684235, acc.: 0.00%] [G loss: 0.704312384129] [mll=90.065+-3.943] [ks=8.401]\n",
      "68500 [D loss: 0.707819461823, acc.: 0.00%] [G loss: 0.705452501774] [mll=89.887+-4.283] [ks=7.401]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "68600 [D loss: 0.702500224113, acc.: 0.00%] [G loss: 0.703886568546] [mll=89.221+-3.207] [ks=7.903]\n",
      "68700 [D loss: 0.711031079292, acc.: 0.00%] [G loss: 0.716452181339] [mll=88.636+-3.956] [ks=7.768]\n",
      "68800 [D loss: 0.719467639923, acc.: 0.00%] [G loss: 0.704825758934] [mll=87.768+-3.622] [ks=8.608]\n",
      "68900 [D loss: 0.709641218185, acc.: 0.00%] [G loss: 0.711837351322] [mll=89.229+-4.613] [ks=7.542]\n",
      "69000 [D loss: 0.706951141357, acc.: 0.00%] [G loss: 0.702764928341] [mll=85.436+-5.716] [ks=8.134]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "69100 [D loss: 0.708701610565, acc.: 0.00%] [G loss: 0.705229341984] [mll=90.241+-4.594] [ks=7.690]\n",
      "69200 [D loss: 0.700927972794, acc.: 0.00%] [G loss: 0.703308045864] [mll=89.752+-4.098] [ks=7.580]\n",
      "69300 [D loss: 0.709858834743, acc.: 0.00%] [G loss: 0.701758027077] [mll=90.012+-4.111] [ks=7.606]\n",
      "69400 [D loss: 0.701956748962, acc.: 0.00%] [G loss: 0.704741835594] [mll=89.035+-4.503] [ks=7.680]\n",
      "69500 [D loss: 0.706082820892, acc.: 0.00%] [G loss: 0.704112768173] [mll=89.850+-4.875] [ks=8.381]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "69600 [D loss: 0.707042694092, acc.: 0.00%] [G loss: 0.704837739468] [mll=89.006+-3.835] [ks=8.414]\n",
      "69700 [D loss: 0.72114533186, acc.: 0.00%] [G loss: 0.787025868893] [mll=84.332+-11.005] [ks=8.273]]\n",
      "69800 [D loss: 0.712966024876, acc.: 0.00%] [G loss: 0.715231359005] [mll=86.074+-13.102] [ks=7.516]\n",
      "69900 [D loss: 0.702171325684, acc.: 0.00%] [G loss: 0.705107748508] [mll=89.588+-4.167] [ks=7.829]\n",
      "70000 [D loss: 0.708312451839, acc.: 0.00%] [G loss: 0.703187406063] [mll=88.769+-4.294] [ks=8.002]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "70100 [D loss: 0.708752632141, acc.: 0.00%] [G loss: 0.702658295631] [mll=89.404+-4.364] [ks=8.100]\n",
      "70200 [D loss: 0.704155445099, acc.: 0.00%] [G loss: 0.702407836914] [mll=89.248+-4.689] [ks=7.590]\n",
      "70300 [D loss: 0.709238290787, acc.: 0.00%] [G loss: 0.704273164272] [mll=89.136+-4.282] [ks=7.666]\n",
      "70400 [D loss: 0.70317530632, acc.: 0.00%] [G loss: 0.702983796597] [mll=93.205+-7.018] [ks=7.740]]\n",
      "70500 [D loss: 0.715788722038, acc.: 0.00%] [G loss: 0.702741682529] [mll=89.729+-4.661] [ks=7.741]\n",
      "10000/10000 [==============================] - 0s 50us/step\n",
      "70600 [D loss: 0.704344451427, acc.: 0.00%] [G loss: 0.701464653015] [mll=90.382+-4.472] [ks=7.086]\n",
      "70700 [D loss: 0.708635210991, acc.: 0.00%] [G loss: 0.705815255642] [mll=89.215+-4.438] [ks=7.375]\n",
      "70800 [D loss: 0.713468551636, acc.: 0.00%] [G loss: 0.704945206642] [mll=89.580+-4.416] [ks=7.494]\n",
      "70900 [D loss: 0.706009328365, acc.: 0.00%] [G loss: 0.703785002232] [mll=89.163+-4.471] [ks=7.565]\n",
      "71000 [D loss: 0.705569028854, acc.: 0.00%] [G loss: 0.70213085413] [mll=89.352+-4.499] [ks=7.557]]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "71100 [D loss: 0.708522439003, acc.: 0.00%] [G loss: 0.709016919136] [mll=89.597+-5.034] [ks=7.657]\n",
      "71200 [D loss: 0.720654666424, acc.: 0.00%] [G loss: 0.706333637238] [mll=88.876+-4.904] [ks=8.111]\n",
      "71300 [D loss: 0.705302238464, acc.: 0.00%] [G loss: 0.702753663063] [mll=89.904+-5.492] [ks=8.245]\n",
      "71400 [D loss: 0.707217693329, acc.: 0.00%] [G loss: 0.706149041653] [mll=89.456+-4.192] [ks=8.074]\n",
      "71500 [D loss: 0.704567193985, acc.: 0.00%] [G loss: 0.700695097446] [mll=89.656+-4.673] [ks=8.360]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "71600 [D loss: 0.704122304916, acc.: 0.00%] [G loss: 0.704326570034] [mll=88.620+-5.203] [ks=7.865]\n",
      "71700 [D loss: 0.705549418926, acc.: 0.00%] [G loss: 0.717508852482] [mll=89.781+-4.499] [ks=7.679]\n",
      "71800 [D loss: 0.710019826889, acc.: 0.00%] [G loss: 0.705546796322] [mll=89.286+-4.073] [ks=7.960]\n",
      "71900 [D loss: 0.70476514101, acc.: 0.00%] [G loss: 0.703891217709] [mll=89.498+-5.598] [ks=8.290]]\n",
      "72000 [D loss: 0.705339193344, acc.: 0.00%] [G loss: 0.704429864883] [mll=89.784+-4.568] [ks=8.006]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "72100 [D loss: 0.728244781494, acc.: 0.00%] [G loss: 0.705416142941] [mll=89.164+-4.245] [ks=7.899]\n",
      "72200 [D loss: 0.709000587463, acc.: 0.00%] [G loss: 0.703172922134] [mll=89.600+-4.620] [ks=7.881]\n",
      "72300 [D loss: 0.706851601601, acc.: 0.00%] [G loss: 0.70671069622] [mll=89.627+-4.244] [ks=7.824]]\n",
      "72400 [D loss: 0.708629846573, acc.: 0.00%] [G loss: 0.705019950867] [mll=87.714+-6.707] [ks=7.859]\n",
      "72500 [D loss: 0.706688225269, acc.: 0.20%] [G loss: 0.707129061222] [mll=88.687+-5.280] [ks=7.825]\n",
      "10000/10000 [==============================] - 0s 34us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72600 [D loss: 0.705146670341, acc.: 0.00%] [G loss: 0.703065872192] [mll=92.227+-9.079] [ks=7.640]\n",
      "72700 [D loss: 0.704525709152, acc.: 0.00%] [G loss: 0.705812871456] [mll=89.844+-3.871] [ks=7.601]\n",
      "72800 [D loss: 0.706329882145, acc.: 0.00%] [G loss: 0.704096257687] [mll=89.470+-3.974] [ks=7.855]\n",
      "72900 [D loss: 0.710950195789, acc.: 0.00%] [G loss: 0.718316435814] [mll=92.138+-6.532] [ks=8.021]\n",
      "73000 [D loss: 0.714673519135, acc.: 0.00%] [G loss: 0.705760538578] [mll=90.226+-5.148] [ks=7.861]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "73100 [D loss: 0.706419587135, acc.: 0.00%] [G loss: 0.704683184624] [mll=89.349+-5.545] [ks=8.154]\n",
      "73200 [D loss: 0.707422852516, acc.: 0.00%] [G loss: 0.705187082291] [mll=89.346+-4.390] [ks=8.210]\n",
      "73300 [D loss: 0.704738020897, acc.: 0.00%] [G loss: 0.706470012665] [mll=89.365+-4.268] [ks=8.011]\n",
      "73400 [D loss: 0.705380558968, acc.: 0.00%] [G loss: 0.70433318615] [mll=89.847+-4.261] [ks=7.758]]\n",
      "73500 [D loss: 0.705167889595, acc.: 0.00%] [G loss: 0.703903257847] [mll=89.449+-4.226] [ks=8.173]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "73600 [D loss: 0.705113053322, acc.: 0.00%] [G loss: 0.704059123993] [mll=89.227+-4.343] [ks=7.985]\n",
      "73700 [D loss: 0.706396341324, acc.: 0.00%] [G loss: 0.703839838505] [mll=89.373+-4.596] [ks=8.076]\n",
      "73800 [D loss: 0.706507086754, acc.: 0.00%] [G loss: 0.706132173538] [mll=89.196+-5.814] [ks=8.195]\n",
      "73900 [D loss: 0.702784121037, acc.: 0.00%] [G loss: 0.723261833191] [mll=89.432+-4.215] [ks=8.515]\n",
      "74000 [D loss: 0.702645123005, acc.: 0.00%] [G loss: 0.703512251377] [mll=90.804+-5.103] [ks=7.619]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "74100 [D loss: 0.703535914421, acc.: 0.00%] [G loss: 0.7069683671] [mll=88.579+-5.004] [ks=7.664]4]\n",
      "74200 [D loss: 0.712397217751, acc.: 0.00%] [G loss: 0.70666795969] [mll=89.703+-4.288] [ks=7.765]]\n",
      "74300 [D loss: 0.699910163879, acc.: 0.00%] [G loss: 0.70684170723] [mll=89.544+-5.131] [ks=8.049]]\n",
      "74400 [D loss: 0.710627913475, acc.: 0.00%] [G loss: 0.705390512943] [mll=89.163+-4.396] [ks=7.981]\n",
      "74500 [D loss: 0.707209169865, acc.: 0.00%] [G loss: 0.712709963322] [mll=89.971+-5.154] [ks=8.300]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "74600 [D loss: 0.70547914505, acc.: 0.00%] [G loss: 0.705517172813] [mll=92.080+-7.501] [ks=8.453]]\n",
      "74700 [D loss: 0.709741711617, acc.: 0.00%] [G loss: 0.706464648247] [mll=89.362+-4.245] [ks=8.095]\n",
      "74800 [D loss: 0.70215845108, acc.: 0.00%] [G loss: 0.705245733261] [mll=87.392+-4.483] [ks=8.258]]\n",
      "74900 [D loss: 0.718464612961, acc.: 0.00%] [G loss: 0.70641285181] [mll=90.121+-4.795] [ks=7.888]]\n",
      "75000 [D loss: 0.70312833786, acc.: 0.00%] [G loss: 0.705348491669] [mll=89.406+-4.578] [ks=7.706]]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "75100 [D loss: 0.704142808914, acc.: 0.00%] [G loss: 0.704665243626] [mll=88.801+-4.755] [ks=7.931]\n",
      "75200 [D loss: 0.71126639843, acc.: 0.00%] [G loss: 0.704565286636] [mll=89.251+-4.547] [ks=7.742]]\n",
      "75300 [D loss: 0.703810334206, acc.: 0.00%] [G loss: 0.70507389307] [mll=89.261+-4.597] [ks=7.730]]\n",
      "75400 [D loss: 0.703168511391, acc.: 0.00%] [G loss: 0.711361348629] [mll=90.393+-4.684] [ks=7.928]\n",
      "75500 [D loss: 0.705605864525, acc.: 0.00%] [G loss: 0.704122066498] [mll=87.093+-5.412] [ks=8.077]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "75600 [D loss: 0.710457921028, acc.: 0.00%] [G loss: 0.708822011948] [mll=89.683+-6.435] [ks=7.934]\n",
      "75700 [D loss: 0.704421401024, acc.: 0.00%] [G loss: 0.706606268883] [mll=89.331+-4.797] [ks=7.837]\n",
      "75800 [D loss: 0.707756638527, acc.: 0.00%] [G loss: 0.704517006874] [mll=88.948+-5.289] [ks=7.892]\n",
      "75900 [D loss: 0.708406448364, acc.: 0.00%] [G loss: 0.705048501492] [mll=89.951+-4.508] [ks=7.534]\n",
      "76000 [D loss: 0.704913079739, acc.: 0.00%] [G loss: 0.707953393459] [mll=89.075+-4.313] [ks=7.889]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "76100 [D loss: 0.703846335411, acc.: 0.00%] [G loss: 0.705501019955] [mll=89.619+-4.808] [ks=7.878]\n",
      "76200 [D loss: 0.704204678535, acc.: 0.00%] [G loss: 0.703263223171] [mll=89.418+-4.573] [ks=7.957]\n",
      "76300 [D loss: 0.70415687561, acc.: 0.00%] [G loss: 0.703488588333] [mll=89.056+-4.175] [ks=7.894]]\n",
      "76400 [D loss: 0.704284787178, acc.: 0.00%] [G loss: 0.705107331276] [mll=89.847+-4.378] [ks=8.381]\n",
      "76500 [D loss: 0.704280614853, acc.: 0.00%] [G loss: 0.703410744667] [mll=89.400+-4.531] [ks=7.719]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "76600 [D loss: 0.722745895386, acc.: 0.00%] [G loss: 0.708160459995] [mll=90.128+-4.580] [ks=8.115]\n",
      "76700 [D loss: 0.705438256264, acc.: 0.00%] [G loss: 0.703191637993] [mll=89.818+-4.637] [ks=7.948]\n",
      "76800 [D loss: 0.700756967068, acc.: 0.00%] [G loss: 0.705355107784] [mll=90.223+-5.877] [ks=7.787]\n",
      "76900 [D loss: 0.703780412674, acc.: 0.00%] [G loss: 0.704757630825] [mll=89.423+-4.647] [ks=8.062]\n",
      "77000 [D loss: 0.704932630062, acc.: 0.00%] [G loss: 0.706431746483] [mll=88.088+-4.435] [ks=8.327]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "77100 [D loss: 0.703226208687, acc.: 0.00%] [G loss: 0.706975221634] [mll=83.219+-11.356] [ks=8.101]\n",
      "77200 [D loss: 0.704542636871, acc.: 0.00%] [G loss: 0.703343153] [mll=88.657+-4.183] [ks=7.784]84]\n",
      "77300 [D loss: 0.704273283482, acc.: 0.00%] [G loss: 0.704101681709] [mll=88.158+-5.120] [ks=8.329]\n",
      "77400 [D loss: 0.704855084419, acc.: 0.00%] [G loss: 0.704844415188] [mll=89.367+-4.447] [ks=8.026]\n",
      "77500 [D loss: 0.705103993416, acc.: 0.00%] [G loss: 0.700956344604] [mll=89.009+-5.008] [ks=8.290]\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "77600 [D loss: 0.70723760128, acc.: 0.00%] [G loss: 0.705735683441] [mll=89.858+-3.975] [ks=8.072]]\n",
      "77700 [D loss: 0.705898284912, acc.: 0.00%] [G loss: 0.705594003201] [mll=89.192+-5.332] [ks=8.010]\n",
      "77800 [D loss: 0.711414217949, acc.: 0.00%] [G loss: 0.71492856741] [mll=89.426+-5.601] [ks=8.006]]\n",
      "77900 [D loss: 0.703711509705, acc.: 0.00%] [G loss: 0.707775056362] [mll=89.710+-4.488] [ks=8.255]\n",
      "78000 [D loss: 0.703564763069, acc.: 0.00%] [G loss: 0.706135690212] [mll=89.873+-4.841] [ks=8.154]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "78100 [D loss: 0.705657958984, acc.: 0.00%] [G loss: 0.702877104282] [mll=90.952+-5.139] [ks=7.800]\n",
      "78200 [D loss: 0.700051188469, acc.: 0.00%] [G loss: 0.707881033421] [mll=89.705+-5.244] [ks=7.966]\n",
      "78300 [D loss: 0.715186595917, acc.: 0.00%] [G loss: 0.706280648708] [mll=90.154+-4.573] [ks=8.691]\n",
      "78400 [D loss: 0.708482146263, acc.: 0.00%] [G loss: 0.707226336002] [mll=89.721+-4.391] [ks=7.905]\n",
      "78500 [D loss: 0.705810070038, acc.: 0.00%] [G loss: 0.70025151968] [mll=93.395+-8.892] [ks=8.186]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "78600 [D loss: 0.704564332962, acc.: 0.00%] [G loss: 0.707250535488] [mll=89.614+-4.716] [ks=7.626]\n",
      "78700 [D loss: 0.711938381195, acc.: 0.00%] [G loss: 0.707472264767] [mll=90.087+-5.404] [ks=7.759]\n",
      "78800 [D loss: 0.703145563602, acc.: 0.00%] [G loss: 0.710990309715] [mll=89.305+-5.093] [ks=7.637]\n",
      "78900 [D loss: 0.70956325531, acc.: 0.00%] [G loss: 0.704360485077] [mll=91.699+-4.735] [ks=7.918]]\n",
      "79000 [D loss: 0.704850614071, acc.: 0.00%] [G loss: 0.727479994297] [mll=88.952+-4.479] [ks=7.863]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "79100 [D loss: 0.705746948719, acc.: 0.00%] [G loss: 0.706374526024] [mll=89.432+-4.816] [ks=8.054]\n",
      "79200 [D loss: 0.751713275909, acc.: 0.00%] [G loss: 0.72162938118] [mll=90.180+-5.393] [ks=7.777]]\n",
      "79300 [D loss: 0.708963751793, acc.: 0.00%] [G loss: 0.716805577278] [mll=90.255+-7.964] [ks=8.864]\n",
      "79400 [D loss: 0.706477940083, acc.: 0.00%] [G loss: 0.703763544559] [mll=87.465+-4.538] [ks=8.383]\n",
      "79500 [D loss: 0.707801818848, acc.: 0.00%] [G loss: 0.7051243186] [mll=89.217+-4.457] [ks=8.080]0]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "79600 [D loss: 0.706600308418, acc.: 0.00%] [G loss: 0.706557512283] [mll=89.105+-4.370] [ks=8.123]\n",
      "79700 [D loss: 0.704357147217, acc.: 0.00%] [G loss: 0.704874873161] [mll=89.510+-4.509] [ks=7.950]\n",
      "79800 [D loss: 0.708699464798, acc.: 0.00%] [G loss: 0.708583950996] [mll=89.587+-5.600] [ks=8.074]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79900 [D loss: 0.703518033028, acc.: 0.00%] [G loss: 0.70572668314] [mll=89.726+-4.628] [ks=7.800]]\n",
      "80000 [D loss: 0.706376552582, acc.: 0.00%] [G loss: 0.705198705196] [mll=89.488+-4.862] [ks=8.403]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "80100 [D loss: 0.701454401016, acc.: 0.00%] [G loss: 0.704150795937] [mll=88.672+-4.115] [ks=7.824]\n",
      "80200 [D loss: 0.710980296135, acc.: 0.00%] [G loss: 0.705721437931] [mll=88.625+-4.364] [ks=8.310]\n",
      "80300 [D loss: 0.704851031303, acc.: 0.00%] [G loss: 0.705328822136] [mll=88.935+-4.266] [ks=7.992]\n",
      "80400 [D loss: 0.709968626499, acc.: 0.00%] [G loss: 0.71222025156] [mll=90.077+-4.589] [ks=8.351]]\n",
      "80500 [D loss: 0.706837892532, acc.: 0.00%] [G loss: 0.703678190708] [mll=86.308+-7.704] [ks=8.360]\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "80600 [D loss: 0.70820248127, acc.: 0.00%] [G loss: 0.704286515713] [mll=89.847+-4.434] [ks=7.998]]\n",
      "80700 [D loss: 0.710713267326, acc.: 0.00%] [G loss: 0.709072053432] [mll=89.888+-4.369] [ks=7.695]\n",
      "80800 [D loss: 0.703562855721, acc.: 0.00%] [G loss: 0.70462423563] [mll=88.504+-5.364] [ks=7.949]]\n",
      "80900 [D loss: 0.709290444851, acc.: 0.00%] [G loss: 0.708418011665] [mll=89.196+-4.235] [ks=7.824]\n",
      "81000 [D loss: 0.709945678711, acc.: 0.00%] [G loss: 0.733678758144] [mll=88.839+-4.662] [ks=8.054]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "81100 [D loss: 0.707271814346, acc.: 0.00%] [G loss: 0.705564975739] [mll=87.620+-5.210] [ks=9.077]\n",
      "81200 [D loss: 0.70649433136, acc.: 0.00%] [G loss: 0.705685555935] [mll=89.740+-4.717] [ks=7.683]]\n",
      "81300 [D loss: 0.707131743431, acc.: 0.00%] [G loss: 0.705223560333] [mll=89.631+-4.661] [ks=8.144]\n",
      "81400 [D loss: 0.70255947113, acc.: 0.00%] [G loss: 0.705208837986] [mll=89.373+-4.172] [ks=7.764]]\n",
      "81500 [D loss: 0.70514023304, acc.: 0.00%] [G loss: 0.718423128128] [mll=89.424+-4.591] [ks=7.850]]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "81600 [D loss: 0.708492279053, acc.: 0.00%] [G loss: 0.704112052917] [mll=89.418+-4.605] [ks=8.102]\n",
      "81700 [D loss: 0.703457832336, acc.: 0.00%] [G loss: 0.700858533382] [mll=89.343+-5.028] [ks=7.822]\n",
      "81800 [D loss: 0.707428574562, acc.: 0.00%] [G loss: 0.707440376282] [mll=89.750+-4.611] [ks=7.715]\n",
      "81900 [D loss: 0.713830828667, acc.: 0.00%] [G loss: 0.71482616663] [mll=89.738+-4.264] [ks=7.681]]\n",
      "82000 [D loss: 0.707178592682, acc.: 0.00%] [G loss: 0.707615613937] [mll=90.289+-4.392] [ks=7.865]\n",
      "10000/10000 [==============================] - 0s 47us/step\n",
      "82100 [D loss: 0.704152464867, acc.: 0.00%] [G loss: 0.705296278] [mll=90.864+-6.008] [ks=7.621]21]\n",
      "82200 [D loss: 0.730766654015, acc.: 0.00%] [G loss: 0.706230163574] [mll=88.701+-5.256] [ks=7.819]\n",
      "82300 [D loss: 0.704705357552, acc.: 0.00%] [G loss: 0.705005228519] [mll=89.969+-4.463] [ks=7.480]\n",
      "82400 [D loss: 0.711435258389, acc.: 0.00%] [G loss: 0.706617832184] [mll=90.411+-4.641] [ks=7.588]\n",
      "82500 [D loss: 0.705759048462, acc.: 0.00%] [G loss: 0.707942068577] [mll=88.371+-4.504] [ks=7.879]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "82600 [D loss: 0.705211877823, acc.: 0.00%] [G loss: 0.708026945591] [mll=89.159+-4.506] [ks=7.791]\n",
      "82700 [D loss: 0.706644058228, acc.: 0.00%] [G loss: 0.706480562687] [mll=89.637+-4.346] [ks=8.204]\n",
      "82800 [D loss: 0.706849813461, acc.: 0.39%] [G loss: 0.711585462093] [mll=89.772+-4.201] [ks=8.083]\n",
      "82900 [D loss: 0.703051686287, acc.: 0.00%] [G loss: 0.708924293518] [mll=95.897+-15.045] [ks=7.585]\n",
      "83000 [D loss: 0.697682082653, acc.: 0.00%] [G loss: 0.7167506814] [mll=88.083+-4.465] [ks=7.833]3]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "83100 [D loss: 0.711752891541, acc.: 0.00%] [G loss: 0.709333956242] [mll=89.759+-4.304] [ks=8.250]\n",
      "83200 [D loss: 0.704940140247, acc.: 0.00%] [G loss: 0.706457197666] [mll=89.141+-3.770] [ks=7.874]\n",
      "83300 [D loss: 0.70756149292, acc.: 0.00%] [G loss: 0.70465940237] [mll=89.226+-4.601] [ks=7.910]0]\n",
      "83400 [D loss: 0.70549094677, acc.: 0.00%] [G loss: 0.706794202328] [mll=89.188+-4.503] [ks=8.547]]\n",
      "83500 [D loss: 0.703008413315, acc.: 0.00%] [G loss: 0.705599844456] [mll=90.741+-5.132] [ks=7.790]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "83600 [D loss: 0.705228567123, acc.: 0.00%] [G loss: 0.702490270138] [mll=89.125+-4.347] [ks=7.862]\n",
      "83700 [D loss: 0.734575152397, acc.: 0.00%] [G loss: 0.704832613468] [mll=89.453+-4.434] [ks=8.259]\n",
      "83800 [D loss: 0.704151570797, acc.: 0.00%] [G loss: 0.705839157104] [mll=88.692+-4.678] [ks=7.951]\n",
      "83900 [D loss: 0.705228567123, acc.: 0.00%] [G loss: 0.703966140747] [mll=89.458+-4.783] [ks=7.803]\n",
      "84000 [D loss: 0.492381989956, acc.: 0.00%] [G loss: 0.867623806] [mll=89.011+-4.812] [ks=8.243]43]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "84100 [D loss: 0.691563546658, acc.: 0.00%] [G loss: 0.934139192104] [mll=72.546+-10.906] [ks=11.792]\n",
      "84200 [D loss: 0.711035072803, acc.: 0.00%] [G loss: 0.746288239956] [mll=89.966+-7.045] [ks=8.014]\n",
      "84300 [D loss: 0.707360267639, acc.: 0.00%] [G loss: 0.721128582954] [mll=90.343+-4.968] [ks=8.020]\n",
      "84400 [D loss: 0.704620242119, acc.: 0.00%] [G loss: 0.710727214813] [mll=89.489+-4.315] [ks=8.276]\n",
      "84500 [D loss: 0.704531550407, acc.: 0.00%] [G loss: 0.704384207726] [mll=89.635+-4.309] [ks=7.959]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "84600 [D loss: 0.704393386841, acc.: 0.00%] [G loss: 0.703171133995] [mll=89.699+-4.271] [ks=8.136]\n",
      "84700 [D loss: 0.710749030113, acc.: 0.00%] [G loss: 0.703049242496] [mll=90.131+-4.329] [ks=7.848]\n",
      "84800 [D loss: 0.703620970249, acc.: 0.00%] [G loss: 0.709225893021] [mll=89.279+-3.907] [ks=7.619]\n",
      "84900 [D loss: 0.710141658783, acc.: 0.00%] [G loss: 0.70301347971] [mll=88.847+-4.425] [ks=7.568]]\n",
      "85000 [D loss: 0.705180168152, acc.: 0.00%] [G loss: 0.704070329666] [mll=89.148+-4.046] [ks=7.545]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "85100 [D loss: 0.73302590847, acc.: 0.00%] [G loss: 0.716520369053] [mll=94.180+-8.373] [ks=7.642]]\n",
      "85200 [D loss: 0.705973625183, acc.: 0.00%] [G loss: 0.703630447388] [mll=86.415+-8.317] [ks=8.036]\n",
      "85300 [D loss: 0.712837934494, acc.: 0.39%] [G loss: 0.716439127922] [mll=89.691+-4.021] [ks=7.871]\n",
      "85400 [D loss: 0.705008804798, acc.: 0.00%] [G loss: 0.706406533718] [mll=95.351+-9.852] [ks=8.066]\n",
      "85500 [D loss: 0.724763631821, acc.: 0.00%] [G loss: 0.704249918461] [mll=88.834+-4.229] [ks=7.767]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "85600 [D loss: 0.701193571091, acc.: 0.00%] [G loss: 0.705710530281] [mll=89.722+-4.229] [ks=7.615]\n",
      "85700 [D loss: 0.729160785675, acc.: 0.00%] [G loss: 0.704076528549] [mll=89.309+-4.451] [ks=7.916]\n",
      "85800 [D loss: 0.711082577705, acc.: 0.00%] [G loss: 0.705918192863] [mll=88.973+-4.522] [ks=7.759]\n",
      "85900 [D loss: 0.703107953072, acc.: 0.00%] [G loss: 0.702556610107] [mll=88.065+-4.373] [ks=7.925]\n",
      "86000 [D loss: 0.714193403721, acc.: 0.00%] [G loss: 0.703956961632] [mll=89.449+-4.353] [ks=7.812]\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "86100 [D loss: 0.706282794476, acc.: 0.00%] [G loss: 0.711541712284] [mll=90.297+-4.169] [ks=7.333]\n",
      "86200 [D loss: 0.710470736027, acc.: 0.00%] [G loss: 0.716840207577] [mll=89.189+-4.603] [ks=7.892]\n",
      "86300 [D loss: 0.703799724579, acc.: 0.00%] [G loss: 0.706122517586] [mll=92.458+-6.480] [ks=7.903]\n",
      "86400 [D loss: 0.707817316055, acc.: 0.00%] [G loss: 0.706154763699] [mll=89.557+-4.214] [ks=7.642]\n",
      "86500 [D loss: 0.706283330917, acc.: 0.00%] [G loss: 0.703578352928] [mll=89.137+-4.369] [ks=7.675]\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "86600 [D loss: 0.703593373299, acc.: 0.00%] [G loss: 0.70446485281] [mll=89.676+-4.797] [ks=7.575]]\n",
      "86700 [D loss: 0.704433560371, acc.: 0.00%] [G loss: 0.704723477364] [mll=89.155+-4.981] [ks=8.165]\n",
      "86800 [D loss: 0.702612042427, acc.: 0.00%] [G loss: 0.705183446407] [mll=89.749+-4.402] [ks=7.955]\n",
      "86900 [D loss: 0.706793308258, acc.: 0.00%] [G loss: 0.706332623959] [mll=89.435+-4.353] [ks=7.924]\n",
      "87000 [D loss: 0.703276097775, acc.: 0.00%] [G loss: 0.703736305237] [mll=89.322+-4.374] [ks=7.923]\n",
      "10000/10000 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87100 [D loss: 0.733048498631, acc.: 0.00%] [G loss: 0.7058801651] [mll=89.961+-4.484] [ks=7.772]]]\n",
      "87200 [D loss: 0.709249377251, acc.: 0.00%] [G loss: 0.706842541695] [mll=89.225+-4.364] [ks=8.435]\n",
      "87300 [D loss: 0.706650733948, acc.: 0.00%] [G loss: 0.705385446548] [mll=88.618+-4.400] [ks=8.102]\n",
      "87400 [D loss: 0.708628177643, acc.: 0.00%] [G loss: 0.706606805325] [mll=89.361+-4.597] [ks=7.784]\n",
      "87500 [D loss: 0.706632256508, acc.: 0.20%] [G loss: 0.703582763672] [mll=89.771+-4.195] [ks=7.861]\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "87600 [D loss: 0.705144047737, acc.: 0.00%] [G loss: 0.71155923605] [mll=89.203+-5.326] [ks=7.883]]\n",
      "87700 [D loss: 0.707520723343, acc.: 0.00%] [G loss: 0.706772327423] [mll=89.798+-4.457] [ks=7.874]\n",
      "87800 [D loss: 0.72606742382, acc.: 0.00%] [G loss: 0.706362783909] [mll=89.603+-4.604] [ks=7.876]]\n",
      "87900 [D loss: 0.707460641861, acc.: 0.00%] [G loss: 0.708558082581] [mll=90.528+-5.756] [ks=7.838]\n",
      "88000 [D loss: 0.70593225956, acc.: 0.00%] [G loss: 0.704752504826] [mll=89.443+-4.297] [ks=7.776]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "88100 [D loss: 0.703887701035, acc.: 0.00%] [G loss: 0.705752849579] [mll=89.405+-4.565] [ks=7.971]\n",
      "88200 [D loss: 0.70381373167, acc.: 0.00%] [G loss: 0.710165560246] [mll=88.825+-5.175] [ks=8.131]]\n",
      "88300 [D loss: 0.707542538643, acc.: 0.00%] [G loss: 0.708728253841] [mll=90.481+-5.360] [ks=7.733]\n",
      "88400 [D loss: 0.7109811306, acc.: 0.00%] [G loss: 0.703572332859] [mll=90.021+-4.510] [ks=8.000]0]\n",
      "88500 [D loss: 0.703969120979, acc.: 0.00%] [G loss: 0.706709325314] [mll=89.035+-4.925] [ks=7.869]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "88600 [D loss: 0.831806242466, acc.: 0.00%] [G loss: 0.704316675663] [mll=90.206+-4.809] [ks=7.714]\n",
      "88700 [D loss: 0.702988624573, acc.: 0.00%] [G loss: 0.703852713108] [mll=89.662+-5.101] [ks=8.291]\n",
      "88800 [D loss: 0.706975698471, acc.: 0.00%] [G loss: 0.707146525383] [mll=88.760+-4.988] [ks=8.241]\n",
      "88900 [D loss: 0.702613115311, acc.: 0.00%] [G loss: 0.704279780388] [mll=89.964+-4.568] [ks=8.166]\n",
      "89000 [D loss: 0.701019883156, acc.: 0.00%] [G loss: 0.707895219326] [mll=89.842+-4.364] [ks=7.715]\n",
      "10000/10000 [==============================] - 1s 54us/step\n",
      "89100 [D loss: 0.707744419575, acc.: 0.00%] [G loss: 0.706980288029] [mll=89.282+-4.754] [ks=8.386]\n",
      "89200 [D loss: 0.709979176521, acc.: 0.00%] [G loss: 0.704890668392] [mll=89.337+-5.151] [ks=7.757]\n",
      "89300 [D loss: 0.702724933624, acc.: 0.00%] [G loss: 0.707977354527] [mll=90.337+-4.599] [ks=7.798]\n",
      "89400 [D loss: 0.707788586617, acc.: 0.00%] [G loss: 0.709369719028] [mll=88.020+-4.932] [ks=8.098]\n",
      "89500 [D loss: 0.707829594612, acc.: 0.00%] [G loss: 0.715558111668] [mll=89.628+-4.911] [ks=10.602]\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "89600 [D loss: 0.70345044136, acc.: 0.00%] [G loss: 0.708506524563] [mll=89.578+-4.705] [ks=7.969]]\n",
      "89700 [D loss: 0.704367518425, acc.: 0.00%] [G loss: 0.704831540585] [mll=89.462+-5.337] [ks=7.930]\n",
      "89800 [D loss: 0.707838118076, acc.: 0.00%] [G loss: 0.705723822117] [mll=90.339+-4.587] [ks=8.222]\n",
      "89900 [D loss: 0.705224752426, acc.: 0.00%] [G loss: 0.70761692524] [mll=84.753+-11.222] [ks=8.443]]\n",
      "90000 [D loss: 0.703201055527, acc.: 0.00%] [G loss: 0.706900060177] [mll=89.619+-4.207] [ks=7.816]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "90100 [D loss: 0.707624435425, acc.: 0.00%] [G loss: 0.706306040287] [mll=88.289+-4.903] [ks=8.092]\n",
      "90200 [D loss: 0.702728807926, acc.: 0.00%] [G loss: 0.710506677628] [mll=88.278+-4.780] [ks=8.360]\n",
      "90300 [D loss: 0.705036640167, acc.: 0.00%] [G loss: 0.70420396328] [mll=91.985+-5.458] [ks=7.748]]\n",
      "90400 [D loss: 0.722111344337, acc.: 0.00%] [G loss: 0.708398580551] [mll=89.783+-4.299] [ks=7.500]\n",
      "90500 [D loss: 0.704078912735, acc.: 0.00%] [G loss: 0.705281972885] [mll=94.630+-10.551] [ks=7.961]\n",
      "10000/10000 [==============================] - 0s 39us/step\n",
      "90600 [D loss: 0.712583184242, acc.: 0.00%] [G loss: 0.703845381737] [mll=89.463+-4.616] [ks=7.576]\n",
      "90700 [D loss: 0.711359977722, acc.: 0.20%] [G loss: 0.719055294991] [mll=89.551+-5.092] [ks=7.452]\n",
      "90800 [D loss: 0.706804394722, acc.: 0.00%] [G loss: 0.706886351109] [mll=93.465+-9.428] [ks=8.301]\n",
      "90900 [D loss: 0.709853410721, acc.: 0.00%] [G loss: 0.703330039978] [mll=89.663+-4.306] [ks=7.649]\n",
      "91000 [D loss: 0.703205347061, acc.: 0.00%] [G loss: 0.706897199154] [mll=88.722+-4.243] [ks=8.324]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "91100 [D loss: 0.720097362995, acc.: 0.00%] [G loss: 0.705309152603] [mll=89.385+-4.530] [ks=8.182]\n",
      "91200 [D loss: 0.705551981926, acc.: 0.00%] [G loss: 0.704765915871] [mll=89.342+-4.680] [ks=8.127]\n",
      "91300 [D loss: 0.706016600132, acc.: 0.00%] [G loss: 0.704196453094] [mll=88.945+-4.544] [ks=7.885]\n",
      "91400 [D loss: 0.702111959457, acc.: 0.00%] [G loss: 0.707042098045] [mll=89.187+-4.022] [ks=8.002]\n",
      "91500 [D loss: 0.707197189331, acc.: 0.00%] [G loss: 0.717377722263] [mll=89.642+-4.708] [ks=9.173]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "91600 [D loss: 0.709037423134, acc.: 0.00%] [G loss: 0.705417096615] [mll=88.097+-4.571] [ks=8.225]\n",
      "91700 [D loss: 0.702670633793, acc.: 0.00%] [G loss: 0.70524841547] [mll=89.911+-4.200] [ks=8.021]]\n",
      "91800 [D loss: 0.706832885742, acc.: 0.00%] [G loss: 0.704826414585] [mll=89.838+-4.395] [ks=8.051]\n",
      "91900 [D loss: 0.705508828163, acc.: 0.00%] [G loss: 0.704639554024] [mll=89.194+-4.647] [ks=7.799]\n",
      "92000 [D loss: 0.703448295593, acc.: 0.00%] [G loss: 0.705619871616] [mll=89.448+-4.285] [ks=7.615]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "92100 [D loss: 0.708555757999, acc.: 0.00%] [G loss: 0.70652794838] [mll=89.163+-4.664] [ks=7.641]]\n",
      "92200 [D loss: 0.752915382385, acc.: 0.00%] [G loss: 0.705888211727] [mll=89.176+-4.781] [ks=8.327]\n",
      "92300 [D loss: 0.7191426754, acc.: 0.00%] [G loss: 0.706003725529] [mll=89.230+-4.877] [ks=8.609]]]\n",
      "92400 [D loss: 0.718918442726, acc.: 0.00%] [G loss: 0.702517032623] [mll=89.382+-4.192] [ks=7.789]\n",
      "92500 [D loss: 0.704154253006, acc.: 0.00%] [G loss: 0.704702973366] [mll=90.398+-4.908] [ks=7.672]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "92600 [D loss: 0.708729863167, acc.: 0.00%] [G loss: 0.706917524338] [mll=89.626+-4.667] [ks=7.630]\n",
      "92700 [D loss: 0.711479067802, acc.: 0.00%] [G loss: 0.705773890018] [mll=89.565+-5.318] [ks=7.636]\n",
      "92800 [D loss: 0.706012547016, acc.: 0.00%] [G loss: 0.704317033291] [mll=89.412+-4.989] [ks=7.539]\n",
      "92900 [D loss: 0.707972764969, acc.: 0.20%] [G loss: 0.715484082699] [mll=89.466+-4.858] [ks=7.971]\n",
      "93000 [D loss: 0.702385902405, acc.: 0.00%] [G loss: 0.70689445734] [mll=95.854+-10.146] [ks=8.015]]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "93100 [D loss: 0.706751585007, acc.: 0.00%] [G loss: 0.703201234341] [mll=88.979+-4.591] [ks=7.987]\n",
      "93200 [D loss: 0.705323576927, acc.: 0.00%] [G loss: 0.70371234417] [mll=89.463+-5.593] [ks=7.752]]\n",
      "93300 [D loss: 0.385768979788, acc.: 0.00%] [G loss: 1.02367162704] [mll=90.000+-4.774] [ks=7.623]]\n",
      "93400 [D loss: 0.729322195053, acc.: 0.00%] [G loss: 0.837434649467] [mll=77.163+-8.032] [ks=10.798]\n",
      "93500 [D loss: 0.709418237209, acc.: 0.00%] [G loss: 0.738107264042] [mll=92.692+-6.205] [ks=8.010]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "93600 [D loss: 0.705865204334, acc.: 0.00%] [G loss: 0.715154111385] [mll=90.560+-4.980] [ks=7.190]\n",
      "93700 [D loss: 0.683485507965, acc.: 0.00%] [G loss: 0.710852563381] [mll=89.603+-5.583] [ks=7.911]\n",
      "93800 [D loss: 0.705257892609, acc.: 0.00%] [G loss: 0.728453218937] [mll=90.017+-5.920] [ks=8.789]\n",
      "93900 [D loss: 0.703700721264, acc.: 0.00%] [G loss: 0.709042131901] [mll=89.607+-4.998] [ks=7.676]\n",
      "94000 [D loss: 0.703562736511, acc.: 0.00%] [G loss: 0.712854325771] [mll=89.962+-4.316] [ks=7.714]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "94100 [D loss: 0.70419973135, acc.: 0.00%] [G loss: 0.704956769943] [mll=89.687+-4.638] [ks=7.902]]\n",
      "94200 [D loss: 0.703616857529, acc.: 0.00%] [G loss: 0.704342782497] [mll=88.894+-5.444] [ks=7.972]\n",
      "94300 [D loss: 0.707559466362, acc.: 0.00%] [G loss: 0.704671323299] [mll=89.620+-4.222] [ks=8.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94400 [D loss: 0.707594633102, acc.: 0.00%] [G loss: 0.702052116394] [mll=88.774+-4.364] [ks=7.968]\n",
      "94500 [D loss: 0.772324621677, acc.: 0.00%] [G loss: 0.708307802677] [mll=89.385+-4.766] [ks=7.581]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "94600 [D loss: 0.709205508232, acc.: 0.00%] [G loss: 0.707582890987] [mll=89.904+-3.899] [ks=7.803]\n",
      "94700 [D loss: 0.708213090897, acc.: 0.00%] [G loss: 0.707558274269] [mll=89.332+-4.708] [ks=7.554]\n",
      "94800 [D loss: 0.709797620773, acc.: 0.00%] [G loss: 0.713301599026] [mll=89.252+-4.024] [ks=7.680]\n",
      "94900 [D loss: 0.703903198242, acc.: 0.00%] [G loss: 0.704571187496] [mll=89.721+-4.335] [ks=7.459]\n",
      "95000 [D loss: 0.705792546272, acc.: 0.00%] [G loss: 0.722206652164] [mll=89.511+-4.524] [ks=7.753]\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "95100 [D loss: 0.703872025013, acc.: 0.00%] [G loss: 0.705655992031] [mll=89.294+-4.375] [ks=8.012]\n",
      "95200 [D loss: 0.702827692032, acc.: 0.00%] [G loss: 0.704945802689] [mll=89.487+-4.504] [ks=7.688]\n",
      "95300 [D loss: 0.707612454891, acc.: 0.00%] [G loss: 0.710576176643] [mll=89.418+-5.317] [ks=9.626]\n",
      "95400 [D loss: 0.70793646574, acc.: 0.00%] [G loss: 0.703306078911] [mll=89.577+-4.685] [ks=7.875]]\n",
      "95500 [D loss: 0.70708489418, acc.: 0.00%] [G loss: 0.705655932426] [mll=89.473+-4.466] [ks=7.742]]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "95600 [D loss: 0.70767557621, acc.: 0.00%] [G loss: 0.709152817726] [mll=89.635+-4.460] [ks=8.034]]\n",
      "95700 [D loss: 0.712793588638, acc.: 0.00%] [G loss: 0.713903546333] [mll=89.387+-4.024] [ks=7.973]\n",
      "95800 [D loss: 0.711768567562, acc.: 0.00%] [G loss: 0.704685926437] [mll=89.507+-5.150] [ks=8.239]\n",
      "95900 [D loss: 0.718440711498, acc.: 0.00%] [G loss: 0.729605197906] [mll=89.423+-4.450] [ks=7.988]\n",
      "96000 [D loss: 0.715134441853, acc.: 0.00%] [G loss: 0.703401982784] [mll=92.273+-7.913] [ks=7.949]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "96100 [D loss: 0.705247581005, acc.: 0.00%] [G loss: 0.707040250301] [mll=88.552+-4.904] [ks=7.805]\n",
      "96200 [D loss: 0.703447699547, acc.: 0.00%] [G loss: 0.70394128561] [mll=89.336+-4.274] [ks=8.064]]\n",
      "96300 [D loss: 0.691232144833, acc.: 0.00%] [G loss: 0.712929010391] [mll=89.506+-4.188] [ks=7.685]\n",
      "96400 [D loss: 0.706680893898, acc.: 0.00%] [G loss: 0.715029120445] [mll=88.888+-4.801] [ks=8.723]\n",
      "96500 [D loss: 0.704840540886, acc.: 0.00%] [G loss: 0.705192327499] [mll=89.429+-5.679] [ks=7.955]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "96600 [D loss: 0.704877972603, acc.: 0.00%] [G loss: 0.710334837437] [mll=86.881+-5.155] [ks=8.207]\n",
      "96700 [D loss: 0.70616877079, acc.: 0.00%] [G loss: 0.704420506954] [mll=89.393+-4.805] [ks=8.061]]\n",
      "96800 [D loss: 0.711580872536, acc.: 0.00%] [G loss: 0.705136537552] [mll=89.199+-4.271] [ks=7.881]\n",
      "96900 [D loss: 0.703370392323, acc.: 0.00%] [G loss: 0.704617381096] [mll=84.957+-8.468] [ks=8.056]\n",
      "97000 [D loss: 0.741375923157, acc.: 0.00%] [G loss: 0.707091271877] [mll=89.144+-4.634] [ks=8.145]\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "97100 [D loss: 0.707239568233, acc.: 0.00%] [G loss: 0.706806659698] [mll=89.139+-4.347] [ks=8.414]\n",
      "97200 [D loss: 0.707776784897, acc.: 0.00%] [G loss: 0.703584313393] [mll=89.643+-4.259] [ks=8.003]\n",
      "97300 [D loss: 0.734128594398, acc.: 0.00%] [G loss: 0.707565844059] [mll=88.322+-4.872] [ks=7.846]\n",
      "97400 [D loss: 0.70608651638, acc.: 0.00%] [G loss: 0.707920968533] [mll=89.634+-5.007] [ks=7.761]]\n",
      "97500 [D loss: 0.711569964886, acc.: 0.00%] [G loss: 0.719829022884] [mll=90.189+-4.375] [ks=7.837]\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "97600 [D loss: 0.72848290205, acc.: 0.00%] [G loss: 0.706443428993] [mll=90.123+-5.917] [ks=7.794]]\n",
      "97700 [D loss: 0.702485799789, acc.: 0.00%] [G loss: 0.708093702793] [mll=89.197+-5.133] [ks=8.266]\n",
      "97800 [D loss: 0.704353809357, acc.: 0.00%] [G loss: 0.706825315952] [mll=89.683+-3.882] [ks=8.017]\n",
      "97900 [D loss: 0.760459423065, acc.: 0.00%] [G loss: 0.729153633118] [mll=88.962+-4.823] [ks=7.985]\n",
      "98000 [D loss: 0.709194898605, acc.: 0.00%] [G loss: 0.709024548531] [mll=88.974+-4.788] [ks=7.841]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "98100 [D loss: 0.716385483742, acc.: 0.00%] [G loss: 0.706416666508] [mll=93.085+-7.146] [ks=8.089]\n",
      "98200 [D loss: 0.717088103294, acc.: 0.00%] [G loss: 0.72185844183] [mll=89.258+-4.672] [ks=7.666]]\n",
      "98300 [D loss: 0.702704310417, acc.: 0.00%] [G loss: 0.705436229706] [mll=85.934+-6.579] [ks=8.516]\n",
      "98400 [D loss: 0.707366764545, acc.: 0.00%] [G loss: 0.710026860237] [mll=88.785+-4.728] [ks=8.090]\n",
      "98500 [D loss: 0.704249382019, acc.: 0.00%] [G loss: 0.703849434853] [mll=85.542+-7.016] [ks=8.340]\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "98600 [D loss: 0.700135946274, acc.: 0.00%] [G loss: 0.705020666122] [mll=89.631+-4.699] [ks=7.689]\n",
      "98700 [D loss: 0.705532371998, acc.: 0.00%] [G loss: 0.70747178793] [mll=88.994+-5.027] [ks=8.306]]\n",
      "98800 [D loss: 0.694019973278, acc.: 0.00%] [G loss: 0.704067766666] [mll=88.485+-4.493] [ks=8.254]\n",
      "98900 [D loss: 0.70810842514, acc.: 0.20%] [G loss: 0.706365346909] [mll=89.206+-4.721] [ks=8.547]]\n",
      "99000 [D loss: 0.709264159203, acc.: 0.00%] [G loss: 0.707460343838] [mll=89.502+-4.656] [ks=7.879]\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "99100 [D loss: 0.705032587051, acc.: 0.00%] [G loss: 0.702667951584] [mll=89.827+-5.194] [ks=7.873]\n",
      "99200 [D loss: 0.702140808105, acc.: 0.00%] [G loss: 0.703534185886] [mll=89.184+-5.167] [ks=7.957]\n",
      "99300 [D loss: 0.710294365883, acc.: 0.00%] [G loss: 0.704471170902] [mll=89.581+-4.976] [ks=7.606]\n",
      "99400 [D loss: 0.714026212692, acc.: 0.00%] [G loss: 0.71296018362] [mll=89.528+-4.751] [ks=7.992]]\n",
      "99500 [D loss: 0.717887759209, acc.: 0.00%] [G loss: 0.706464290619] [mll=89.883+-5.537] [ks=8.015]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "99600 [D loss: 0.705962061882, acc.: 0.00%] [G loss: 0.70826280117] [mll=89.601+-4.880] [ks=7.919]]\n",
      "99700 [D loss: 0.702659130096, acc.: 0.00%] [G loss: 0.708060801029] [mll=89.451+-4.468] [ks=8.091]\n",
      "99800 [D loss: 0.757394552231, acc.: 0.00%] [G loss: 0.713312387466] [mll=89.958+-5.036] [ks=7.926]\n",
      "99900 [D loss: 0.70728468895, acc.: 0.00%] [G loss: 0.706796705723] [mll=86.627+-5.213] [ks=8.572]]\n",
      "100000 [D loss: 0.708827137947, acc.: 0.00%] [G loss: 0.705090641975] [mll=89.222+-4.922] [ks=7.703]\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "Scaling jet pts\n",
      "Scaling lep isos\n",
      "Discriminator params: 161537\n",
      "Generator params: 340497\n",
      "scaling lepton isolations\n",
      "scaling jet pts\n",
      "100 [D loss: 0.858670771122, acc.: 50.00%] [G loss: 1.51251900196] [mll=-1.000+--1.000] [ks=999.000]\n",
      "KS score improved from 999.00 to 15.40, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_100.weights\n",
      "200 [D loss: 0.0558671206236, acc.: 0.00%] [G loss: 5.72502470016] [mll=nan+-nan] [ks=15.396]\n",
      "KS score improved from 15.40 to 14.20, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_200.weights\n",
      "300 [D loss: 0.355506896973, acc.: 0.00%] [G loss: 5.4809923172] [mll=44.413+-5.346] [ks=14.196]]]\n",
      "KS score improved from 14.20 to 13.94, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_300.weights\n",
      "400 [D loss: 0.192501991987, acc.: 0.00%] [G loss: 6.19563627243] [mll=48.216+-5.751] [ks=13.941]]\n",
      "500 [D loss: 0.110271885991, acc.: 0.00%] [G loss: 7.09531354904] [mll=43.615+-4.899] [ks=14.209]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "600 [D loss: 0.110733784735, acc.: 0.00%] [G loss: 5.40682983398] [mll=57.334+-6.309] [ks=15.031]]\n",
      "700 [D loss: 0.0511082559824, acc.: 0.00%] [G loss: 5.5661945343] [mll=77.420+-8.527] [ks=14.063]]\n",
      "KS score improved from 13.94 to 13.40, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_700.weights\n",
      "800 [D loss: 0.134130999446, acc.: 0.00%] [G loss: 6.06164264679] [mll=71.543+-7.677] [ks=13.397]]\n",
      "900 [D loss: 0.0537689104676, acc.: 0.00%] [G loss: 5.11356735229] [mll=74.599+-7.771] [ks=13.647]\n",
      "1000 [D loss: 0.125458166003, acc.: 0.00%] [G loss: 5.26791763306] [mll=74.010+-7.264] [ks=13.950]\n",
      "10000/10000 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 [D loss: 0.339876830578, acc.: 0.00%] [G loss: 5.37839078903] [mll=57.689+-5.178] [ks=14.783]]\n",
      "1200 [D loss: 0.922900557518, acc.: 0.00%] [G loss: 2.95878458023] [mll=52.311+-4.667] [ks=14.376]]\n",
      "1300 [D loss: 0.162435591221, acc.: 0.00%] [G loss: 5.69382572174] [mll=21.028+-2.106] [ks=15.375]]\n",
      "1400 [D loss: 0.0481594949961, acc.: 0.00%] [G loss: 5.21388244629] [mll=63.929+-5.673] [ks=14.404]\n",
      "KS score improved from 13.40 to 12.99, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_1400.weights\n",
      "1500 [D loss: 0.0526015982032, acc.: 0.00%] [G loss: 4.50280237198] [mll=83.351+-8.890] [ks=12.993]\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "KS score improved from 12.99 to 12.04, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_1500.weights\n",
      "1600 [D loss: 0.0605621337891, acc.: 0.00%] [G loss: 3.95328307152] [mll=90.752+-8.024] [ks=12.037]\n",
      "1700 [D loss: 0.203616887331, acc.: 0.00%] [G loss: 6.18505907059] [mll=78.119+-6.919] [ks=14.715]]\n",
      "1800 [D loss: 0.214732155204, acc.: 0.00%] [G loss: 3.52193665504] [mll=54.283+-6.263] [ks=13.306]]\n",
      "1900 [D loss: 0.323684185743, acc.: 0.00%] [G loss: 6.70232486725] [mll=52.493+-5.459] [ks=14.475]]\n",
      "2000 [D loss: 0.192513644695, acc.: 0.00%] [G loss: 4.60080099106] [mll=45.039+-2.838] [ks=14.757]]\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "2100 [D loss: 0.170426815748, acc.: 0.00%] [G loss: 3.8510248661] [mll=76.896+-6.895] [ks=12.903]]]\n",
      "KS score improved from 12.04 to 10.37, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_2100.weights\n",
      "2200 [D loss: 0.2223123312, acc.: 0.00%] [G loss: 3.29688286781] [mll=70.053+-21.682] [ks=10.370]70]\n",
      "2300 [D loss: 0.553423285484, acc.: 0.00%] [G loss: 2.70873308182] [mll=60.083+-16.263] [ks=12.492]]\n",
      "2400 [D loss: 0.194227352738, acc.: 0.00%] [G loss: 3.14835691452] [mll=102.855+-28.398] [ks=12.078]\n",
      "2500 [D loss: 0.161133855581, acc.: 0.00%] [G loss: 2.33477306366] [mll=43.437+-20.878] [ks=13.757]]\n",
      "10000/10000 [==============================] - 0s 45us/step\n",
      "2600 [D loss: 0.178142771125, acc.: 0.00%] [G loss: 2.91389107704] [mll=62.166+-9.099] [ks=12.781]\n",
      "2700 [D loss: 0.24441075325, acc.: 0.00%] [G loss: 2.75246405602] [mll=69.117+-10.088] [ks=11.151]]]\n",
      "2800 [D loss: 0.280569314957, acc.: 0.00%] [G loss: 2.38009953499] [mll=84.573+-7.045] [ks=13.012]]\n",
      "2900 [D loss: 1.26186668873, acc.: 0.20%] [G loss: 2.50126862526] [mll=75.722+-10.818] [ks=11.172]]]\n",
      "KS score improved from 10.37 to 9.73, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_2900.weights\n",
      "3000 [D loss: 0.324654132128, acc.: 0.00%] [G loss: 1.726744771] [mll=78.320+-33.181] [ks=9.732]]]]\n",
      "10000/10000 [==============================] - 0s 48us/step\n",
      "3100 [D loss: 0.233407557011, acc.: 0.00%] [G loss: 2.56241893768] [mll=91.459+-13.646] [ks=11.304]]\n",
      "3200 [D loss: 0.438914775848, acc.: 0.00%] [G loss: 2.92916321754] [mll=74.344+-8.762] [ks=13.498]]\n",
      "3300 [D loss: 0.220695003867, acc.: 0.00%] [G loss: 2.64607453346] [mll=73.450+-17.169] [ks=11.083]]\n",
      "3400 [D loss: 0.114701494575, acc.: 0.00%] [G loss: 2.78044843674] [mll=89.142+-10.362] [ks=11.037]]\n",
      "3500 [D loss: 0.14139804244, acc.: 0.00%] [G loss: 2.45415663719] [mll=70.729+-9.350] [ks=13.198]]\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "3600 [D loss: 0.256610959768, acc.: 0.00%] [G loss: 2.61947989464] [mll=85.941+-7.919] [ks=11.220]]\n",
      "3700 [D loss: 0.342641353607, acc.: 0.20%] [G loss: 4.14057683945] [mll=61.209+-14.904] [ks=11.972]]\n",
      "3800 [D loss: 0.105135768652, acc.: 0.00%] [G loss: 3.16530776024] [mll=76.008+-13.390] [ks=10.649]]\n",
      "3900 [D loss: 0.301479518414, acc.: 0.00%] [G loss: 4.766248703] [mll=77.501+-12.491] [ks=10.752]2]]\n",
      "4000 [D loss: 0.54632461071, acc.: 0.00%] [G loss: 2.42573451996] [mll=79.964+-18.852] [ks=10.248]]]\n",
      "10000/10000 [==============================] - 1s 50us/step\n",
      "KS score improved from 9.73 to 8.86, saving models to progress/jetisoscale_mllwidth_flatNegNoise_6/gen_4000.weights\n",
      "4100 [D loss: nan, acc.: 0.00%] [G loss: nan] [mll=95.465+-12.977] [ks=8.864]5+-12.977] [ks=8.864]]\n",
      "4200 [D loss: nan, acc.: 0.00%] [G loss: nan] [mll=nan+-nan] [ks=18.000]\n",
      "4300 [D loss: nan, acc.: 0.00%] [G loss: nan] [mll=nan+-nan] [ks=18.000]\n",
      "4400 [D loss: nan, acc.: 0.00%] [G loss: nan] [mll=nan+-nan] [ks=18.000]\n",
      "4500 [D loss: nan, acc.: 0.00%] [G loss: nan] [mll=nan+-nan] [ks=18.000]\n",
      "10000/10000 [==============================] - 0s 49us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ae0477f51296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"verbose\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# gan.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5e7bbc69a611>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# note, nested within nepochs_dump_pred_metrics, so below value must be multiple of that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnepochs_dump_plots\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntest_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrac_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                     \u001b[0mreals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     _ = make_plots(preds,reals,title=\"{}: epoch {}\".format(self.tag,epoch),\n",
      "\u001b[0;32m<ipython-input-8-e2ff9266f1b3>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, N, frac)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mjetcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoscaler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0misocoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misocoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjetscaler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mjetcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjetscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjetcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scale_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    params[\"tag\"] = \"jetisoscale_mllwidth_flatNegNoise_{}\".format(i)\n",
    "    params[\"verbose\"] = False\n",
    "    gan = GAN(**params)\n",
    "    gan.train()\n",
    "# gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gan.predict(150000,1.0)\n",
    "make_plots(preds,gan.data[:N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot metrics vs epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.tag = \"v5_default_scan_0\"\n",
    "gan.load_last_checkpoint()\n",
    "print \"Loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def smooth(x,window=31,npoly=2):\n",
    "    from scipy.signal import savgol_filter\n",
    "    return savgol_filter(x,window,npoly)\n",
    "\n",
    "fig, (ax1, ax2, ax3,ax4) = plt.subplots(1,4,figsize=(15,3))\n",
    "# plot losses\n",
    "ax1.plot(gan.d_epochinfo[\"epoch\"],gan.d_epochinfo[\"d_loss\"],color=\"C0\",lw=0.5)\n",
    "ax1.plot(gan.d_epochinfo[\"epoch\"],gan.d_epochinfo[\"g_loss\"],color=\"C1\",lw=0.5)\n",
    "ax1.plot(gan.d_epochinfo[\"epoch\"],smooth(gan.d_epochinfo[\"d_loss\"]),label=\"d loss (smoothed)\",color=\"C0\")\n",
    "ax1.plot(gan.d_epochinfo[\"epoch\"],smooth(gan.d_epochinfo[\"g_loss\"]),label=\"g loss (smoothed)\",color=\"C1\")\n",
    "ax1.legend()\n",
    "# plot masses\n",
    "ax2.plot(gan.d_epochinfo[\"epoch\"],gan.d_epochinfo[\"mass_sig\"],color=\"C0\",lw=0.5)\n",
    "ax2.plot(gan.d_epochinfo[\"epoch\"],gan.d_epochinfo[\"mass_mu\"],color=\"C1\",lw=0.5)\n",
    "ax2.plot(gan.d_epochinfo[\"epoch\"],smooth(gan.d_epochinfo[\"mass_sig\"]),label=\"Z width (smoothed)\",color=\"C0\")\n",
    "ax2.plot(gan.d_epochinfo[\"epoch\"],smooth(gan.d_epochinfo[\"mass_mu\"]),label=\"Z mass (smoothed)\",color=\"C1\")\n",
    "ax2.legend()\n",
    "# plot ks metrics\n",
    "ax3.plot(gan.d_epochinfo[\"epoch\"],gan.d_epochinfo[\"ks\"], lw=0.5,color=\"C0\")\n",
    "ax3.plot(gan.d_epochinfo[\"epoch\"],smooth(gan.d_epochinfo[\"ks\"]), label=\"KS metric (smooth)\",color=\"C0\")\n",
    "ax3.legend();\n",
    "# plot times\n",
    "ax4.plot(gan.d_epochinfo[\"epoch\"],1./60*(np.array(gan.d_epochinfo[\"time\"])-gan.d_epochinfo[\"time\"][0]), label=\"times [min]\")\n",
    "ax4.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions and real events\n",
    "Get the noise from the gan object, feed it into the generator, then also take true events (`data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15000\n",
    "# frac = 0.0001 # 2 events\n",
    "# frac = 0.00005 # 1 event\n",
    "frac = 1.0\n",
    "_, noise = gan.get_noise(N,max_true_samples_frac=frac)\n",
    "# print preds.shape\n",
    "preds = gan.generator.predict(noise,verbose=1)\n",
    "make_plots(preds,gan.data[:N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recarray\n",
    "The real data (`gan.data`) is a recarray, so column indexing happens with `gan.data[\"lep1_px\"]`.\n",
    "The predictions from the generator are just normal matrices, so you have to do yucky things like `preds[:,7]`\n",
    "and keep track of what that means. Use a helper function to get a `np.view` into the predictions so that\n",
    "they columns can be accessed in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_pt(data,haspy2=False):\n",
    "    pxsum = data[\"lep1_px\"]+data[\"lep2_px\"]\n",
    "    if haspy2: pysum = data[\"lep1_py\"]+data[\"lep2_py\"]\n",
    "    else: pysum = data[\"lep1_py\"]\n",
    "    return np.hypot(pxsum,pysum)\n",
    "\n",
    "def met_pt(data):\n",
    "    if \"met\" in data.dtype.names:\n",
    "        return data[\"met\"]\n",
    "    else:\n",
    "        return np.hypot(data[\"metx\"],data[\"mety\"])\n",
    "    \n",
    "def ht(data):\n",
    "    return data[\"jet_pt1\"]*(data[\"jet_pt1\"] > 10) + \\\n",
    "           data[\"jet_pt2\"]*(data[\"jet_pt2\"] > 10) + \\\n",
    "           data[\"jet_pt3\"]*(data[\"jet_pt3\"] > 10) + \\\n",
    "           data[\"jet_pt4\"]*(data[\"jet_pt4\"] > 10) + \\\n",
    "           data[\"jet_pt5\"]*(data[\"jet_pt5\"] > 10)\n",
    "\n",
    "def nvtx(data):\n",
    "    if \"mll\" in data.dtype.names:\n",
    "        return data.nvtxs\n",
    "    else:\n",
    "        return np.rint(data[\"nvtxs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Z_pT for predicted and real events\n",
    "predsrec = get_recview(preds)\n",
    "fig,ax = plt.subplots()\n",
    "ax.hist(Z_pt(predsrec,haspy2=False),label=\"Z $p_{T}$ fake\",bins=np.linspace(0,100,50),histtype=\"step\",density=True,lw=2)\n",
    "ax.hist(Z_pt(gan.data[:10000],haspy2=False), label=\"Z $p_{T}$ real\",bins=np.linspace(0,100,50),histtype=\"step\",density=True,lw=2)\n",
    "ax.legend()\n",
    "ax.set_title(\"Z-boson $p_T$ for real and fake events\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "lowpu_real_met  = met_pt(gan.data)[nvtx(gan.data) < 10]\n",
    "highpu_real_met = met_pt(gan.data)[nvtx(gan.data) > 25]\n",
    "lowpu_fake_met  = met_pt(predsrec)[nvtx(predsrec) < 10]\n",
    "highpu_fake_met = met_pt(predsrec)[nvtx(predsrec) > 25]\n",
    "_ = ax.hist(lowpu_real_met,label=\"low PU, real\",bins=np.linspace(0,100,50),histtype=\"step\",density=True,lw=1.5)\n",
    "_ = ax.hist(lowpu_fake_met,label=\"low PU, fake\",bins=np.linspace(0,100,50),histtype=\"step\",density=True,lw=1.5)\n",
    "_ = ax.hist(highpu_real_met,label=\"high PU, real\",bins=np.linspace(0,100,50),histtype=\"step\",density=True,lw=1.5)\n",
    "_ = ax.hist(highpu_fake_met,label=\"high PU, fake\",bins=np.linspace(0,100,50),histtype=\"step\",density=True,lw=1.5)\n",
    "_ = ax.legend()\n",
    "_ = ax.set_title(\"MET for low (nvtx<10) and high (nvtx>25) events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(9,4), sharex=True,sharey=True)\n",
    "\n",
    "bins = [np.linspace(15,75,15),np.linspace(15,75,15)]\n",
    "\n",
    "ptj1 = gan.data[\"jet_pt1\"]\n",
    "zpt = Z_pt(gan.data)\n",
    "good = (zpt > 15.) & (ptj1 > 15.)\n",
    "_,_,_,im = ax1.hist2d(ptj1[good],zpt[good],label=\"real\",bins=bins,normed=True) #, norm=LogNorm())\n",
    "fig.colorbar(im,ax=ax1, format=\"%.0e\")\n",
    "\n",
    "ptj1 = predsrec[\"jet_pt1\"]\n",
    "zpt = Z_pt(predsrec)\n",
    "good = (zpt > 15.) & (ptj1 > 15.)\n",
    "_,_,_,im = ax2.hist2d(ptj1[good],zpt[good],label=\"real\",bins=bins,normed=True)\n",
    "fig.colorbar(im,ax=ax2, format='%.0e')\n",
    "\n",
    "ax1.set_title(\"Real\")\n",
    "ax2.set_title(\"Fake\")\n",
    "ax1.set_ylabel(\"Z $p_{T}$\")\n",
    "ax1.set_xlabel(\"jet 1 $p_{T}$\")\n",
    "ax2.set_xlabel(\"jet 1 $p_{T}$\")\n",
    "\n",
    "\n",
    "fig.set_tight_layout(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predmll = Minv(preds)\n",
    "predmll = predmll[np.isfinite(predmll)]\n",
    "bins = np.linspace(60,120,120)\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, sharex=True,gridspec_kw={'height_ratios':[9, 2]})\n",
    "hreal = ax1.hist(gan.data[\"mll\"],bins=bins, label=\"real $m_{ll}$\",histtype=\"step\",density=True,lw=2)\n",
    "hfake = ax1.hist(predmll,bins=bins, label=\"fake $m_{ll}$\",histtype=\"step\",density=True,lw=2)\n",
    "ratio = hfake[0]/hreal[0]\n",
    "ax2.plot(bins[:-1],ratio,marker=\"o\",markersize=3,linewidth=1.5,linestyle=\"\")\n",
    "ax2.set_ylim([0.5,1.5])\n",
    "ax2.set_ylabel(\"fake/real\")\n",
    "_ = ax1.legend()\n",
    "realmll = gan.data[\"mll\"]\n",
    "print \"real:\",realmll.mean(), realmll.std()\n",
    "print \"fake:\",predmll.mean(), predmll.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetmat = np.c_[predsrec[\"jet_pt1\"],predsrec[\"jet_pt2\"],predsrec[\"jet_pt3\"],predsrec[\"jet_pt4\"],predsrec[\"jet_pt5\"]]\n",
    "# njet counts just any jet with pt>15\n",
    "njets1 = (jetmat > 15.).sum(axis=-1)\n",
    "# njet counts only jets with pt>15 starting from first jet if all previous jets pass threshold\n",
    "# e.g., if jetpt1>15, jetpt2<15, jetpt3>15, then njets==1 in second case, but 2 in first case\n",
    "njets2 = (jetmat > 15.).argmin(axis=-1)\n",
    "# turns out the two are very similar\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(12,3), sharey=False)\n",
    "for numer,denom,ax in [\n",
    "    [\"jet_pt2\",\"jet_pt1\",ax1],\n",
    "    [\"jet_pt3\",\"jet_pt2\",ax2],\n",
    "    [\"jet_pt4\",\"jet_pt3\",ax3],\n",
    "]:\n",
    "    jetratio_real = (gan.data[:N][numer]/gan.data[:N][denom])[(gan.data[:N][denom] > 15.) & (gan.data[:N][numer] > 15.)]\n",
    "    jetratio_fake = (predsrec[numer]/predsrec[denom])[(predsrec[denom] > 15.) & (predsrec[numer] > 15.)]\n",
    "    bins = np.linspace(0,4,60)\n",
    "    ax.hist(jetratio_real,bins=bins,histtype=\"step\",density=True,label=\"real\",lw=1.5)\n",
    "    ax.hist(jetratio_fake,bins=bins,histtype=\"step\",density=True,label=\"fake\",lw=1.5)\n",
    "    ax.legend()\n",
    "    ax.set_title(\"{} / {} ratio\".format(numer,denom))\n",
    "fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "picklenames = glob.glob(\"progress/v3_default_scan*/*pkl\")\n",
    "def get_epochks(fname):\n",
    "    with open(fname) as fh:\n",
    "        data = pickle.load(fh)\n",
    "        return np.array(data[\"epoch\"]),np.array(data[\"ks\"])\n",
    "    return [],[]\n",
    "# print dirnames\n",
    "# print get_epochks(picklenames[0])\n",
    "fig,ax = plt.subplots()\n",
    "for pn in picklenames:\n",
    "    xs, ys = get_epochks(pn)\n",
    "#     good = ys < 0.08\n",
    "#     xs = xs[good]\n",
    "#     ys = ys[good]\n",
    "    print pn, xs[ys.argmin()], ys[ys.argmin()]\n",
    "#     ax.plot(xs,ys, label=pn)\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
